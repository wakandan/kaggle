{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:56:37.126876Z",
     "start_time": "2018-09-24T07:56:34.525485Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import re\n",
    "# try using stacking\n",
    "from mlxtend.classifier import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T03:57:29.048469Z",
     "start_time": "2018-09-24T03:57:29.026727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "----------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_df.info()\n",
    "print('-'*40)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pal = dict(man=\"#4682B4\", woman=\"#CD5C5C\", child=\"#2E8B57\", male=\"#6495ED\", female=\"#F08080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff2ec22eda0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl0nNWd5vHvr6q0WYsXSd4XGdtgliQEHAiELISBNj1JnAUaJ3TCmXDa6Uk4vWT6zDEzE840J5kTzpxuutNhMk03pIE0Y9J0OFEnTjuLyQoYCzAxxhhkebdsS7YlWbK2Uv3mj7pyClG23tJSVTLP55w6euvWfV/da8t6fN/7vvc1d0dERCRW6AaIiEhxUCCIiAigQBARkUCBICIigAJBREQCBYKIiAAKBBERCRQIIiICKBBERCRIFLoBuairq/OGhoZCN0NEZEp54YUX2t29frR6UyoQGhoaaGpqKnQzRESmFDPbF6WeThmJiAigQBARkUCBICIigAJBREQCBYKIiAAKBBERCRQIIiICKBBERCRQIIiICDDF7lQuJo9v2f+Wss9cvbgALRERmRgaIYiICKBAEBGRQIEgIiKAAkFERAIFgoiIAAoEEREJIgWCma02s11m1mxm67N8XmZmT4TPt5hZQyi/ysy2hdfLZvaJjH32mtn28JmeeiMiUmCj3odgZnHgAeBG4CCw1cwa3f3VjGp3AifdfbmZrQXuA24DXgFWuXvSzOYBL5vZv7l7Mux3vbu3T2SHRERkbKKMEK4Cmt29xd0HgA3AmhF11gCPhO0ngRvMzNz9dMYv/3LAJ6LRIiIy8aIEwgLgQMb7g6Esa50QAJ1ALYCZXW1mO4DtwB9nBIQDPzazF8xs3dm+uZmtM7MmM2tqa2uL0icRERmDSZ9Udvct7n4p8B7gbjMrDx9d5+5XADcDXzKzD5xl/wfdfZW7r6qvr5/s5oqIvG1FCYRDwKKM9wtDWdY6ZpYApgPHMyu4+06gG7gsvD8Uvh4DniJ9akpERAokSiBsBVaY2VIzKwXWAo0j6jQCd4TtW4DN7u5hnwSAmS0BVgJ7zazSzKpDeSVwE+kJaBERKZBRrzIKVwjdBWwC4sDD7r7DzO4Fmty9EXgIeMzMmoETpEMD4DpgvZkNAingi+7ebmYXAE+Z2XAbHnf3f5/ozomISHSRlr92943AxhFl92Rs9wG3ZtnvMeCxLOUtwLtybayIiEwe3aksIiKAAkFERAIFgoiIAAoEEREJFAgiIgIoEEREJFAgiIgIoEAQEZFAgSAiIoACQUREAgWCiIgACgQREQkUCCIiAigQREQkUCCIiAigQBARkUCBICIigAJBREQCBYKIiAARA8HMVpvZLjNrNrP1WT4vM7MnwudbzKwhlF9lZtvC62Uz+0TUY4qISH6NGghmFgceAG4GLgE+bWaXjKh2J3DS3ZcD9wP3hfJXgFXufjmwGvh7M0tEPKaIiORRlBHCVUCzu7e4+wCwAVgzos4a4JGw/SRwg5mZu59292QoLwc8h2OKiEgeRQmEBcCBjPcHQ1nWOiEAOoFaADO72sx2ANuBPw6fRzkmYf91ZtZkZk1tbW0RmisiImMx6ZPK7r7F3S8F3gPcbWblOe7/oLuvcvdV9fX1k9NIERGJFAiHgEUZ7xeGsqx1zCwBTAeOZ1Zw951AN3BZxGOKiEgeRQmErcAKM1tqZqXAWqBxRJ1G4I6wfQuw2d097JMAMLMlwEpgb8RjiohIHiVGq+DuSTO7C9gExIGH3X2Hmd0LNLl7I/AQ8JiZNQMnSP+CB7gOWG9mg0AK+KK7twNkO+YE901ERHIwaiAAuPtGYOOIsnsytvuAW7Ps9xjwWNRjiohI4ehOZRERARQIIiISKBBERARQIIiISKBAEBERQIEgIiKBAkFERAAFgoiIBAoEEREBFAgiIhIoEEREBFAgiIhIoEAQERFAgSAiIoECQUREAAWCiIgECgQREQEUCCIiEigQREQEiBgIZrbazHaZWbOZrc/yeZmZPRE+32JmDaH8RjN7wcy2h68fztjn5+GY28Jr9kR1SkREcpcYrYKZxYEHgBuBg8BWM2t091czqt0JnHT35Wa2FrgPuA1oBz7q7ofN7DJgE7AgY7/b3b1pgvoiIiLjEGWEcBXQ7O4t7j4AbADWjKizBngkbD8J3GBm5u4vufvhUL4DqDCzsolouIiITKwogbAAOJDx/iBv/l/+m+q4exLoBGpH1PkU8KK792eUfTucLvqKmVlOLRcRkQmVl0llM7uU9GmkL2QU3+7u7wDeH16fPcu+68ysycya2traJr+xIiJvU1EC4RCwKOP9wlCWtY6ZJYDpwPHwfiHwFPA5d989vIO7HwpfTwGPkz419Rbu/qC7r3L3VfX19VH6JCIiYxAlELYCK8xsqZmVAmuBxhF1GoE7wvYtwGZ3dzObAfwQWO/uvxmubGYJM6sL2yXAR4BXxtcVEREZj1EDIcwJ3EX6CqGdwHfdfYeZ3WtmHwvVHgJqzawZ+DIwfGnqXcBy4J4Rl5eWAZvM7LfANtIjjH+YyI6JiEhuRr3sFMDdNwIbR5Tdk7HdB9yaZb+vAl89y2GvjN5MERGZbLpTWUREAAWCiIgECgQREQEUCCIiEigQREQEUCCIiEigQBAREUCBICIigQJBREQABYKIiAQKBBERARQIIiISKBBERARQIIiISKBAEBERQIEgIiKBAkFERAAFgoiIBAoEEREBIgaCma02s11m1mxm67N8XmZmT4TPt5hZQyi/0cxeMLPt4euHM/a5MpQ3m9k3zMwmqlMiIpK7UQPBzOLAA8DNwCXAp83skhHV7gROuvty4H7gvlDeDnzU3d8B3AE8lrHPt4A/AlaE1+px9KNoJIdSvLDvBKmUF7opIiI5iTJCuApodvcWdx8ANgBrRtRZAzwStp8EbjAzc/eX3P1wKN8BVITRxDygxt2fc3cHHgU+Pu7eFFAylWLD8/v58F/9gk9961kaXz48+k4iIkUkSiAsAA5kvD8YyrLWcfck0AnUjqjzKeBFd+8P9Q+Ocswpo7s/yd/89A3Wf2870ytKqC5L8FzL8UI3S0QkJ3mZVDazS0mfRvrCGPZdZ2ZNZtbU1tY28Y2bALuPdXOiZ4A/WLWQte9ZxIKZFfx05zEe37K/0E0TEYksSiAcAhZlvF8YyrLWMbMEMB04Ht4vBJ4CPufuuzPqLxzlmAC4+4PuvsrdV9XX10dobv4d6eojZnDZgumYGQ21lbR399Pdnyx000REIosSCFuBFWa21MxKgbVA44g6jaQnjQFuATa7u5vZDOCHwHp3/81wZXdvBbrM7L3h6qLPAd8fZ18K5mhXH3VVZSRi6T/OJbXTANh/vKeQzRIRycmogRDmBO4CNgE7ge+6+w4zu9fMPhaqPQTUmlkz8GVg+NLUu4DlwD1mti28ZofPvgj8I9AM7AZ+NFGdyrejXX3MqSk/837BjAoSMWPv8dMFbJWISG4SUSq5+0Zg44iyezK2+4Bbs+z3VeCrZzlmE3BZLo0tRv2DQ5w8PciVS34XCIl4jIUzK9irEYKITCG6U3mcjp3qB2BuxggBoKG2ksMdvZwe0DyCiEwNCoRxOtrVB8CcmrI3lS+prSTlsO1ARyGaJSKSMwXCOB3p6qMkbsysLH1T+eJZ0zCgae/JwjRMRCRHCoRxOtrVx+zqcmIjlmKqKI0zp6acrXtPFKhlIiK5USCM09Gu/rfMHwxbUjuNF/edJDmUynOrRERyp0AYh+7+JN39ybfMHwxrqKukZ2CI146cynPLRERyp0AYh99NKJ9lhDArfYPaS/s1jyAixU+BMA5nAmF69kCYXlFCZWmc3W26H0FEip8CYRyOdvVTURKnuiz7/X1mxgX1VbS0KxBEpPgpEMZheMmKcz3sbWldJXvau/PYKhGRsVEgjJG7h0DIPqE8bGldJQdP9tKfHMpTy0RExkaBMEadvYP0J1PMPcv8wbAL6itxh31a6E5EipwCYYyOdqXXMJpdPUog1FUB0KKJZREpcgqEMeroHQBg1oglK0ZqqEtferpHE8siUuQUCGPUeXqQmEF1+blXEK8uL2F2dRktbZpYFpHipkAYo87eQarLS96yhlE26SuNNEIQkeIW6QE58ladvYNMrygZtd7jW/aTcmdnaxePb9l/pvwzVy+ezOaJiORMI4QxihoIAHVVZfQMDNE7oEtPRaR4KRDGwN3p6sstEADau/sns1kiIuMSKRDMbLWZ7TKzZjNbn+XzMjN7Iny+xcwaQnmtmT1tZt1m9s0R+/w8HHNbeM2eiA7lQ8fpQQaHnBoFgoicR0adQzCzOPAAcCNwENhqZo3u/mpGtTuBk+6+3MzWAvcBtwF9wFeAy8JrpNvdvWmcfci71s70onZRRwizKkuJGbQpEESkiEUZIVwFNLt7i7sPABuANSPqrAEeCdtPAjeYmbl7j7v/mnQwnDeOdPUC0QMhHjNmTiulvXtgMpslIjIuUQJhAXAg4/3BUJa1jrsngU6gNsKxvx1OF33FzrVCXJE53JHbCAHSp42Oa4QgIkWskJPKt7v7O4D3h9dns1Uys3Vm1mRmTW1tbXlt4Nkc6eyLdFNapvrqMtq7+0m5T2LLRETGLkogHAIWZbxfGMqy1jGzBDAdOH6ug7r7ofD1FPA46VNT2eo96O6r3H1VfX19hOZOvtbOvsg3pQ2rrSplcMjp6h2cxJaJiIxdlEDYCqwws6VmVgqsBRpH1GkE7gjbtwCb3c/+X2EzS5hZXdguAT4CvJJr4wultbM3p9NFkHmlkeYRRKQ4jXrOw92TZnYXsAmIAw+7+w4zuxdocvdG4CHgMTNrBk6QDg0AzGwvUAOUmtnHgZuAfcCmEAZx4KfAP0xozybRkc6+yJecDqvPuPR0+eyqyWiWiMi4RDoJ7u4bgY0jyu7J2O4Dbj3Lvg1nOeyV0ZpYXNyd1s4+rlg8I6f9qssTlMZjmlgWkaKlO5Vz1Nk7SO/gENOnnXvZ65HMjNoqXXoqIsVLgZCjXG9Ky1RXVaa7lUWkaCkQctTaGW5Ky+GS02F1VaWcPD3AUEqXnopI8VEg5OjMCCHHU0YAtVVlpBxO9ui0kYgUHwVCjoZvSqsqG8sIQYvciUjxUiDk6HBHH3NqyonHcl9poy48f7ldIwQRKUIKhBwd6epl7vTyMe07rSxBRUlcIwQRKUoKhBy1dvYxb4yBAOmJZQWCiBQjBUIO3J3Wjj7mTa8Y8zHSq57qlJGIFB8FQg66epP0Dg6Na4RQW1WWvrlNz1cWkSKjQMhBa3gwzljnECB9yghg7/GeCWmTiMhEUSDkoDU8GGe8p4wA9rYrEESkuCgQcjB8U9r4ThmlRwgtCgQRKTIKhBy0dvYSM5hdXTbmY5Ql4lSXJ9ijQBCRIqNAyEFrZx+zq8tJxMf3x1ZXVaZTRiJSdBQIOWjt7GXejLGfLhpWV1WqEYKIFB0FQg7Ge1PasNrKMo73DNCp5yuLSBFRIEQ0ETelDdOVRiJSjBQIEU3ETWnDhq800mkjESkmkQLBzFab2S4zazaz9Vk+LzOzJ8LnW8ysIZTXmtnTZtZtZt8csc+VZrY97PMNM8t9+dA8OhwejDMRI4TaylLMdOmpiBSXUQPBzOLAA8DNwCXAp83skhHV7gROuvty4H7gvlDeB3wF+Issh/4W8EfAivBaPZYO5MuRcA/CeO5SHpaIx1gyaxpvHD017mOJiEyUKCOEq4Bmd29x9wFgA7BmRJ01wCNh+0ngBjMzd+9x91+TDoYzzGweUOPuz7m7A48CHx9PRybb8Ahh/gRcZQSwcm4Nrx1RIIhI8YgSCAuAAxnvD4ayrHXcPQl0ArWjHPPgKMcsKsNPSquvGvtNaZlWzqtm7/EeTg8kJ+R4IiLjVfSTyma2zsyazKypra2tYO0YflLaeG9KG7Zybg3u8MbR7gk5nojIeEX57XYIWJTxfmEoy1rHzBLAdOD4KMdcOMoxAXD3B919lbuvqq+vj9DcyTGeJ6Vlc/G8agBeO9I1YccUERmPKIGwFVhhZkvNrBRYCzSOqNMI3BG2bwE2h7mBrNy9Fegys/eGq4s+B3w/59bnUWtHH/Mn4AqjYYtmTmNaaZydrZpHEJHikBitgrsnzewuYBMQBx529x1mdi/Q5O6NwEPAY2bWDJwgHRoAmNleoAYoNbOPAze5+6vAF4F/AiqAH4VXUXJ3Wjv7uH7l7Ak7ZixmXDS3WiMEESkaowYCgLtvBDaOKLsnY7sPuPUs+zacpbwJuCxqQwups3dwwm5Ky7Rybg0/eqUVd6fIb8MQkbeBop9ULga/ew7CxJ0ygvQ8QsfpQY529U/ocUVExkKBEEHr8F3KE3QPwrCVc2sA2KnTRiJSBBQIERzuGP+T0rK5aG640kgTyyJSBBQIERzp7CMeM2ZXT2wgTK8oYcGMCk0si0hRUCBEcLizl9nVZcRjEz/xu3JutUYIIlIUFAgRHJmgB+Nks3JeNbvbuulPDk3K8UVEolIgRJB+UtrEXmE0bOXcGpIpZ/cxLYUtIoWlQBhF+qa03kkbIWgJCxEpFgqEUXScHqRvMMW8GZMzQmioraQ0EWNnqwJBRApLgTCK392UNjkjhEQ8xqXza3hxf8ekHF9EJCoFwijO3JQ2SYEAcM0Ftbx8oIOefj0bQUQKR4EwislatiLTtcvqSKacrXtPTNr3EBEZjQJhFPtPnKY0HqO+emKelJbNlUtmUhI3nt19rkdIiIhMLgXCKFraummomzYpN6UNqyiN8+7FM3m2RYEgIoWjQBhFS1sPy+qrJv37XLusllcOddLZOzjp30tEJBsFwjkMDqXYf+I0F9RXTvr3uuaCWlIOz+/RPIKIFIYC4Rz2nzhNMuVcUDf5I4TLF8+gvCTGM7vbJ/17iYhko0A4h93HugHyMkIoS8RZtWSWJpZFpGAUCOfQ0p5eX+iCPMwhAFyzrJbXjpzieLeeoCYi+RcpEMxstZntMrNmM1uf5fMyM3sifL7FzBoyPrs7lO8ys9/LKN9rZtvNbJuZNU1EZyZaS1s3dVWlTK8oycv3u3ZZLQDPtWgeQUTyLzFaBTOLAw8ANwIHga1m1ujur2ZUuxM46e7LzWwtcB9wm5ldAqwFLgXmAz81swvdfXit5+vdvWhPmre09Uza/MHjW/a/pewPVi2kqizBM7vb+Y/vnDcp31dE5GyijBCuAprdvcXdB4ANwJoRddYAj4TtJ4EbzMxC+QZ373f3PUBzON6U0NLew7LZkz9/MCwRj/GBC+vYuL2VvkE9H0FE8itKICwADmS8PxjKstZx9yTQCdSOsq8DPzazF8xsXe5Nn1wdpwc40TOQlyuMMv3h1Us4eXqQH/y2Na/fV0SkkJPK17n7FcDNwJfM7APZKpnZOjNrMrOmtra2vDVud9vwhHL+RgiQnlheVl/JY8/ty+v3FRGJEgiHgEUZ7xeGsqx1zCwBTAeOn2tfdx/+egx4irOcSnL3B919lbuvqq+vj9DcibG7bfiS0/yOEMyMz753CS8f6OC3B7UktojkT5RA2AqsMLOlZlZKepK4cUSdRuCOsH0LsNndPZSvDVchLQVWAM+bWaWZVQOYWSVwE/DK+LszcVraeiiJG4tmTt4qp2fzySsXMq00zqPPapQgIvkzaiCEOYG7gE3ATuC77r7DzO41s4+Fag8BtWbWDHwZWB/23QF8F3gV+HfgS+EKoznAr83sZeB54Ifu/u8T27XxaWnrZvGsaSTi+T+rVlNewifevYB/e/kwJ3sG8v79ReTtadTLTgHcfSOwcUTZPRnbfcCtZ9n3a8DXRpS1AO/KtbH51NKen0Xtzuaz1yzhn7fs5789tZ33r3jzqbLPXL24QK0SkfOZ7lTOIjmUYt/xnrzPH2RaObeGq5fO4hevt9GlFVBFJA8UCFkcPNnL4JDn/Qqjkb72icsYHErxRNMBhlJe0LaIyPlPgZBFS3v6CqNlBQ6E5bOrWXP5Ava097D5taMFbYuInP8UCFnsPhbuQcjzTWnZXLF4JlcumcnPd7XxxtFThW6OiJzHFAhZbDvYwdyacmZWlha6KQB89J3zqa8u4ztb9rF1zwnSV/SKiEysSFcZvZ0MpZzfNLfzHy6eU+imnFGaiPH59y3lX144wFPbDtEzkOTrn3ons0YEVrYF83RFkohEpRHCCDsOd9JxepD3r6grdFPepKaihP/0vqXcfNlcfr6rjQ/976f5y3/bodNIIjJhNEIY4VdvpFfjft/y4goEgJgZ719Rz5/csIIHnm7mO8/t49u/2cuqJTP52OXz6R0Yoro8P89uEJHzjwJhhF++3sal82uoqyordFPO6uJ5NXzzM1dwvLufJ184yL++eJB7vr8DA5bPruK65XUsn11FegVyEZFoFAgZevqTvLj/JHded0GhmxJJbVUZX/jgMr7wwWXsOnKKr/9oJy/sO8m3n9nLghkVfPDCetxdwSAikSgQMmzZc5zBIS+6+YMoLppbzY2XzOX6i2az7UAHv3i9jcef38/Bjl6+/sl3MH9G/hfpE5GpRZPKGX75ejvlJTGuXDKz0E0Zs0Q8xqqGWfz5jRfy0XfOY+ueE9x0/y/Z8Px+Xa4qIuekEUKGX73RxtVLaykviRe6KeeU7fLSkWJmXLOsjovm1vC9Fw+y/nvbefTZfXzqioXc+f6leWiliEw1CoTgcEcvu9t6+PRVhbtuP8ov+lzNqizl89ct5ZnmdjbtOMrfPf0G714ygysWT91RkIhMDp0yCn4dLjcdudT0+SBmxnUr6ln3gQsw4A/+77P81Y930Tc4VOimiUgRUSAAqZTz+PP7mTe9nAvnFH79osmyaNY07rp+BR9713z+bnMzv/+NX7Gl5XihmyUiRUKBAGzYeoBtBzr4i5suOu8v0awojfPXt13Oo5+/isGhFLc9+Bx3PPw8m187SkpLbIu8rb3t5xDau/v5+o92cvXSWXzyigWFbk7efODCejb92Qf4x1/t4TvP7ePz/9TE4lnTuPGSObynYSZXLplFffX4b87T+koiU8fbPhD+1w930js4xNc+cdl5PzoYaVppgj+5YQX/+UPL2LTjCPf/5HUeeWYvD/16DwCVZQlqK0uZVVnKjIoSqitKqClP8MkrFjBjWikzp5VSXZ6gJDx3ejImxUUkfyIFgpmtBv4WiAP/6O5fH/F5GfAocCVwHLjN3feGz+4G7gSGgD9x901RjpkPv36jne+9dIi7rl/O8tnV+f72RaMkHuMj75xPV2+S5FCKwx297DtxmrZT/ZzoGWBPew+n+gYZPqP0zyN+8cdjRkVJnJQ78ZgRMyMeMxIxoyQeozQRo7I0TmVZgqryBNNK4zTUVbK0tpLp086PtZc0EpLzwaiBYGZx4AHgRuAgsNXMGt391YxqdwIn3X25ma0F7gNuM7NLgLXApcB84KdmdmHYZ7RjTprO04N8Y/MbPPLMXpbUTuOuDy/Px7edEhLxGItrK1lc++anxaXc6elP0tWb5D1LZ9JxepCTpwfo6U/SOzhE32CKVw51knJnKAVDqRTJlJMccvqTQxzt6qdnoIfTA0P8bOexM8edN72ci+fVcPG8albOTX9tqK0kEZ+Y6a3vPLeP7v4kp3qT9Ayk2/qOBdPpHRhKt9Udw3jlUCcl8RglcaMsEaM0EacsEeMj75pHaTxGIh5jKOUkUymSQ07f4BCnB4boHRxicCjFS/tPngnERCxGSTzGywc6mF1TRl1V2ZlRlEgxizJCuApodvcWADPbAKwBMn95rwH+Z9h+Evimpc+/rAE2uHs/sMfMmsPxiHDMCdM7MMTutm6aj3Xz2pFTPLF1Px29g6x9zyK+fONFRX8jWjGImVFdXkJ1eQkfumh21jpRThkNDqW4dlkte9p72N3Ww2tHunit9RS/fL2NZBiClCZiLJ41jYbaaSyeVUl9dRm1VaXMmlZKeUmckriRiMcYHEqlw2hgiI7eQY5399PePcCxU320dvbR2tHHsVN9jJwrf2Lrgcj9/tYvdkeuO9Ijz+49s11fXcb8GRUsnFHB3OnlzKkpY05NObWVZdRUJJheUUJlWYKyRIyyRLqPb7dTmMXG3RlKOQNDKfoHUwwMpTg9MERPf/LM11P9STbvPMbgUOrMK+VwyfwaAEpiRllJ+j8XlWUJqsKrsiw9Uh7+WhqPUVYSozQeIx4r3N99lEBYAGT+CzoIXH22Ou6eNLNOoDaUPzdi3+GZ29GOOWF+729+yf4Tp4H06Y1rl9Vy980Xn/lLe7sp5Ln+kniMFXOqWTHnzafoHn1mL8dO9XOkq4+jnX0c7xlg+6FOftN8nN4c7peoKkswu6aM+dMruG5FHe2n+qmpKKGmvITKsjgVJXHKwz/AmBlm4A7JoRSDKWcwmf6H359MMZBMce3yWgaSKZKpFPFYjETMeKa5nZJE7MzIIRFOj8XMGEo5g6kUg8kUqxpm0dbdz7Gufg539HK4s5edrV1sfu1YpD7FjDO/HAwwAyPd5mGKjNxk/t8gcyUXx3EPnzskU6m3/EciCiP9n6dndqfvaxocGtuVe/GYEU//hZ/5u992z02T/p/Xop9UNrN1wLrwttvMdo33mC3Ad8Z7EKgD2sd/mKKQU19uH+c3G+/+o9lxfv3dwPnVn/OpL5DH/lR8dVy7L4lSKUogHAIWZbxfGMqy1TloZglgOunJ5XPtO9oxAXD3B4EHI7Qzr8ysyd1XFbodE+F86guoP8XsfOoLnH/9iTLTtRVYYWZLzayU9CRx44g6jcAdYfsWYLOnl9ZsBNaaWZmZLQVWAM9HPKaIiOTRqCOEMCdwF7CJ9CWiD7v7DjO7F2hy90bgIeCxMGl8gvQveEK975KeLE4CX3L3IYBsx5z47omISFSmNfLHxszWhdNZU9751BdQf4rZ+dQXOA/7o0AQERHQ4nYiIhIoEHJkZqvNbJeZNZvZ+kK3Jwoze9jMjpnZKxlls8zsJ2b2Rvg6M5SbmX0j9O+3ZnZF4Vr+Vma2yMyeNrNXzWyHmf1pKJ+q/Sk3s+fN7OXQn78M5UvNbEto9xPh4gvCBRpPhPItZtZQyPZnY2ZxM3vJzH4Q3k/lvuw1s+1mts3MmkLZlPxZi0KBkIOMZTxmponfAAAEJklEQVRuBi4BPh2W5yh2/wSsHlG2HviZu68AfhbeQ7pvK8JrHfCtPLUxqiTwX9z9EuC9wJfC38FU7U8/8GF3fxdwObDazN5LevmX+919OXCS9PIwkLFMDHB/qFds/hTYmfF+KvcF4Hp3vzzj8tKp+rM2OnfXK+ILuAbYlPH+buDuQrcrYtsbgFcy3u8C5oXtecCusP33wKez1SvGF/B90mtiTfn+ANOAF0nftd8OJEL5mZ870lfmXRO2E6GeFbrtGX1YSPqX5IeBH5C+0XZK9iW0ay9QN6Jsyv+sne2lEUJusi3jMVUfojDH3VvD9hFgTtieMn0MpxjeDWxhCvcnnGLZBhwDfgLsBjrcPRmqZLb5TcvEAMPLxBSLvwH+K5AK72uZun2B9GoWPzazF8KqCTCFf9ZGU/RLV8jkc3c3syl1uZmZVQH/CvyZu3dlLgY21frj6XtzLjezGcBTwMoCN2lMzOwjwDF3f8HMPlTo9kyQ69z9kJnNBn5iZq9lfjjVftZGoxFCbqIs4zFVHDWzeQDh6/Ca1EXfRzMrIR0G/+zu3wvFU7Y/w9y9A3ia9GmVGZZeBgbe3OYz/bE3LxNTDN4HfMzM9gIbSJ82+lumZl8AcPdD4esx0mF9FefBz9rZKBBycz4tuZG53MgdpM/FD5d/Llwx8V6gM2N4XHCWHgo8BOx097/O+Giq9qc+jAwwswrS8yE7SQfDLaHayP5kWyam4Nz9bndf6O4NpP9tbHb325mCfQEws0ozqx7eBm4CXmGK/qxFUuhJjKn2An4feJ30ed7/Xuj2RGzz/wNagUHS5zXvJH2u9mfAG8BPgVmhrpG+kmo3sB1YVej2j+jLdaTP6/4W2BZevz+F+/NO4KXQn1eAe0L5BaTX/WoG/gUoC+Xl4X1z+PyCQvfhLP36EPCDqdyX0O6Xw2vH8L/3qfqzFuWlO5VFRATQKSMREQkUCCIiAigQREQkUCCIiAigQBARkUB3Koucg5kNkb6EcNjH3X1vgZojMql02anIOZhZt7tXjWG/hP9u/R6RKUGnjERyZGYNZvYrM3sxvK4N5R8K5Y2knyOOmf1heN7BNjP7+7CEukhRUiCInFtF+GW+zcyeCmXHgBvd/QrgNuAbGfWvAP7U3S80s4vD5+9z98uBIeD2fDZeJBeaQxA5t97wyzxTCfBNMxv+JX9hxmfPu/uesH0DcCWwNazGWsHvFkITKToKBJHc/TlwFHgX6VF2X8ZnPRnbBjzi7nfnsW0iY6ZTRiK5mw60unsK+CxwtnmBnwG3hLX0h5/FuyRPbRTJmQJBJHf/B7jDzF4m/TCbnmyV3P1V4H+QfuLWb0k/DW1e3lopkiNddioiIoBGCCIiEigQREQEUCCIiEigQBAREUCBICIigQJBREQABYKIiAQKBBERAeD/A9iZ/O4PTemlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train_df['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f343bd9e978>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot('Sex', data=train_df, kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f33ff6ee160>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot('Who', data=train_df, kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7faad05e4b70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 437.975x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot('Pclass', data=train_df, hue='Sex', kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7faad043f128>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAFgCAYAAAAvjqe1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGUpJREFUeJzt3WuUZWV95/Hvj0YFQWm56UDT0AjoAK1cREGE6CjGmLBGHTUSBZcuE/GCEpc6ajKAZjQsYTKEW0CNQdQYw0SRSbxNYKF0g5cADSgiEbuhGxVQaBRHGKD/82LvltNFV3dVd9U5VfV8P2uddc5+nn35n1UvfvXss/d+UlVIktSCLUZdgCRJw2LoSZKaYehJkpph6EmSmmHoSZKaYehJkpph6EmSmmHoSZKaYehJkpph6EmSmjFnQy/Jlkn2SLLlqGuRJM0MczkQFgDLly9fPuo6JGlTZdQFzDVzdqQnSdJYhp4kqRmGniSpGYaeJKkZhp4kqRmGniSpGYaeJKkZhp4kqRmGniSpGYaeJKkZhp4kqRmGniSpGYaeJKkZc3mWBUlT7OD3XDi0Y1192nFDO5ba4UhPktQMQ0+S1AxDT5LUDENPktQMQ0+S1AxDT5LUDENPktQMQ0+S1AxDT5LUDENPktQMQ0+S1AxDT5LUDENPktSMoYVekouTXJfk2iRXJDmgb98nyVVJbu7f9x7YZtw+SZIma5gjvddX1TOr6kDgdOCTfft5wDlVtQ9wDnD+wDYb6pMkaVKGNp9eVd07sLgdsCbJzsBBwFF9++eAs5PsBGS8vqq6a3DfSeYD88cccsEUfwVJ0iw31Elkk3wCeDFdoL0E2A24vaoeBqiqh5P8pG/PBvruGrPrE4GTh/MtJEmz1VAvZKmqN1XVQuADwGlTuOszgEVjXkdM4f4lSXPAUEd6a1XVp5N8DFgF7JpkXj+SmwfsAqykG+mN1zd2f6uB1YNtSab9e0iSZpehjPSSbJtkt4Hlo4G7gTuBZcAxfdcxwLVVdVdVjds3jJolSXPPsEZ62wAXJdkGeJgu8I6uqkpyPPCpJCcB9wDHDWy3oT5JkiZlKKFXVXcAh47TdxPwnMn2SZI0WT6RRZLUDENPktQMQ0+S1AxDT5LUDENPktQMQ0+S1AxDT5LUDENPktQMQ0+S1AxDT5LUDENPktQMQ0+S1AxDT5LUDENPktQMQ0+S1AxDT5LUDENPktQMQ0+S1AxDT5LUDENPktQMQ0+S1AxDT5LUDENPktQMQ0+S1AxDT5LUDENPktQMQ0+S1AxDT5LUDENPktQMQ0+S1AxDT5LUDENPktQMQ0+S1AxDT5LUDENPktSMoYRekh2SfDnJD5PckOQLSXbq+yrJ9UmW9a/FA9sdneSmJD9K8vkkjx9GvZKkuWlYI70CPlpVT6uqxcAtwKkD/c+tqgP61w0ASbYFPg4cXVV7Ab8C3j2keiVJc9BQQq+q7q6qyweavgXsvpHNfg/4t6r69375POAP17dikvlJ9hh8AQs2r2pJ0lyz5bAPmGQL4C3AJQPNlyfZEvgKcEpVPQAsBG4dWOc2YLdxdnsicPI0lCtJmkNGcSHLWcB9wNn98sKqehZwJLAv8N82YZ9nAIvGvI7Y/FIlSXPJUEd6SU4H9qb7nW4NQFWt7N9/meQTwLv61W8DXjCw+UJg5fr2W1WrgdVjjjW1xUuSZr2hjfSSfAQ4GHhZf/qSJE9KsnX/eUvglcCyfpOvAock2btfPh74x2HVK0mae4Z1y8J+wPuBXYAr+1sTvgg8Hfh2kuuA64EH6U9vVtWvgD8B/jnJj4DtgNOHUa8kaW4ayunNqvo+MN75xmdsYLsvAV+alqIkSc3xiSySpGYYepKkZhh6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZgwl9JLskOTLSX6Y5IYkX0iyU993aJLrktyc5OtJdh7Ybtw+SZIma1gjvQI+WlVPq6rFwC3AqUm2AD4DvK2q9gG+CZwKsKE+SZI2xVBCr6rurqrLB5q+BewOHAzcX1VL+vbzgFf3nzfUJ0nSpG057AP2I7i3AJcAC4Fb1/ZV1c+TbJFk+w31VdXdY/Y5H5g/5lALpus7SJJmp1FcyHIWcB9w9hTu80Rg+ZjXFVO4f0nSHDDUkV6S04G9gaOrak2S2+hOc67t3xFYU1V3b6hvPbs+A7hgTNsCDD5J0oChhV6Sj9D9Tvf7VfVA33w1sHWS5/W/3R0PXDSBvnVU1Wpg9ZjjTcO3kCTNZkMJvST7Ae8Hbgau7ANpeVW9PMmxwPlJtgJWAK8D6EeC6+2TJGlTDCX0qur7wHqHXlV1JbB4sn2SJE2WT2SRJDXD0JMkNcPQkyQ1w9CTJDXD0JMkNcPQkyQ1w9CTJDXD0JMkNcPQkyQ1Y8Khl+Td47S/a+rKkSRp+kxmpHfSOO1/PhWFSJI03Tb67M0k/6n/OC/JC1j3GZp7Ar+ajsIkScOX5KPAPVX1l/3yJ4GnVtXv9MuvBl4DvLSqthpdpZtmIg+c/tv+fSvgkwPtBfwMOGGqi5IkjcwS4M0DywcAJHlMVT0IPK9f56UjqG2zbfT0ZlUtqqpFwGfXfu5fe1bVc6vqkiHUKUkajqXAoensRDdX6XeBg/r+taFHklOSLEtybZI9+7bHJfl4khuSXJ/kv4ziS4xnwr/pVdVxaz8n2WLwNT2lSZKGrap+AdwB7Ac8F7iSLggPT7It8FTgGuBxwPeq6gDg88Cf9rt4C7AN8Azg94AzkzxlqF9iAyZz9eZBSa5K8mvgwf71UP8uSZo7ltCN6A6nC7wr+8+HAVdX1UPAw8AX+/W/CyzqP/8O8Knq3A5cATx7iLVv0GQmkf0U8L+BNwL/d3rKkSTNAEuAFwO7Ax+pqtVJ9mLg1CbwUFU93H9+mPHzpKa10kmazKnJ3YE/q6ofVNWtg6/pKk6SNBJLgOcDW1fV6r5tOfA6Hgm98XwDOLb/TXAX4Ajg29NV6GRNJvS+SJf8kqQ5rKp+THd72tUDzUvpBj9XbWTzvwF+A1wPfBV4Z1XdMR11borJnN7cCvhikiV0tyr81uBFLpKk2a+qdh2zfBpw2sDyVgOfLwcu7z8/APzxUIrcBJMJvRv7lyRJs9KEQ6+qPjidhUiSNN0mHHoDjyN7lKq6bGrKkSRp+kzm9ObfjlneCXgssIruGZySJM1okzm9uWhwOck8uhkWfOC0JGlW2ORHiPU3JX4YeO/UlSNJ0vSZzOnN9TkKWDMVhUiSNu7g91w4LU84ufq047LxtWa/yVzIspJ1HyfzeLp799461UVJkjQdJjPSe92Y5V8DN1fVL6ewHkmSps1kLmT5BnTTCgFPBu6oKk9tSlJDkhTdRYwvA3age/rKi4CXAI8BXlVVP+inE/oc8ES6s4L/UlXv7fdxCvA0YDu6q/9v6beb9skMJjO10BOSXEj3TLXbgd8k+VSS7aatOknSTLS6qg4B/ivwJWBpVR0IXAj82dp1gKOr6mC62defleQlA/t4FvBHwH+kC8vXDqPwyVy9eRbdxICLga3798cDZ05DXZKkmevz/fs1QFXVP/fLVwN79Z/nAaclua5v358u/Nb6WlWtrqqim4XhqdNf9uR+03sJsOfA8PPmJG+gG5ZKktpxf//+MPDAQPvgvHrvAp4EPKeq7k/yMbrTnGP3sXa7raep1nVMZqR3P91TWAbtyLpfWJIkgPnAT/vA2xX4z6MuCCY30vsE8H+S/BVwK928Sn8KfHw6CpMkPdosup/uTOCiJN+je1zlpSOuB5hc6H2Y7gKW1wK7AD8BPlpVY5/JKUmao6oqA59X0J3xW7t8Od0FKlTVrcCzx9nHKRtank6TOb3518APq+pFVbVvVb0I+EGSMyaycZLTkyxPUkn2H2hfkeSmJMv61+8O9B2a5LokNyf5epKdJ1GvJEnrmEzoHQP825i2q+kuOZ2Ii4Ej6U6NjvXKqjqgf30Nfns/4GeAt1XVPsA3gVMnUa8kSeuYzOnNorsEddA8JhicVbUEIJnw6eiDgfvXbgecB6wA3jh2xSTz6X40HbRgogeSJLVhMiO9K4C/6Edga0dip/Ttm+uzSa5Pcm4fYAALGRgVVtXPgS2SbL+e7U8Elo95TUVdkqQ5ZDKh9066R838NMl36C5kOQo4YTNrOKKqngkcAgQ4exP2cQawaMzriM2sS5I0x0zm2ZurkhxEdzXObsBK4Dub+/zNqlrZvz+Q5Fzgkr7rNrrbIgBIsiOwpqruXs8+VtM98oaB9TenLEnSHDSp+fT6gPtW/9psSbYBtqyqe9Ol1GuAZX331cDWSZ7X/653PHDRVBxXkmar2z60eFrm01t40g1NjBQ2dxLZCUtyJvAK4CnAvyb5BXA08E9J5tFdFHMj/fx8VbUmybHA+Um2oruIZez0RpIkTdjQQq+q3gG8Yz1dB25gmyvpHmwtSRqxJG8GnlFVb0vybLoHRT+7qr7b/zy1jO6nqb+kG8jcBby5qn6U5Pl093t/BzgUeBA4FjiZ7mHUK4FXVNWvk7wQ+O90z+rcEvhwVf1DX8PlwHeBw+gelPKPVfW+iX6HyVzIIklq26XAC/vPLwSuGrN8HfBp4LVV9Qzg74HPDmy/L3BOVS3ut/0a8K6q2pfuodPH9OtdAzyvn67oRcDpSZ40sJ+FdPd9Hwi8KcneE/0Chp4kaUKq6kd011osoAu5DwAvTLIb8DhgZ+C6qrqx3+TvgAOSPKFf/mFVrb1u4xpgWVWt6pcHpyXaCfhf/XM7vwZsTzfp7FoXVdWaqroX+AGTmJbI0JMkTcZlwB8AT+6ftfkfgN/v2zdm7HRCY5fX/uT2N8DlwOKqOoDugdUbmpZowj/VGXqSpMm4FHgfsLRfXtovX0p3Zf8zkzy973s9cG1V/WqSx5gPrKiqSnIUj4wAN9vQLmSRJG2+GXBrwWV091CvnSroUuBPgMuq6q7+qvu/T7Il3YUsm3LV/fuAc5N8kO6iles3v+xOupna554kewDLly9fzh577DHaYqQ54uD3XDi0Y1192nFDO9YMNuqAm3M8vSlJaoahJ0lqhqEnSWqGoSdJaoahJ0lqhqEnSWqG9+lJ0ixy+FmHT8t9ZktPWNrE7RGO9CRJmyXJiiT7j9P35SRP7T9fnuQPxlnvgiRvn846wZGeJGkaVdVLR13DIEd6kqQJS3JYkiVJrutfL+67Xp3kqn7U9/aB9dc7Ckyya5JLk9yY5MvAjsOo35GeJGlCkmwPfJFustcrk8wDnth3P76qDusfAfm9JBdU1X0b2N2ZwDer6oNJ9qSbi++r01g+4EhPkjRxhwE3VtWVAFX1cFXd0/f9Q9+2ArgHWLCRfb0A+ES/zY955AHW08rQkyRNhU2e426YDD1J0kRdBeyb5DCAJPOSPGkT93UZ8IZ+P4voZmKfdjMyiSVJ6zfK++mq6u4krwD+Ksk2wBrg3Zu4u3cCFyb5I2A53Uzp087QwznCJGmi+t/zDhvTvMeYdfYY5/PzBz7fzpBGd4M8vSlJaoahJ0lqhqEnSWqGoSdJaoYXskiakW770OKhHm/hSTcM9XgaDUd6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYMJfSSnJ5keZJKsv9A+z5Jrkpyc/++90T6JEnaFMMa6V0MHAncOqb9POCcqtoHOAc4f4J9kiRN2lAeQ1ZVSwCSR+Y+TLIzcBBwVN/0OeDsJDsBGa+vqu4au/8k84H5Y5oXTOV3kCTNfqN89uZuwO1V9TBAVT2c5Cd9ezbQ96jQA04ETh5O2ZKk2WquPHD6DOCCMW0LgCuGX4qmijPaS5pqowy9lcCuSeb1I7l5wC59ezbQ9yhVtRpYPdg2eCpVkiQY4S0LVXUnsAw4pm86Bri2qu7aUN/wK5UkzRXDumXhzCSr6E45/muS7/ddxwMnJLkZOKFfZgJ9kiRN2rCu3nwH8I71tN8EPGecbcbtkyRpU/hEFklSMww9SVIz5sotC7PGbR9aPLRjLTzphqEdS5JmA0d6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZhh6kqRmGHqSpGYYepKkZmw56gKkmeC2Dy0e2rEWnnTD0I4laV2O9CRJzTD0JEnNMPQkSc0w9CRJzTD0JEnNMPQkSc3wlgVJAg4/6/ChHWvpCUuHdiyty5GeJKkZhp4kqRmGniSpGTMi9JKsSHJTkmX963f79kOTXJfk5iRfT7LzqGuVJM1eMyL0eq+sqgP619eSbAF8BnhbVe0DfBM4dbQlSpJms5l89ebBwP1VtaRfPg9YAbxx7IpJ5gPzxzQvmNbqJEmzzkwKvc8mCbAE+ACwELh1bWdV/TzJFkm2r6q7x2x7InDy8EqVJM1GM+X05hFV9UzgECDA2ZPc/gxg0ZjXEVNaoSRp1psRI72qWtm/P5DkXOAS4K+B3deuk2RHYM16RnlU1Wpg9WBbN2iUJOkRIx/pJdkmyXb95wCvAZYBVwNbJ3lev+rxwEWjqVKSNBfMhJHek4F/SjIPmAfcCLy1qtYkORY4P8lWdBexvG50ZUqSZruRh15V/Rg4cJy+K4HFw61IkjRXjfz0piRJw2LoSZKaYehJkpph6EmSmmHoSZKaYehJkpph6EmSmmHoSZKaYehJkpph6EmSmmHoSZKaYehJkpph6EmSmmHoSZKaYehJkpph6EmSmmHoSZKaYehJkpph6EmSmmHoSZKaYehJkpph6EmSmrHlqAuQWnP4WYcP7VhLT1g6tGNJs4EjPUlSMww9SVIzDD1JUjMMPUlSMww9SVIzDD1JUjMMPUlSMww9SVIzDD1JUjMMPUlSM3wM2Rzm464kaV2O9CRJzZjxoZdknyRXJbm5f9971DVJkmanGR96wHnAOVW1D3AOcP6I65EkzVIz+je9JDsDBwFH9U2fA85OslNV3TWw3nxg/pjNdwdYtWrVRo/zwL13bXSdqbLyof83tGPdv+b+oR1rxYoVU75P/y6bb6r/LnP1bwIz8++yaNGiPYBVVfXQ9FXTllTVqGsYV5KDgQurar+BthuB11XVNQNtpwAnD79CSZp2i6pqxaiLmCtm9EhvEs4ALhjT9lhgT+DfgYeHXdAUWwBcARwBbHzoqmHwbzIzzcW/y1z5HjPCTA+9lcCuSeZV1cNJ5gG79O2/VVWrgdXr2f7mIdQ47ZKs/bjK//hmBv8mM5N/F23MjL6QparuBJYBx/RNxwDXDv6eJ0nSRM30kR7A8cCnkpwE3AMcN+J6JEmz1IwPvaq6CXjOqOuQJM1+M/r0pn5rNfBB1v+7pUbDv8nM5N9FGzSjb1mQJGkqOdKTJDXD0JMkNcPQkyQ1w9CbwZKcnmR5kkqy/6jrUSfJDkm+nOSHSW5I8oUkO426rtYluTjJdUmuTXJFkgNGXZNmHkNvZrsYOBK4ddSFaB0FfLSqnlZVi4FbgFNHXJPg9VX1zKo6EDgd+OSoC9LMY+jNYFW1pKpWbnxNDVNV3V1Vlw80fYt+Vg+NTlXdO7C4HbBmVLVo5prxN6dLM1mSLYC3AJeMuhZBkk8ALwYCvGTE5WgGcqQnbZ6zgPuAs0ddiKCq3lRVC4EPAKeNuh7NPIaetImSnA7sDfxhVXkqbQapqk8DL0iyw6hr0cxi6EmbIMlHgIOBl1XVA6Oup3VJtk2y28Dy0cDd/Uv6LR9DNoMlORN4BfAU4OfALwZnkddoJNkP+B7dfI2/6ZuXV9XLR1dV25I8GfgSsA3dpNF3A++uqmtGWphmHENPktQMT29Kkpph6EmSmmHoSZKaYehJkpph6EmSmmHoSROQ5PlJVo26Dkmbx9BTk5KsSPKbJPcluSPJBUm2HXVdkqaXoaeWHV1V2wIHAc8C/nzE9UiaZoaemldVtwNfAfZPsn2Sv0vykyT3JLl4fdskeV+SW5L8KsmNSV4+0LdXkm8kuTfJz5N8vm9Pkv+Z5M4kv+wnoHVyYGmInFpIzeuf2fhS4AvAp+lmTdivf3/uOJvdAhwB/Ax4FfCZJHtV1U+BvwC+DrwAeCzdKBK6KW+OBPYB7gWeDqyehq8kaRyGnlp2cZKH6ALoX4BzgduBHarqnn6db6xvw6q6aGDx80neDzyb7vmPD9JNKrtLVa0ClvTrPQg8gS7svlNVP5ji7yNpIzy9qZa9rKrmV9XuVfVWYDfg7oHAG1eS45IsS7I6yWpgf2DHvvu9dJOYfifJ95O8EaCqLqObd+8c4M4kH0vyxOn4YpLWz9CTHrES2D7J/A2tlGR34OPA2+lGhfPpZl0IQFX9rKr+uKp2Ad4MnJtkr77vzKo6GNiX7jTne6bt20h6FENP6vW/x32FLqSelOQxSY5cz6rbAAXcBZDkDXQjPfrlVyVZ0C/e06+7JskhSZ6T5DHAr4H7ASeflYbI0JPWdSzdb283AXcCJ45doapuBP4HcBVwB7AYWDqwyiHAt5PcB1wCvLOqfgw8kW6EeA9wK/AL4LRp+yaSHsX59CRJzXCkJ0lqhqEnSWqGoSdJaoahJ0lqhqEnSWqGoSdJaoahJ0lqhqEnSWrG/wcRefxVvUNbfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 439.85x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot('Pclass', data=train_df, hue='Who', kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f33ff75b940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAFgCAYAAAA8WedBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFZBJREFUeJzt3X+0ZlV93/H3BwaklQgiU4uAwUaSFESxzDIKMTEQu9BScRkgEhN+hFWaLjRaf4UmLn/VZMXaSJBUWyrKwLIExCoUs9AUHEVAcVBk+BHNVFEGiQw/FRPUwW//OPvKk2GYeZi55z737nm/1rprztlnn3O/D+uu9WGfc569U1VIktSDHWZdgCRJ88VQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHVj2awL2BZHHnlkXX755bMuQ5LGkFkXsBQt6ZHa3XffPesSJEmLyJIONUmSJhlqkqRuGGqSpG4YapKkbhhqkqRuGGqSpG4YapKkbhhqkqRuGGqSpG4YapKkbhhqkqRuGGqSpG4s6Vn6t9Uhbzpv1iVs0fXvOWHWJUjSkuFITZLUDUNNktQNQ02S1A1DTZLUDUNNktQNQ02S1A1DTZLUDUNNktQNQ02S1A1DTZLUDUNNktQNQ02S1A1DTZLUDUNNktQNQ02S1A1DTZLUDUNNktQNQ02S1A1DTZLUDUNNktQNQ02S1A1DTZLUDUNNktQNQ02S1A1DTZLUDUNNktQNQ02S1A1DTZLUjdFDLcmOSb6S5LK2/4wkX0yyNsmFSXZu7U9o+2vb8f3Grk2S1JeFGKm9Frh1Yv/dwBlV9UzgPuCU1n4KcF9rP6P1kyRpaqOGWpJ9gH8DfLDtBzgcuLh1WQm8vG0f3fZpx49o/SVJmsrYI7U/B94M/KTtPwW4v6o2tP11wN5te2/gdoB2/IHW/x9JcmqS1UlWr1+/fszaJUlLzGihluQo4K6qun4+r1tVZ1fViqpasXz58vm8tCRpiVs24rUPA16W5KXALsCTgDOB3ZMsa6OxfYA7Wv87gH2BdUmWAbsB94xYnySpM6ON1KrqP1XVPlW1H/BK4MqqehXwGeCY1u1E4JK2fWnbpx2/sqpqrPokSf2ZxffU/gB4fZK1DM/Mzmnt5wBPae2vB06fQW2SpCVszNuPP1VVq4BVbfsbwPM20ech4NiFqEeS1CdnFJEkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdWO0UEuyS5Lrknw1yc1J3tHan5Hki0nWJrkwyc6t/Qltf207vt9YtUmS+jTmSO2HwOFV9RzgYODIJM8H3g2cUVXPBO4DTmn9TwHua+1ntH6SJE1ttFCrwYNtd6f2U8DhwMWtfSXw8rZ9dNunHT8iScaqT5LUn1GfqSXZMckNwF3AXwP/D7i/qja0LuuAvdv23sDtAO34A8BTNnHNU5OsTrJ6/fr1Y5YvSVpiRg21qnq4qg4G9gGeB/ziPFzz7KpaUVUrli9fvs01SpL6sSBvP1bV/cBngBcAuydZ1g7tA9zRtu8A9gVox3cD7lmI+iRJfRjz7cflSXZv2/8EeDFwK0O4HdO6nQhc0rYvbfu041dWVY1VnySpP8u23GWr7QWsTLIjQ3heVFWXJbkF+Msk7wK+ApzT+p8DnJ9kLXAv8MoRa5MkdWi0UKuqG4HnbqL9GwzP1zZufwg4dqx6JEn9c0YRSVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUnaziU5I8nrJvY/leSDE/t/luT1SS6bTYXTM9QkSVcDhwIk2QHYEzhw4vihwM4zqOtxmyrUklwxTZskaUm6BnhB2z4QuAn4fpInJ3kC8C+BLwO7Jrk4yd8k+UiSACQ5IslXkqxJ8qF2zkxsNtSS7JJkD2DP9uH2aD/7AXsvRIGSpHFV1XeADUmezjAquxb4IkPQrQDWAD8Cngu8DjgA+BfAYUl2Ac4FfrOqDgKWAf9hoT/DnGVbOP7vGT7A04DrgbT27wF/MWJdkqSFdQ1DoB0KvJdh4HIo8ADD7UmA66pqHUCSG4D9gO8D36yqr7c+K4HTgD9fsMonbDbUqupM4Mwkr6mqsxaoJknSwpt7rnYQw+3H24E3MAxiPtz6/HCi/8NseWC04KYqqKrOSnIoQyovm2g/b6S6JEkL6xrgjcA3quph4N4kuzM8Y/t3wLMe47yvAfsleWZVrQV+B/jsQhS8KVOFWpLzgZ8DbmBIZ4ACDDVJ6sMahrce/9dGbbtW1d3tnZBHqaqHkpwMfDTJMuBLwH8fu9jHMu3QcQVwQFXVmMVIkmajjc6etFHbSRPbq4BVE/uvnti+guElkpmb9ntqNwH/fMxCJEnaVtOO1PYEbklyHRMPCqvqZaNUJUnSVpg21N4+ZhGSJM2Had9+nNmbLJIkTWvatx+/z/C2Iwzzf+0E/KCqnvTYZ0mStLCmHan9zNx2m+vraOD5YxUlSdLWeNzfBm+v9X8iyduA0+e/JEnSphzypvPm9WtV17/nhE1/+WwJm/b24ysmdndg+N7aQ6NUJEnSVpp2pPZvJ7Y3ALcx3IKUJHWsrcpyOfAFhrkhv8QwF+Q7gH8GvKp1PRPYBfgH4OSq+lqSk4CXAf+UYVaqj1fVm8esd9pnaiePWYQkaVF7JnAs8LsMofZbwC8zBNYfAicAL6yqDUl+HfgT4DfauQczzDbyQ+BrSc6qqtvHKnTa24/7AGcBh7Wmq4DXzi1BIEnq2jerag1AkpuBK6qqkqxhmOh+N2Blkv0Z3pTfaeLcK6rqgXbuLcDPMqwAMIppp8n6MHApw7pqTwP+D48sRSBJ6tvkkjM/mdj/CcPg6D8Dn6mqZzE8rtrlMc4dfbmaaUNteVV9uKo2tJ9zgeUj1iVJWjp2A+5o2yfNsI6pE/OeJL8NXND2jwfuGackSdKmLOJX8P8Lw+3HtwCfnGUh04ba7zI8UzuD4X7pNcw4jSVJ46uq25hYIHSj5Wgmj/38xGlvacfPBc6d6H/UWHXOmTbU3gmcWFX3ASTZA/ivDGEnSdKiMO0ztWfPBRpAVd3LIlkQTpKkOdOG2g5Jnjy300Zqo77BIknS4zVtMP0ZcG2Sj7b9Y4E/HqckSZK2zrQzipyXZDVweGt6RVXdMl5ZkiQ9flPfQmwhZpBJkhYtn4tJ0hLx7XceNK9Lzzz9rWsW6/fettq0L4pIkrToGWqSpMeU5E1Jfr9tn5HkyrZ9eJKPJDk+yZokNyV598R5DyZ5T5Kbk/zfJM9LsirJN5K8rPXZL8lVSb7cfg5t7S9qfS9O8jft90w1qhzt9mOSfYHzgKcyzEJydlWd2b4OcCHDzM63AcdV1X2t4DOBlwJ/D5xUVV8eqz5Jj/btdx406xKm8vS3rpl1CduTq4A3AO9jWCD6CUl2Al4IfB14N3AIcB/w6SQvr6pPAE8ErqyqNyX5OPAu4MXAAcBKhkny7wJeXFUPtRn+L2i/A4bvQh8IfAe4mmGVmM9vqdgxR2obgDdU1QHA84HTkhwAnM6wFMH+wBVtH+AlwP7t51TgAyPWJkmazvXAIUmexDDj/rUMwfNC4H5gVVWtr6oNwEeAX2nn/YhhcVGANcBnq+rHbXu/1r4T8D/bEjYfZQi8OddV1bqq+glww8Q5mzVaqFXVnXMjrar6PnArsDfDitkrW7eVwMvb9tHAeTX4ArB7kr3Gqk+StGUtiL7JMN/vNQwjt19jWDj0ts2c+uOqmnux5afL1bSQmrtL+B+B7wLPYQjKnSfO36olaxbkmVpbDvy5wBeBp1bVne3Q3zHcnoQh8CYXjlvX2ja+1qlJVidZvX79+tFqliT91FXAG4HPte3fA74CXAf8apI9k+zIsILLZx/HdXcD7mxB9zvAjtta6Oiv9CfZFfgY8Lqq+t7ks762curjekW1qs4GzgZYsWLFvL7eKkmL2Qxfwb8K+CPg2qr6QZKHgKuq6s4kpwOfAQJ8sqoueRzXfT/wsSQnMNyq/MG2FjpqqLWHiR8DPlJV/7s1fzfJXu0/xl4MDwphWGBu34nT9+GRReckSTNSVVcwPP+a2//5ie0LeGStzclzdp3YfvumjlXV3wLPnjj0B619FbBqov+rp611tNuP7W3Gc4Bbq+q9E4cuBU5s2ycCl0y0n5DB84EHJm5TSpK0RWOO1A5juEe6JskNre0PgT8FLkpyCvAt4Lh27K8YXudfy/BK/8kj1iZJ6tBooVZVn2e4x7opR2yifwGnjVWPJKl/zigiSeqGoSZJ6oahJknqhkvPSNIScdhZh83rd3Ovfs3VW/W9tyTnApdV1cUbtT8NeF9VHZPkRcAbq+qoTZx/G7Ciqu7emt+/OYaaJGleVNV3gGNmWYO3HyVJm5XkhCQ3JvlqkvNb868kuaYtJXNM67dfkps2cf5Tkny6LUPzQR77zfhtZqhJkh5TkgOBtwCHV9VzgNe2Q3sBvwwcxfD94815G/D5qjoQ+Djw9JHK9fajJGmzDgc+Ovf8q6rubXP4fqJNRHxLkqdu7gIMy9G8op3/yST3jVWsIzVJ0taYXBpmVhMtP4qhJknanCuBY5M8BSDJHltxjc8Bv9XOfwnw5Pkr7x/z9qMkLRFb+wr+tqiqm5P8MfDZJA8zrKP2eL0DuCDJzQwLjX57PmucZKhJkjarqlYCKzdzfG4pmduAZ7XtVbTlY6rqHuBfj1wm4O1HSVJHDDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3DDVJUjcMNUlSNww1SVI3Rgu1JB9KcleSmyba9kjy10n+tv375NaeJO9LsjbJjUn+1Vh1SZL6NeZI7VzgyI3aTgeuqKr9gSvaPsBLgP3bz6nAB0asS5LUqdFCrao+B9y7UfPRwMq2vRJ4+UT7eTX4ArB7kr3Gqk2S1KeFfqb21Kq6s23/HfDUtr03cPtEv3Wt7VGSnJpkdZLV69evH69SSdKSM7MXRaqqgNqK886uqhVVtWL58uUjVCZJWqoWOtS+O3dbsf17V2u/A9h3ot8+rU2SpKktdKhdCpzYtk8ELploP6G9Bfl84IGJ25SSJE1l2VgXTnIB8CJgzyTrgLcBfwpclOQU4FvAca37XwEvBdYCfw+cPFZdkqR+jRZqVXX8Yxw6YhN9CzhtrFokSdsHZxSRJHXDUJMkdWO024+SHnHIm86bdQlT+fjPzLoCads4UpMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNQkyR1w1CTJHXDUJMkdcNZ+he5b7/zoFmXMJWnv3XNrEuQJEdqkqR+GGqSpG4YapKkbhhqkqRuGGqSpG4YapKkbhhqkqRuGGqSpG4YapKkbhhqkqRuOE2WpCXnsLMOm3UJW3T1a66edQnbJUdqkqRuGGqSpG4YapKkbhhqkqRuGGqSpG4YapKkbhhqkqRuGGqSpG4YapKkbjijiOaFMzxIWgwcqUmSumGoSZK6YahJkrphqEmSumGoSZK6YahJkrphqEmSumGoSZK6YahJkrphqEmSumGoSZK6YahJkrphqEmSumGoSZK6YahJkrphqEmSumGoSZK6YahJkrqxqEItyZFJvpZkbZLTZ12PJGlpWTShlmRH4L8BLwEOAI5PcsBsq5IkLSWLJtSA5wFrq+obVfUj4C+Bo2dckyRpCVk26wIm7A3cPrG/DviljTslORU4te0+mORrC1DbzPzsOJfdE7h7nEsvXvn9zLqERc+/t/kzD39vl1fVkfNRy/ZkMYXaVKrqbODsWdexlCVZXVUrZl2Htg/+vWkhLabbj3cA+07s79PaJEmaymIKtS8B+yd5RpKdgVcCl864JknSErJobj9W1YYkrwY+BewIfKiqbp5xWb3y9q0Wkn9vWjCpqlnXIEnSvFhMtx8lSdomhpokqRuG2nbEaci0kJJ8KMldSW6adS3afhhq2wmnIdMMnAv45WEtKENt++E0ZFpQVfU54N5Z16Hti6G2/djUNGR7z6gWSRqFoSZJ6oahtv1wGjJJ3TPUth9OQyape4badqKqNgBz05DdClzkNGQaU5ILgGuBX0iyLskps65J/XOaLElSNxypSZK6YahJkrphqEmSumGoSZK6YahJkrphqKlbSf4oyc1JbkxyQ5Jfmodrvmy+VjhI8uB8XEfSI3ylX11K8gLgvcCLquqHSfYEdq6q70xx7rL2vb6xa3ywqnYd+/dI2xNHaurVXsDdVfVDgKq6u6q+k+S2FnAkWZFkVdt+e5Lzk1wNnJ/kC0kOnLtYklWt/0lJ/iLJbkm+lWSHdvyJSW5PslOSn0tyeZLrk1yV5Bdbn2ckuTbJmiTvWuD/HtJ2wVBTrz4N7Jvk60nen+RXpzjnAODXq+p44ELgOIAkewF7VdXquY5V9QBwAzB33aOAT1XVj4GzgddU1SHAG4H3tz5nAh+oqoOAO7f5E0p6FENNXaqqB4FDgFOB9cCFSU7awmmXVtU/tO2LgGPa9nHAxZvofyHwm237le137AocCnw0yQ3A/2AYNQIcBlzQts9/XB9I0lSWzboAaSxV9TCwCliVZA1wIrCBR/5nbpeNTvnBxLl3JLknybMZguv3NvErLgX+JMkeDAF6JfBE4P6qOvixytrKjyNpCo7U1KUkv5Bk/4mmg4FvAbcxBBDAb2zhMhcCbwZ2q6obNz7YRoNfYriteFlVPVxV3wO+meTYVkeSPKedcjXDiA7gVY//U0naEkNNvdoVWJnkliQ3MjwvezvwDuDMJKuBh7dwjYsZQuiizfS5EPjt9u+cVwGnJPkqcDNwdGt/LXBaGzW66rg0Al/plyR1w5GaJKkbhpokqRuGmiSpG4aaJKkbhpokqRuGmiSpG4aaJKkb/x/kYiXEJnY5NQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432.25x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot('Survived', data=train_df, hue='Who', kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f33fd552358>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAFgCAYAAACCD78cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFmNJREFUeJzt3X+QZWWd3/H3BwbBFRRYOmScmUTiTrQAdZBeYJ2tCsGYHY1Z2M1CIK6goXakClmtck3UTQQtSW3KHxRipHYskB/lAiNomFgEl/Bj0VkFGzMMM6BxorDM7Mg0ICCry2Zmv/njnpZetum+PdPPvd0z71fVrT7nOc9z7reprvnwnPPcc1NVSJLUyn7DLkCStHczaCRJTRk0kqSmDBpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkppaNOwC9sSqVavq1ltvHXYZktRahl3AnljQM5rHH3982CVIkmawoINGkjT/GTSSpKYMGklSUwaNJKkpg0aS1JRBI0lqyqCRJDVl0EiSmjJoJElNGTSSpKYMGklSUwaNJKmpBf30Zs0vKy9bOewS+rL+gvXDLkHapzijkSQ1ZdBIkpoyaCRJTRk0kqSmDBpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkpoyaCRJTRk0kqSmDBpJUlPNgibJQUnuTXJ/ks1JPta1X5XkR0k2dK8VXXuSfDbJliQbk7yxVW2SpMFp+TUBzwGnVNWzSQ4Avpnkf3bHPlhVN76g/1uB5d3rRODy7qckaQFrNqOpnme73QO6V00z5FTgmm7ct4FDkyxuVZ8kaTCa3qNJsn+SDcAO4Laquqc7dHF3eeySJAd2bUuARycN39q1vfCcq5OMJRkbHx9vWb4kaQ40DZqq2lVVK4ClwAlJjgU+DLwW+FXgcOA/zvKca6pqtKpGR0ZG5rxmSdLcGsiqs6p6CrgTWFVV27vLY88BXwRO6LptA5ZNGra0a5MkLWAtV52NJDm0234p8BbgexP3XZIEOA3Y1A1ZB5zdrT47CXi6qra3qk+SNBgtV50tBq5Osj+9QFtbVV9LckeSESDABuC8rv8twNuALcDPgHc3rE2SNCDNgqaqNgLHTdF+yov0L+D8VvVIkobDJwNIkpoyaCRJTRk0kqSmDBpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkpoyaCRJTRk0kqSmDBpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkpoyaCRJTRk0kqSmDBpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkpoyaCRJTRk0kqSmDBpJUlMGjSSpKYNGktRUs6BJclCSe5Pcn2Rzko917UcluSfJliQ3JHlJ135gt7+lO/6qVrVJkgan5YzmOeCUqnoDsAJYleQk4L8Cl1TVrwA/Ac7t+p8L/KRrv6TrJ0la4JoFTfU82+0e0L0KOAW4sWu/Gjit2z6126c7/uYkaVWfJGkwmt6jSbJ/kg3ADuA24P8CT1XVzq7LVmBJt70EeBSgO/408MtTnHN1krEkY+Pj4y3LlyTNgaZBU1W7qmoFsBQ4AXjtHJxzTVWNVtXoyMjIHtcoSWprIKvOquop4E7g14BDkyzqDi0FtnXb24BlAN3xVwBPDKI+SVI7LVedjSQ5tNt+KfAW4CF6gfM7XbdzgJu77XXdPt3xO6qqWtUnSRqMRTN32W2LgauT7E8v0NZW1deSPAhcn+QTwP8Gruj6XwFcm2QL8CRwZsPaJEkD0ixoqmojcNwU7T+kd7/mhe1/DZzeqh5J0nD4ZABJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkpoyaCRJTRk0kqSmDBpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkpoyaCRJTRk0kqSmDBpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkpoyaCRJTRk0kqSmDBpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkppqFjRJliW5M8mDSTYneV/XflGSbUk2dK+3TRrz4SRbknw/yW+0qk2SNDiLGp57J/CBqvpukkOA+5Lc1h27pKo+NblzkqOBM4FjgFcC/yvJP62qXQ1rlCQ11mxGU1Xbq+q73fZPgYeAJdMMORW4vqqeq6ofAVuAE1rVJ0kajIHco0nyKuA44J6u6b1JNia5MslhXdsS4NFJw7YyRTAlWZ1kLMnY+Ph4w6olSXOhedAkORi4CXh/VT0DXA68GlgBbAc+PZvzVdWaqhqtqtGRkZE5r1eSNLeaBk2SA+iFzJeq6isAVfVYVe2qqr8FvsDzl8e2AcsmDV/atUmSFrCWq84CXAE8VFWfmdS+eFK33wI2ddvrgDOTHJjkKGA5cG+r+iRJg9Fy1dlK4J3AA0k2dG0fAc5KsgIo4GHgPQBVtTnJWuBBeivWznfFmSQtfM2Cpqq+CWSKQ7dMM+Zi4OJWNUmSBs8nA0iSmjJoJElNGTSSpKYMGklSUwaNJKkpg0aS1JRBI0lqyqCRJDVl0EiSmjJoJElNGTSSpKYMGklSUwaNJKkpg0aS1JRBI0lqyqCRJDVl0EiSmjJoJElNGTSSpKYMGklSUwaNJKkpg0aS1JRBI0lqyqCRJDVl0EjSApdkV5INSTYl+XKSX5qm70VJ/mCQ9Rk0krTw/byqVlTVscDfAOcNu6DJ+gqaJLf30yZJGrpvAL8CkOTsJBuT3J/k2hd2TPJ7Sb7THb9pYiaU5PRudnR/kru7tmOS3NvNnDYmWd5vQYumO5jkIOCXgCOSHAakO/RyYEm/byJJai/JIuCtwK1JjgH+E/Cmqno8yeFTDPlKVX2hG/sJ4FzgMuCjwG9U1bYkh3Z9zwMuraovJXkJsH+/dU0bNMB7gPcDrwTu4/mgeQb4XL9vIklq6qVJNnTb3wCuoPfv95er6nGAqnpyinHHdgFzKHAw8PWufT1wVZK1wFe6tm8Bf5hkKb2A+kG/xU0bNFV1KXBpkguq6rJ+TypJGqifV9WKyQ1JXqzvZFcBp1XV/UneBZwMUFXnJTkR+FfAfUmOr6o/SXJP13ZLkvdU1R39vElf92iq6rIkb0ry77prfmcnOXu6MUmWJbkzyYNJNid5X9d+eJLbkvyg+3lY154kn02ypbv+98Z+apMkTekO4PQkvwy9f3un6HMIsD3JAcA7JhqTvLqq7qmqjwLjwLIk/wT4YVV9FrgZeH2/hfS7GOBa4FPArwO/2r1GZxi2E/hAVR0NnAScn+Ro4EPA7VW1HLi924fedcXl3Ws1cHm/v4Qk6e+qqs3AxcCfJbkf+MwU3f4zcA+9S2Xfm9T+ySQPJNkE/DlwP3AGsKm7RHcscE2/taSqZu6UPAQcXf10fvFz3Ezvvs7ngJOranuSxcBdVfWaJH/cbV/X9f/+RL8XO+fo6GiNjY3tbkmaYysvWznsEvqy/oL1wy5Bmq2+roPNV/1+jmYT8A93902SvAo4jl5yHjkpPH4MHNltLwEenTRsK1OsbEuyOslYkrHx8fHdLUmSNCAzrTqbcATwYJJ7gecmGqvqN2camORg4Cbg/VX1zOQbVFVVSWY1S6qqNcAa6M1oZjNWkjR4/QbNRbtz8u4G003Al6pqYoncY0kWT7p0tqNr3wYsmzR8adcmSVrA+gqaqvqz2Z44vanLFcBDVTX5JtQ64Bzgj7qfN09qf2+S64ETgaenuz8jSVoY+gqaJD8FJi5TvQQ4APirqnr5NMNWAu8EHpj0QaKP0AuYtUnOBR6ht5IB4BbgbcAW4GfAu2fxe0iS5ql+ZzSHTGx3M5VT6S1Znm7MN3nxlRJvnqJ/Aef3U48kaeHo9x7NL3SB8N+TXMjzn4GRJA3Q8R+8Zk4XQ933ybNnXEKd5Erg7cCO7knRfen30tlvT9rdj96HNf+63zeRJO0VrqL3Wci+P6wJ/c9o/vWk7Z3Aw/Qun0mS9hFVdXf3uchZ6fcejTfmJUm7pd9nnS1N8tUkO7rXTd2joiVJmla/j6D5Ir3Pubyye/2Prk2SpGn1GzQjVfXFqtrZva4CRhrWJUnaS/S7GOCJJL8LXNftnwU80aYkSdJM+lmOPNeSXEfvy9GOSLIVuLCqrphpXL9B8+/pfY/0JfSeEPDnwLt2q1JJ0oJUVWftzrh+g+bjwDlV9RP4xTe1fYpeAEmS9KL6vUfz+omQAaiqJ+l9v4wkSdPqN2j2S3LYxE43o5n142skSfuefsPi08C3kny52z+d3ndRS5I0rX6fDHBNkjHglK7pt6vqwXZlSZL2Fn1f/uqCxXCRJM2K91kkaQH6i4+/bk6/JuAfffSBfr4mYBm9JzcfSe+jLmuq6tKZxhk0kqR+7QQ+UFXfTXIIcF+S22a6ldLvqjNJ0j6uqrZX1Xe77Z8CDwFLZhpn0EiSZq37XprjgHtm6mvQSJJmJcnBwE3A+6vqmZn6GzSSpL4lOYBeyHypqr7SzxiDRpLUlyQBrgAeqqrP9DvOVWeStAD1sxy5gZXAO4EHkmzo2j5SVbdMN8igkST1paq+Ccw64Lx0JklqyqCRJDVl0EiSmjJoJElNGTSSpKYMGklSU82WNye5Eng7sKOqju3aLgJ+Dxjvuv1i/XWSDwPnAruA36+qr7eqTZIWupWXrZzTrwlYf8H6fr4m4CDgbuBAevlxY1VdONO4ljOaq4BVU7RfUlUrutdEyBwNnAkc0435fJL9G9YmSZq954BTquoNwApgVZKTZhrULGiq6m7gyT67nwpcX1XPVdWPgC3ACa1qkyTNXvU82+0e0L1mnFkN4x7Ne5NsTHJlksO6tiXAo5P6bOVFvuMgyeokY0nGxsfHp+oiSWokyf7d42d2ALdV1bz7moDLgVfTm3JtBz492xNU1ZqqGq2q0ZGRkbmuT5I0jaraVVUrgKXACUmOnWnMQIOmqh7rivxb4As8f3lsG7BsUtelXZskaR6qqqeAO5n6XvzfMdCgSbJ40u5vAZu67XXAmUkOTHIUsBy4d5C1SZKml2QkyaHd9kuBtwDfm2lcy+XN1wEnA0ck2QpcCJycZAW9m0cPA+8BqKrNSdYCDwI7gfOraler2iRpoetnOXIDi4Gru1XB+wFrq+prMw1qFjRVddYUzVdM0/9i4OJW9UiS9kxVbQSOm+04nwwgSWrKoJEkNWXQSJKaMmgkSU0ZNJKkppqtOpP09x3/wWuGXUJf7vvk2cMuQXsRZzSSpKYMGklSUwaNJKkpg0aS1JRBI0lqyqCRJDVl0EiSmjJoJElNGTSSpKYMGklSUwaNJKkpg0aS1JQP1ZS0YK28bOWwS+jL+gvWD7uEoXJGI0lqyqCRJDVl0EiSmjJoJElNGTSSpKYMGklSUwaNJKkpg0aS1JRBI0lqyqCRJDVl0EiSmmoWNEmuTLIjyaZJbYcnuS3JD7qfh3XtSfLZJFuSbEzyxlZ1SZIGq+WM5ipg1QvaPgTcXlXLgdu7fYC3Asu712rg8oZ1SZIGqFnQVNXdwJMvaD4VuLrbvho4bVL7NdXzbeDQJItb1SZJGpxB36M5sqq2d9s/Bo7stpcAj07qt7Vr+3uSrE4ylmRsfHy8XaWSpDkxtMUAVVVA7ca4NVU1WlWjIyMjDSqTJM2lQX/x2WNJFlfV9u7S2I6ufRuwbFK/pV2bgL/4+OuGXUJ/Dnv5sCuQNA8NekazDjin2z4HuHlS+9nd6rOTgKcnXWKTJC1gzWY0Sa4DTgaOSLIVuBD4I2BtknOBR4Azuu63AG8DtgA/A97dqi5J0mA1C5qqOutFDr15ir4FnN+qFknS8PhkAElSUwaNJKkpg0aS1JRBI0lqatCfo5G0APjZLc0lZzSSpKYMGklSUwaNJKkpg0aS1JRBI0lqap9edXb8B68Zdgl9+eohw65AknafMxpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkpoyaCRJTRk0kqSmDBpJUlMGjSSpKYNGktSUQSNJasqgkSQ1ZdBIkpoyaCRJTRk0kqSmDBpJUlMGjSSpKYNGktTUomG8aZKHgZ8Cu4CdVTWa5HDgBuBVwMPAGVX1k2HUJ0maO8Oc0fzzqlpRVaPd/oeA26tqOXB7ty9JWuDm06WzU4Gru+2rgdOGWIskaY4MK2gK+NMk9yVZ3bUdWVXbu+0fA0dONTDJ6iRjScbGx8cHUaskaQ8M5R4N8OtVtS3JPwBuS/K9yQerqpLUVAOrag2wBmB0dHTKPpKk+WMoM5qq2tb93AF8FTgBeCzJYoDu545h1CZJmlsDD5okL0tyyMQ28C+BTcA64Jyu2znAzYOuTZI094Zx6exI4KtJJt7/T6rq1iTfAdYmORd4BDhjCLVJkubYwIOmqn4IvGGK9ieANw+6HklSW/NpebMkaS9k0EiSmjJoJElNGTSSpKYMGklSUwaNJKkpg0aS1JRBI0lqyqCRJDVl0EiSmjJoJElNGTSSpKYMGklSUwaNJKkpg0aS1JRBI0lqyqCRJDVl0EiSmjJoJElNGTSSpKYMGklSUwaNJKkpg0aS1JRBI0lqyqCRJDVl0EiSmjJoJElNGTSSpKYMGklSUwaNJKmpeRc0SVYl+X6SLUk+NOx6JEl7Zl4FTZL9gf8GvBU4GjgrydHDrUqStCfmVdAAJwBbquqHVfU3wPXAqUOuSZK0BxYNu4AXWAI8Oml/K3Di5A5JVgOru91nk3x/QLUNzT9uc9ojgMfbnHp+y+9n2CXMe/7Nza05+Ju7tapWzUUtwzDfgmZGVbUGWDPsOha6JGNVNTrsOrTv8G9u3zXfLp1tA5ZN2l/atUmSFqj5FjTfAZYnOSrJS4AzgXVDrkmStAfm1aWzqtqZ5L3A14H9gSuravOQy9pbeflRg+bf3D4qVTXsGiRJe7H5dulMkrSXMWgkSU0ZNPsYH/GjQUtyZZIdSTYNuxYNh0GzD/ERPxqSq4AF+2FD7TmDZt/iI340cFV1N/DksOvQ8Bg0+5apHvGzZEi1SNpHGDSSpKYMmn2Lj/iRNHAGzb7FR/xIGjiDZh9SVTuBiUf8PASs9RE/ai3JdcC3gNck2Zrk3GHXpMHyETSSpKac0UiSmjJoJElNGTSSpKYMGklSUwaNJKkpg0Z7tSR/mGRzko1JNiQ5cQ7O+Ztz9eTrJM/OxXmk+czlzdprJfk14DPAyVX1XJIjgJdU1V/2MXZR97mj1jU+W1UHt34faZic0Whvthh4vKqeA6iqx6vqL5M83IUOSUaT3NVtX5Tk2iTrgWuTfDvJMRMnS3JX1/9dST6X5BVJHkmyX3f8ZUkeTXJAklcnuTXJfUm+keS1XZ+jknwryQNJPjHg/x7SUBg02pv9KbAsyf9J8vkk/6yPMUcD/6KqzgJuAM4ASLIYWFxVYxMdq+ppYAMwcd63A1+vqv8HrAEuqKrjgT8APt/1uRS4vKpeB2zf499QWgAMGu21qupZ4HhgNTAO3JDkXTMMW1dVP++21wK/022fAdw4Rf8bgH/bbZ/ZvcfBwJuALyfZAPwxvdkVwErgum772ln9QtICtWjYBUgtVdUu4C7griQPAOcAO3n+f7IOesGQv5o0dluSJ5K8nl6YnDfFW6wD/kuSw+mF2h3Ay4CnqmrFi5W1m7+OtCA5o9FeK8lrkiyf1LQCeAR4mF4oAPybGU5zA/AfgFdU1cYXHuxmTd+hd0nsa1W1q6qeAX6U5PSujiR5QzdkPb2ZD8A7Zv9bSQuPQaO92cHA1UkeTLKR3v2Xi4CPAZcmGQN2zXCOG+kFw9pp+twA/G73c8I7gHOT3A9s5vmvzH4fcH43u/LbTbVPcHmzJKkpZzSSpKYMGklSUwaNJKkpg0aS1JRBI0lqyqCRJDVl0EiSmvr/Zo+vX/Fg+jkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 402.375x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot('Survived', data=train_df, hue='Pclass', kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "? re.sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T09:05:38.503189Z",
     "start_time": "2018-09-24T09:05:37.737215Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akai/virtualenvs/tensor_flow/lib/python3.5/site-packages/ipykernel_launcher.py:24: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/akai/virtualenvs/tensor_flow/lib/python3.5/site-packages/ipykernel_launcher.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PassengerId\n",
      "Sex                \n",
      "female          314\n",
      "male            577\n",
      "        PassengerId\n",
      "Sex                \n",
      "female          152\n",
      "male            266\n",
      "columns before Index(['Survived', 'Pclass', 'Sex', 'Cabin', 'Embarked', 'Title', 'IsAlone',\n",
      "       'AgeBand', 'FareBand', 'Ticket_NonNumber'],\n",
      "      dtype='object')\n",
      "columns after Index(['IsAlone', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n",
      "       'Cabin_A', 'Cabin_B', 'Cabin_C', 'Cabin_D', 'Cabin_E', 'Cabin_F',\n",
      "       'Cabin_G', 'Cabin_T', 'Cabin_U', 'Embarked_C', 'Embarked_Q',\n",
      "       'Embarked_S', 'Title_Boy', 'Title_Girl', 'Title_Master', 'Title_Miss',\n",
      "       'Title_Mr', 'Title_Mrs', 'Title_Officer', 'Title_Royalty',\n",
      "       'AgeBand_0.0', 'AgeBand_1.0', 'AgeBand_2.0', 'FareBand_0.0',\n",
      "       'FareBand_1.0', 'FareBand_2.0', 'FareBand_3.0', 'Ticket_NonNumber_A',\n",
      "       'Ticket_NonNumber_C', 'Ticket_NonNumber_CA', 'Ticket_NonNumber_FA',\n",
      "       'Ticket_NonNumber_FC', 'Ticket_NonNumber_FCC', 'Ticket_NonNumber_LINE',\n",
      "       'Ticket_NonNumber_P', 'Ticket_NonNumber_PC', 'Ticket_NonNumber_PP',\n",
      "       'Ticket_NonNumber_SC', 'Ticket_NonNumber_SCO', 'Ticket_NonNumber_SO',\n",
      "       'Ticket_NonNumber_SOC', 'Ticket_NonNumber_SOP',\n",
      "       'Ticket_NonNumber_SOTON', 'Ticket_NonNumber_SP',\n",
      "       'Ticket_NonNumber_STON', 'Ticket_NonNumber_SW', 'Ticket_NonNumber_W',\n",
      "       'Ticket_NonNumber_XXX'],\n",
      "      dtype='object')\n",
      "\tnumber of columns 54\n",
      "\tmissing columns {'Ticket_NonNumber_SP', 'Ticket_NonNumber_SCO', 'Ticket_NonNumber_P', 'Ticket_NonNumber_SW', 'Ticket_NonNumber_SOP', 'Cabin_T', 'Ticket_NonNumber_LINE', 'Ticket_NonNumber_FA'}\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "combine = [train_df, test_df]\n",
    "y = train_df['Survived']\n",
    "# train_df.drop(['Survived'], axis=1, inplace=True)\n",
    "test_ids = test_df['PassengerId']\n",
    "def woman_child_or_man(passenger):\n",
    "    age, sex = passenger\n",
    "    if age < 16:\n",
    "        return \"child\"\n",
    "    else:\n",
    "        return dict(male=\"man\", female=\"woman\")[sex]\n",
    "    \n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    dataset.loc[dataset.Title=='Ms', 'Title'] = 'Miss' # unify the naming\n",
    "    dataset['Title'] = dataset['Title'].replace(['Mme', 'Mlle'], 'Mrs') # seem to be the title for old lady\n",
    "    dataset.loc[((dataset.Title=='Master') | (dataset.Title.isnull())) & (dataset.Age<15) & (dataset.Sex=='male'), 'Title'] = 'Boy'\n",
    "    dataset.loc[((dataset.Title=='Mrs') | dataset.Title.isnull() | (dataset.Title=='Miss') ) & (dataset.Sex=='female') & (dataset.Age<15), 'Title'] = 'Girl'\n",
    "    dataset['Title'] = dataset['Title'].replace(['Jonkheer', 'Don', 'Sir', 'Countess', 'Lady', 'Dona'], 'Royalty')\n",
    "    dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer')\n",
    "    \n",
    "combined = pd.concat([train_df, test_df])\n",
    "grouped_median_age = combined[train_df.Age.notnull()].groupby(['Sex', 'Pclass', 'Title']).median()\n",
    "grouped_median_age = grouped_median_age.reset_index()[['Sex', 'Pclass', 'Title', 'Age']]\n",
    "\n",
    "def assign_age(row):\n",
    "    condition = (\n",
    "        (grouped_median_age['Sex'] == row['Sex']) & \n",
    "        (grouped_median_age['Title'] == row['Title']) & \n",
    "        (grouped_median_age['Pclass'] == row['Pclass'])\n",
    "    )\n",
    "    return grouped_median_age[condition]['Age'].values[0]\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Age'] = dataset.apply(lambda row: assign_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)\n",
    "    dataset.loc[(dataset.Sex=='male') & (dataset.Pclass==3) & (dataset.Title=='Master'), 'Age'] = 35\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    dataset.loc[dataset.Embarked.isnull(), 'Embarked'] = 'S'\n",
    "    dataset.loc[dataset.Cabin.notnull(), 'Cabin'] = dataset.loc[dataset.Cabin.notnull(), 'Cabin'].map(lambda x: x[0])\n",
    "    dataset.loc[dataset.Cabin.isnull(), 'Cabin'] = 'U' #unknown\n",
    "    \n",
    "def cleanTicket(ticket):\n",
    "    original_ticket = ticket\n",
    "    ticket = ticket.split()\n",
    "    ticket = [''.join(ticket[:-1]), ticket[-1]]\n",
    "    ticket = ' '.join(ticket)\n",
    "    ticket = re.sub('/.+ ',' ', ticket)\n",
    "    ticket = ticket.replace('.', '')\n",
    "    ticket = ticket.replace('/', '')\n",
    "    ticket = ticket.split()\n",
    "    ticket = list(map(lambda t : t.strip().upper(), ticket))\n",
    "    if len(ticket)>2:\n",
    "        number = ticket[-1]\n",
    "        non_number = \"\".join(ticket[:-1])\n",
    "        ticket = [non_number, number]\n",
    "#     ticket = list(filter(lambda t : not t.isdigit(), ticket))\n",
    "    \n",
    "    if len(ticket) ==2:\n",
    "        res =  [ticket[0], int(ticket[1])]\n",
    "    elif len(ticket)==1:\n",
    "        try:\n",
    "            res =  ['XXX', int(ticket[0])]\n",
    "        except:\n",
    "            res = [ticket[0], 0]\n",
    "    if ticket[0] in ('AS', 'A4', 'A5', 'A2', 'AQ'):\n",
    "        res = ['A', ticket[1]]\n",
    "    elif ticket[0] in ('WE', 'WEP'):\n",
    "        res = ['W', ticket[1]]\n",
    "            \n",
    "#     print(original_ticket, res)\n",
    "    return res\n",
    "for dataset in combine:    \n",
    "#     print(dataset.loc[dataset.Ticket.notnull(), 'Ticket'].size)\n",
    "    dataset.loc[ dataset['Age'] <= 15, 'AgeBand'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 15) & (dataset['Age'] <= 40), 'AgeBand'] = 1\n",
    "    dataset.loc[ dataset['Age'] > 40, 'AgeBand'] = 2\n",
    "    dataset['AgeBand'] = dataset['AgeBand'].astype(str)\n",
    "    dataset.loc[dataset['Fare'].isnull(), 'Fare'] = 8\n",
    "    dataset.loc[dataset['Fare'] <= 8, 'FareBand'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 8) & (dataset['Fare'] <= 50), 'FareBand'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 50) & (dataset['Fare'] <= 100), 'FareBand']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 100, 'FareBand'] = 3\n",
    "    dataset['FareBand'] = dataset['FareBand'].astype(str)\n",
    "    dataset['Pclass'] = dataset['Pclass'].astype(str)\n",
    "    dataset[['Ticket_NonNumber', 'Ticket_Number']] = pd.DataFrame(dataset['Ticket'].map(cleanTicket).values.tolist(), index=dataset.index)\n",
    "    print(dataset.groupby(['Sex']).count()[['PassengerId']])\n",
    "\n",
    "test_infos = test_df[['PassengerId', 'Name', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'Ticket', 'Title', 'Ticket_Number', 'FareBand', 'AgeBand', 'Pclass', 'IsAlone']]\n",
    "for dataset in combine:\n",
    "    dataset.drop(['PassengerId', 'Name', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'Ticket', 'Ticket_Number'], axis=1, inplace=True)\n",
    "print('columns before', train_df.columns)\n",
    "train_df.drop(['Survived'], axis=1, inplace=True)\n",
    "train_df = pd.get_dummies(train_df)\n",
    "print('columns after', train_df.columns)\n",
    "print(\"\\tnumber of columns\", len(train_df.columns))\n",
    "test_df = pd.get_dummies(test_df)\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set( train_df.columns ) - set( test_df.columns )\n",
    "print(\"\\tmissing columns\", missing_cols)\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    test_df[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "test_df = test_df[train_df.columns]\n",
    "train_df.to_csv('train_temp.csv')\n",
    "# print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc,def'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(['abc', 'def'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T09:06:00.540343Z",
     "start_time": "2018-09-24T09:05:52.433236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** before reduced = [0.78212291 0.82122905 0.80337079 0.74719101 0.8079096 ]\n",
      "reduced shape (891, 13) (418, 13)\n",
      "*** retrain after reducing***\n",
      "0.7912158258762099\n",
      "Cross-validation of : <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "CV score = 0.7811283618230739\n",
      "**********\n",
      "Cross-validation of : <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>\n",
      "CV score = 0.7800298745969111\n",
      "**********\n",
      "Cross-validation of : <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "CV score = 0.8149311632403441\n",
      "**********\n",
      "Cross-validation of : <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
      "CV score = 0.818295672687334\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## array([0.81564246, 0.80446927, 0.80898876, 0.79213483, 0.8079096 ])\n",
    "# clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, min_samples_leaf=100, max_depth=2, random_state=random_state)\n",
    "\n",
    "## array([0.79888268, 0.81564246, 0.81460674, 0.80337079, 0.85875706])\n",
    "clf = RandomForestClassifier(max_depth=4, max_features=3, n_estimators=400)\n",
    "\n",
    "## array([0.75977654, 0.75977654, 0.7752809 , 0.76966292, 0.82485876])\n",
    "# clf = VotingClassifier(\n",
    "#     estimators=[\n",
    "#         ('lr', LogisticRegression()),\n",
    "#         ('svc', SVC()),\n",
    "#         ('tree', DecisionTreeClassifier(max_depth=2, max_features=3)),\n",
    "#         ('sgd', SGDClassifier()),\n",
    "#         ('linear_svc', LinearSVC()),\n",
    "#         ('gaussian', GaussianNB()),\n",
    "#         ('knn', KNeighborsClassifier(n_neighbors = 2))\n",
    "#     ],\n",
    "#     voting='hard',\n",
    "# )\n",
    "\n",
    "## array([0.82122905, 0.80446927, 0.79775281, 0.75842697, 0.8079096 ])\n",
    "# clf = AdaBoostClassifier(\n",
    "#     DecisionTreeClassifier(max_depth=1), n_estimators=300,\n",
    "#     algorithm='SAMME', learning_rate=0.2\n",
    "# )\n",
    "\n",
    "# clf = DecisionTreeClassifier()\n",
    "# cv = cross_val_score(clf, train_df, y, cv=5)\n",
    "# print(cv)\n",
    "clf.fit(train_df, y)\n",
    "# print(\"*\"*40, \"running grid search\")\n",
    "# param_test = {'n_estimators': np.linspace(100,500,5, dtype=np.int),\n",
    "#               'max_depth': [1,2,3,4,6,8],\n",
    "#               'max_features': ['sqrt', 'auto', 'log2'],\n",
    "#               'min_samples_split': [2, 3, 10],\n",
    "#               'min_samples_leaf': [1, 3, 10],\n",
    "#               'bootstrap': [True, False],\n",
    "#              }\n",
    "# gs = GridSearchCV(estimator=clf, param_grid=param_test, cv=5, n_jobs=5, verbose=1)\n",
    "# gs.fit(train_df, y)\n",
    "# print(\"*\"*40, \"best params\", gs.best_params_, gs.best_score_)\n",
    "# clf.fit(train_df, y)\n",
    "cv = cross_val_score(clf, train_df, y, cv=5)\n",
    "print(\"** before reduced = {}\".format(cv))\n",
    "features = pd.DataFrame()\n",
    "features['feature'] = train_df.columns\n",
    "features['importance'] = clf.feature_importances_\n",
    "features.sort_values(by=['importance'], ascending=True, inplace=True)\n",
    "features.set_index('feature', inplace=True)\n",
    "features.plot(kind='barh', figsize=(25, 25))\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "train_reduced = model.transform(train_df)\n",
    "test_reduced = model.transform(test_df)\n",
    "print(\"reduced shape\", train_reduced.shape, test_reduced.shape)\n",
    "print(\"*** retrain after reducing***\")\n",
    "print(np.mean(cross_val_score(clf, train_reduced, y, cv=5)))\n",
    "clf.fit(train_reduced, y)\n",
    "logreg = LogisticRegression()\n",
    "logreg_cv = LogisticRegressionCV()\n",
    "rf = RandomForestClassifier()\n",
    "gboost = GradientBoostingClassifier()\n",
    "\n",
    "models = [logreg, logreg_cv, rf, gboost]\n",
    "for m in models:\n",
    "    print('Cross-validation of : {0}'.format(m.__class__))\n",
    "    score = np.mean(cross_val_score(m, X=train_reduced, y=y, scoring='accuracy', cv=5))\n",
    "    print('CV score = {0}'.format(score))\n",
    "    print('*'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T08:29:14.890139Z",
     "start_time": "2018-09-24T08:02:31.531399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************** running grid search\n",
      "Fitting 5 folds for each of 3240 candidates, totalling 16200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=5)]: Done 190 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=5)]: Done 440 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=5)]: Done 790 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=5)]: Done 1240 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=5)]: Done 1790 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=5)]: Done 2440 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=5)]: Done 3190 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=5)]: Done 4040 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=5)]: Done 4990 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=5)]: Done 6040 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=5)]: Done 7190 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=5)]: Done 8440 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=5)]: Done 9790 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=5)]: Done 11240 tasks      | elapsed: 32.8min\n",
      "[Parallel(n_jobs=5)]: Done 12790 tasks      | elapsed: 37.2min\n",
      "[Parallel(n_jobs=5)]: Done 14440 tasks      | elapsed: 42.1min\n",
      "[Parallel(n_jobs=5)]: Done 16190 tasks      | elapsed: 47.4min\n",
      "[Parallel(n_jobs=5)]: Done 16200 out of 16200 | elapsed: 47.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************** best params for random forest {'min_samples_split': 3, 'min_samples_leaf': 3, 'max_depth': 8, 'bootstrap': True, 'n_estimators': 300, 'max_features': 4} 0.8249158249158249\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*40, \"running grid search\")\n",
    "param_test = {'n_estimators': np.linspace(100,500,5, dtype=np.int),\n",
    "              'max_depth': [1,2,3,4,6,8],\n",
    "              'max_features': ['sqrt', 'auto', 'log2', 2, 3, 4],\n",
    "              'min_samples_split': [2, 3, 10],\n",
    "              'min_samples_leaf': [1, 3, 10],\n",
    "              'bootstrap': [True, False],\n",
    "             }\n",
    "gs = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_test, cv=5, n_jobs=5, verbose=1)\n",
    "gs.fit(train_reduced, y)\n",
    "print(\"*\"*40, \"best params for random forest\", gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** best score for random forest = 0.8182704934805359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=100, max_features=10, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest = RandomForestClassifier(**{\n",
    "    'min_samples_split': 3,                                     \n",
    "    'min_samples_leaf': 3, \n",
    "    'max_depth': 100, \n",
    "    'bootstrap': True, \n",
    "    'n_estimators': 400, \n",
    "    'max_features': 10})\n",
    "score = np.mean(cross_val_score(best_forest, train_reduced, y, cv=5))\n",
    "print(\"** best score for random forest = {}\".format(score))\n",
    "best_forest.fit(train_reduced, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:14:45.501102Z",
     "start_time": "2018-09-24T06:39:03.922274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3600 candidates, totalling 18000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done 175 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=5)]: Done 625 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=5)]: Done 1017 tasks      | elapsed:   46.6s\n",
      "[Parallel(n_jobs=5)]: Done 1367 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=5)]: Done 1817 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=5)]: Done 2367 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=5)]: Done 3017 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=5)]: Done 3767 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=5)]: Done 4617 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=5)]: Done 5567 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=5)]: Done 6617 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=5)]: Done 7767 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=5)]: Done 9017 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=5)]: Done 10367 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=5)]: Done 11817 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=5)]: Done 13367 tasks      | elapsed: 24.8min\n",
      "[Parallel(n_jobs=5)]: Done 15017 tasks      | elapsed: 28.6min\n",
      "[Parallel(n_jobs=5)]: Done 16767 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=5)]: Done 18000 out of 18000 | elapsed: 35.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=5,\n",
       "       param_grid={'learning_rate': array([0.1, 0.2, 0.3, 0.4, 0.5]), 'n_estimators': array([ 100,  212,  325,  437,  550,  662,  775,  887, 1000]), 'max_depth': array([1, 2, 3, 4, 5]), 'min_samples_split': [2, 5, 10, 20], 'max_features': [2, 4, 6, 8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test = {\n",
    "    'learning_rate': np.linspace(0.1, 0.5, 5),\n",
    "    'n_estimators': np.linspace(100, 1000, 9, dtype=np.int),\n",
    "    'max_depth': np.linspace(1, 5, 5, dtype=np.int),\n",
    "    'min_samples_split': [2,5,10,20],\n",
    "    'max_features': [2,4,6,8]\n",
    "}\n",
    "gs = GridSearchCV(estimator=GradientBoostingClassifier(), param_grid=param_test, cv=5, n_jobs=5, verbose=1)\n",
    "gs.fit(train_reduced, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T03:58:02.373900Z",
     "start_time": "2018-09-24T03:57:27.405Z"
    }
   },
   "outputs": [],
   "source": [
    "gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T09:35:36.158814Z",
     "start_time": "2018-09-24T09:35:33.144719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** score = 0.7732880887811738\n"
     ]
    }
   ],
   "source": [
    "ada_boosting = AdaBoostClassifier(n_estimators=500, learning_rate=0.1, algorithm='SAMME', random_state=random_state)\n",
    "score = np.mean(cross_val_score(ada_boosting, train_reduced, y, cv=5))\n",
    "print(\"** score = {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:38:41.024658Z",
     "start_time": "2018-09-24T06:38:39.833955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** score = 0.8148742440475114\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting = GradientBoostingClassifier(\n",
    "    learning_rate=0.5,\n",
    "    n_estimators=437, \n",
    "    max_depth= 2,\n",
    "    min_samples_leaf= 2,\n",
    "    min_samples_split=2)\n",
    "score = np.mean(cross_val_score(gradient_boosting, train_reduced, y, cv=5))\n",
    "gradient_boosting.fit(train_reduced, y)\n",
    "print(\"** score = {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:28:29.698641Z",
     "start_time": "2018-09-24T06:28:29.664494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId                                          Name   Age  SibSp  \\\n",
      "0          892                              Kelly, Mr. James  34.5      0   \n",
      "1          893              Wilkes, Mrs. James (Ellen Needs)  47.0      1   \n",
      "2          894                     Myles, Mr. Thomas Francis  62.0      0   \n",
      "3          895                              Wirz, Mr. Albert  27.0      0   \n",
      "4          896  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  22.0      1   \n",
      "\n",
      "   Parch     Fare  FamilySize   Ticket Title Ticket_Number FareBand AgeBand  \\\n",
      "0      0   7.8292           1   330911    Mr        330911      0.0     1.0   \n",
      "1      0   7.0000           2   363272   Mrs        363272      0.0     2.0   \n",
      "2      0   9.6875           1   240276    Mr        240276      1.0     2.0   \n",
      "3      0   8.6625           1   315154    Mr        315154      1.0     1.0   \n",
      "4      1  12.2875           3  3101298   Mrs       3101298      1.0     1.0   \n",
      "\n",
      "  Pclass  IsAlone  Survived  \n",
      "0      3        1         0  \n",
      "1      3        0         1  \n",
      "2      2        1         0  \n",
      "3      3        1         0  \n",
      "4      3        0         0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akai/virtualenvs/tensor_flow/lib/python3.5/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_pred = best_forest.predict(test_reduced)\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_ids,\n",
    "    \"Survived\": y_pred\n",
    "})\n",
    "test_infos['Survived'] = y_pred\n",
    "print(test_infos.head())\n",
    "test_infos.to_csv('titanic_result_feature_engineer_random_forest_inspection.csv')\n",
    "submission.to_csv('titanic_result_feature_engineer_random_forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeBand_0.0</th>\n",
       "      <th>AgeBand_1.0</th>\n",
       "      <th>AgeBand_2.0</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_NonNumber_W</th>\n",
       "      <th>Ticket_NonNumber_XXX</th>\n",
       "      <th>Title_Boy</th>\n",
       "      <th>Title_Girl</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AgeBand_0.0  AgeBand_1.0  AgeBand_2.0  Cabin_A  Cabin_B  Cabin_C  Cabin_D  \\\n",
       "0           0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "1           0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "2           0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "3           0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "4           0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "5           1.0          0.0          0.0      0.0      0.0      0.0      0.0   \n",
       "6           0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "7           0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "8           0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "9           0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "10          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "11          0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "12          0.0          1.0          0.0      0.0      1.0      0.0      0.0   \n",
       "13          0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "14          0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "15          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "16          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "17          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "18          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "19          0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "20          0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "21          1.0          0.0          0.0      0.0      0.0      0.0      0.0   \n",
       "22          0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "23          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "24          0.0          0.0          1.0      0.0      1.0      0.0      0.0   \n",
       "25          0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "26          0.0          1.0          0.0      0.0      1.0      0.0      0.0   \n",
       "27          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "28          0.0          0.0          1.0      1.0      0.0      0.0      0.0   \n",
       "29          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "..          ...          ...          ...      ...      ...      ...      ...   \n",
       "70          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "71          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "72          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "73          0.0          1.0          0.0      0.0      0.0      0.0      1.0   \n",
       "74          0.0          1.0          0.0      0.0      0.0      1.0      0.0   \n",
       "75          0.0          1.0          0.0      0.0      0.0      1.0      0.0   \n",
       "76          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "77          0.0          0.0          1.0      0.0      0.0      1.0      0.0   \n",
       "78          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "79          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "80          1.0          0.0          0.0      0.0      0.0      0.0      0.0   \n",
       "81          0.0          0.0          1.0      0.0      0.0      1.0      0.0   \n",
       "82          0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "83          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "84          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "85          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "86          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "87          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "88          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "89          1.0          0.0          0.0      0.0      0.0      0.0      0.0   \n",
       "90          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "91          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "92          0.0          1.0          0.0      0.0      1.0      0.0      0.0   \n",
       "93          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "94          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "95          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "96          0.0          0.0          1.0      0.0      0.0      1.0      0.0   \n",
       "97          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "98          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "99          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "    Cabin_E  Cabin_F  Cabin_G      ...        Ticket_NonNumber_W  \\\n",
       "0       0.0      0.0      0.0      ...                       0.0   \n",
       "1       0.0      0.0      0.0      ...                       0.0   \n",
       "2       0.0      0.0      0.0      ...                       0.0   \n",
       "3       0.0      0.0      0.0      ...                       0.0   \n",
       "4       0.0      0.0      0.0      ...                       0.0   \n",
       "5       0.0      0.0      0.0      ...                       0.0   \n",
       "6       0.0      0.0      0.0      ...                       0.0   \n",
       "7       0.0      0.0      0.0      ...                       0.0   \n",
       "8       0.0      0.0      0.0      ...                       0.0   \n",
       "9       0.0      0.0      0.0      ...                       0.0   \n",
       "10      0.0      0.0      0.0      ...                       0.0   \n",
       "11      0.0      0.0      0.0      ...                       0.0   \n",
       "12      0.0      0.0      0.0      ...                       0.0   \n",
       "13      0.0      0.0      0.0      ...                       0.0   \n",
       "14      1.0      0.0      0.0      ...                       1.0   \n",
       "15      0.0      0.0      0.0      ...                       0.0   \n",
       "16      0.0      0.0      0.0      ...                       0.0   \n",
       "17      0.0      0.0      0.0      ...                       0.0   \n",
       "18      0.0      0.0      0.0      ...                       0.0   \n",
       "19      0.0      0.0      0.0      ...                       0.0   \n",
       "20      0.0      0.0      0.0      ...                       0.0   \n",
       "21      0.0      0.0      0.0      ...                       0.0   \n",
       "22      0.0      0.0      0.0      ...                       0.0   \n",
       "23      0.0      0.0      0.0      ...                       0.0   \n",
       "24      0.0      0.0      0.0      ...                       0.0   \n",
       "25      0.0      0.0      0.0      ...                       0.0   \n",
       "26      0.0      0.0      0.0      ...                       0.0   \n",
       "27      0.0      0.0      0.0      ...                       0.0   \n",
       "28      0.0      0.0      0.0      ...                       0.0   \n",
       "29      0.0      0.0      0.0      ...                       0.0   \n",
       "..      ...      ...      ...      ...                       ...   \n",
       "70      0.0      0.0      0.0      ...                       0.0   \n",
       "71      0.0      0.0      0.0      ...                       0.0   \n",
       "72      0.0      0.0      0.0      ...                       0.0   \n",
       "73      0.0      0.0      0.0      ...                       0.0   \n",
       "74      0.0      0.0      0.0      ...                       0.0   \n",
       "75      0.0      0.0      0.0      ...                       0.0   \n",
       "76      0.0      0.0      0.0      ...                       0.0   \n",
       "77      0.0      0.0      0.0      ...                       0.0   \n",
       "78      0.0      0.0      0.0      ...                       0.0   \n",
       "79      0.0      0.0      0.0      ...                       0.0   \n",
       "80      0.0      0.0      0.0      ...                       0.0   \n",
       "81      0.0      0.0      0.0      ...                       0.0   \n",
       "82      0.0      0.0      0.0      ...                       0.0   \n",
       "83      0.0      0.0      0.0      ...                       0.0   \n",
       "84      0.0      0.0      0.0      ...                       0.0   \n",
       "85      0.0      0.0      0.0      ...                       0.0   \n",
       "86      0.0      0.0      0.0      ...                       0.0   \n",
       "87      0.0      0.0      0.0      ...                       0.0   \n",
       "88      0.0      0.0      0.0      ...                       0.0   \n",
       "89      0.0      0.0      0.0      ...                       0.0   \n",
       "90      0.0      0.0      0.0      ...                       0.0   \n",
       "91      0.0      0.0      0.0      ...                       0.0   \n",
       "92      0.0      0.0      0.0      ...                       0.0   \n",
       "93      0.0      0.0      0.0      ...                       0.0   \n",
       "94      0.0      0.0      0.0      ...                       0.0   \n",
       "95      0.0      0.0      0.0      ...                       0.0   \n",
       "96      0.0      0.0      0.0      ...                       0.0   \n",
       "97      0.0      0.0      0.0      ...                       0.0   \n",
       "98      0.0      0.0      0.0      ...                       0.0   \n",
       "99      0.0      0.0      0.0      ...                       0.0   \n",
       "\n",
       "    Ticket_NonNumber_XXX  Title_Boy  Title_Girl  Title_Master  Title_Miss  \\\n",
       "0                    1.0        0.0         0.0           0.0         0.0   \n",
       "1                    1.0        0.0         0.0           0.0         0.0   \n",
       "2                    1.0        0.0         0.0           0.0         0.0   \n",
       "3                    1.0        0.0         0.0           0.0         0.0   \n",
       "4                    1.0        0.0         0.0           0.0         0.0   \n",
       "5                    1.0        0.0         0.0           0.0         0.0   \n",
       "6                    1.0        0.0         0.0           0.0         1.0   \n",
       "7                    1.0        0.0         0.0           0.0         0.0   \n",
       "8                    1.0        0.0         0.0           0.0         0.0   \n",
       "9                    0.0        0.0         0.0           0.0         0.0   \n",
       "10                   1.0        0.0         0.0           0.0         0.0   \n",
       "11                   1.0        0.0         0.0           0.0         0.0   \n",
       "12                   1.0        0.0         0.0           0.0         0.0   \n",
       "13                   1.0        0.0         0.0           0.0         0.0   \n",
       "14                   0.0        0.0         0.0           0.0         0.0   \n",
       "15                   0.0        0.0         0.0           0.0         0.0   \n",
       "16                   1.0        0.0         0.0           0.0         0.0   \n",
       "17                   1.0        0.0         0.0           0.0         0.0   \n",
       "18                   0.0        0.0         0.0           0.0         1.0   \n",
       "19                   1.0        0.0         0.0           0.0         0.0   \n",
       "20                   0.0        0.0         0.0           0.0         0.0   \n",
       "21                   0.0        1.0         0.0           0.0         0.0   \n",
       "22                   0.0        0.0         0.0           0.0         0.0   \n",
       "23                   0.0        0.0         0.0           0.0         0.0   \n",
       "24                   0.0        0.0         0.0           0.0         0.0   \n",
       "25                   0.0        0.0         0.0           0.0         0.0   \n",
       "26                   1.0        0.0         0.0           0.0         1.0   \n",
       "27                   1.0        0.0         0.0           0.0         0.0   \n",
       "28                   1.0        0.0         0.0           0.0         0.0   \n",
       "29                   1.0        0.0         0.0           0.0         0.0   \n",
       "..                   ...        ...         ...           ...         ...   \n",
       "70                   1.0        0.0         0.0           0.0         1.0   \n",
       "71                   1.0        0.0         0.0           0.0         0.0   \n",
       "72                   1.0        0.0         0.0           0.0         1.0   \n",
       "73                   0.0        0.0         0.0           0.0         0.0   \n",
       "74                   1.0        0.0         0.0           0.0         1.0   \n",
       "75                   1.0        0.0         0.0           0.0         0.0   \n",
       "76                   1.0        0.0         0.0           0.0         0.0   \n",
       "77                   1.0        0.0         0.0           0.0         0.0   \n",
       "78                   1.0        0.0         0.0           0.0         0.0   \n",
       "79                   1.0        0.0         0.0           0.0         1.0   \n",
       "80                   1.0        1.0         0.0           0.0         0.0   \n",
       "81                   0.0        0.0         0.0           0.0         0.0   \n",
       "82                   1.0        0.0         0.0           0.0         0.0   \n",
       "83                   1.0        0.0         0.0           0.0         0.0   \n",
       "84                   1.0        0.0         0.0           0.0         0.0   \n",
       "85                   1.0        0.0         0.0           0.0         0.0   \n",
       "86                   1.0        0.0         0.0           0.0         1.0   \n",
       "87                   0.0        0.0         0.0           0.0         1.0   \n",
       "88                   1.0        0.0         0.0           0.0         1.0   \n",
       "89                   1.0        1.0         0.0           0.0         0.0   \n",
       "90                   1.0        0.0         0.0           0.0         0.0   \n",
       "91                   1.0        0.0         0.0           0.0         0.0   \n",
       "92                   0.0        0.0         0.0           0.0         0.0   \n",
       "93                   1.0        0.0         0.0           0.0         0.0   \n",
       "94                   1.0        0.0         0.0           0.0         0.0   \n",
       "95                   1.0        0.0         0.0           0.0         0.0   \n",
       "96                   1.0        0.0         0.0           0.0         0.0   \n",
       "97                   0.0        0.0         0.0           0.0         0.0   \n",
       "98                   1.0        0.0         0.0           0.0         1.0   \n",
       "99                   0.0        0.0         0.0           0.0         0.0   \n",
       "\n",
       "    Title_Mr  Title_Mrs  Title_Officer  Title_Royalty  \n",
       "0        1.0        0.0            0.0            0.0  \n",
       "1        0.0        1.0            0.0            0.0  \n",
       "2        1.0        0.0            0.0            0.0  \n",
       "3        1.0        0.0            0.0            0.0  \n",
       "4        0.0        1.0            0.0            0.0  \n",
       "5        1.0        0.0            0.0            0.0  \n",
       "6        0.0        0.0            0.0            0.0  \n",
       "7        1.0        0.0            0.0            0.0  \n",
       "8        0.0        1.0            0.0            0.0  \n",
       "9        1.0        0.0            0.0            0.0  \n",
       "10       1.0        0.0            0.0            0.0  \n",
       "11       1.0        0.0            0.0            0.0  \n",
       "12       0.0        1.0            0.0            0.0  \n",
       "13       1.0        0.0            0.0            0.0  \n",
       "14       0.0        1.0            0.0            0.0  \n",
       "15       0.0        1.0            0.0            0.0  \n",
       "16       1.0        0.0            0.0            0.0  \n",
       "17       1.0        0.0            0.0            0.0  \n",
       "18       0.0        0.0            0.0            0.0  \n",
       "19       0.0        1.0            0.0            0.0  \n",
       "20       1.0        0.0            0.0            0.0  \n",
       "21       0.0        0.0            0.0            0.0  \n",
       "22       0.0        1.0            0.0            0.0  \n",
       "23       1.0        0.0            0.0            0.0  \n",
       "24       0.0        1.0            0.0            0.0  \n",
       "25       1.0        0.0            0.0            0.0  \n",
       "26       0.0        0.0            0.0            0.0  \n",
       "27       1.0        0.0            0.0            0.0  \n",
       "28       1.0        0.0            0.0            0.0  \n",
       "29       1.0        0.0            0.0            0.0  \n",
       "..       ...        ...            ...            ...  \n",
       "70       0.0        0.0            0.0            0.0  \n",
       "71       1.0        0.0            0.0            0.0  \n",
       "72       0.0        0.0            0.0            0.0  \n",
       "73       1.0        0.0            0.0            0.0  \n",
       "74       0.0        0.0            0.0            0.0  \n",
       "75       1.0        0.0            0.0            0.0  \n",
       "76       1.0        0.0            0.0            0.0  \n",
       "77       0.0        1.0            0.0            0.0  \n",
       "78       1.0        0.0            0.0            0.0  \n",
       "79       0.0        0.0            0.0            0.0  \n",
       "80       0.0        0.0            0.0            0.0  \n",
       "81       1.0        0.0            0.0            0.0  \n",
       "82       1.0        0.0            0.0            0.0  \n",
       "83       1.0        0.0            0.0            0.0  \n",
       "84       1.0        0.0            0.0            0.0  \n",
       "85       1.0        0.0            0.0            0.0  \n",
       "86       0.0        0.0            0.0            0.0  \n",
       "87       0.0        0.0            0.0            0.0  \n",
       "88       0.0        0.0            0.0            0.0  \n",
       "89       0.0        0.0            0.0            0.0  \n",
       "90       0.0        1.0            0.0            0.0  \n",
       "91       1.0        0.0            0.0            0.0  \n",
       "92       0.0        1.0            0.0            0.0  \n",
       "93       1.0        0.0            0.0            0.0  \n",
       "94       1.0        0.0            0.0            0.0  \n",
       "95       1.0        0.0            0.0            0.0  \n",
       "96       0.0        1.0            0.0            0.0  \n",
       "97       1.0        0.0            0.0            0.0  \n",
       "98       0.0        0.0            0.0            0.0  \n",
       "99       1.0        0.0            0.0            0.0  \n",
       "\n",
       "[100 rows x 55 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_inspection.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:28:49.681804Z",
     "start_time": "2018-09-24T06:28:44.861953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Titanic: Machine Learning from Disaster"
     ]
    }
   ],
   "source": [
    "! kaggle competitions submit titanic -f titanic_result_feature_engineer_random_forest.csv -m \"feature engineer (fix ticket) + random forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:48:03.184053Z",
     "start_time": "2018-09-24T07:47:57.010174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "          classifiers=[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=8, max_features=4, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=3,\n",
       "            min_weight_fraction_...c_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
       "           weights='uniform'), GaussianNB(priors=None)],\n",
       "          meta_classifier=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          store_train_meta_features=False, use_clones=True,\n",
       "          use_features_in_secondary=False, use_probas=False, verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = KNeighborsClassifier(n_neighbors=2)\n",
    "clf3 = GaussianNB()\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[best_forest, ada_boosting, gradient_boosting, clf1, clf3], \n",
    "                          meta_classifier=lr)\n",
    "np.mean(cross_val_score(sclf, train_reduced, y, cv=5))\n",
    "sclf.fit(train_reduced, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:57:28.036289Z",
     "start_time": "2018-09-24T07:57:28.032290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reduced.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T08:02:18.986796Z",
     "start_time": "2018-09-24T08:00:53.707652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/1000\n",
      "712/712 [==============================] - 1s 971us/step - loss: 0.6998 - acc: 0.5084 - val_loss: 0.6752 - val_acc: 0.7095\n",
      "Epoch 2/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6893 - acc: 0.5478 - val_loss: 0.6751 - val_acc: 0.7095\n",
      "Epoch 3/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6964 - acc: 0.5028 - val_loss: 0.6751 - val_acc: 0.7095\n",
      "Epoch 4/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6903 - acc: 0.5295 - val_loss: 0.6751 - val_acc: 0.7095\n",
      "Epoch 5/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6889 - acc: 0.5520 - val_loss: 0.6751 - val_acc: 0.7095\n",
      "Epoch 6/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6967 - acc: 0.5098 - val_loss: 0.6751 - val_acc: 0.7095\n",
      "Epoch 7/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6919 - acc: 0.5281 - val_loss: 0.6751 - val_acc: 0.7095\n",
      "Epoch 8/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6953 - acc: 0.5154 - val_loss: 0.6750 - val_acc: 0.7095\n",
      "Epoch 9/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6930 - acc: 0.5239 - val_loss: 0.6750 - val_acc: 0.7095\n",
      "Epoch 10/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6935 - acc: 0.5295 - val_loss: 0.6750 - val_acc: 0.7095\n",
      "Epoch 11/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6908 - acc: 0.5028 - val_loss: 0.6750 - val_acc: 0.7095\n",
      "Epoch 12/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6877 - acc: 0.5393 - val_loss: 0.6750 - val_acc: 0.7095\n",
      "Epoch 13/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6969 - acc: 0.5098 - val_loss: 0.6749 - val_acc: 0.7095\n",
      "Epoch 14/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6940 - acc: 0.5309 - val_loss: 0.6749 - val_acc: 0.7095\n",
      "Epoch 15/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6845 - acc: 0.5646 - val_loss: 0.6749 - val_acc: 0.7095\n",
      "Epoch 16/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6863 - acc: 0.5646 - val_loss: 0.6749 - val_acc: 0.7095\n",
      "Epoch 17/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6926 - acc: 0.5365 - val_loss: 0.6749 - val_acc: 0.7095\n",
      "Epoch 18/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6955 - acc: 0.5379 - val_loss: 0.6749 - val_acc: 0.7095\n",
      "Epoch 19/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6871 - acc: 0.5492 - val_loss: 0.6748 - val_acc: 0.7095\n",
      "Epoch 20/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6883 - acc: 0.5506 - val_loss: 0.6748 - val_acc: 0.6983\n",
      "Epoch 21/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6934 - acc: 0.5070 - val_loss: 0.6748 - val_acc: 0.6983\n",
      "Epoch 22/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6989 - acc: 0.5056 - val_loss: 0.6748 - val_acc: 0.6983\n",
      "Epoch 23/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6856 - acc: 0.5379 - val_loss: 0.6748 - val_acc: 0.6983\n",
      "Epoch 24/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6954 - acc: 0.5028 - val_loss: 0.6747 - val_acc: 0.6983\n",
      "Epoch 25/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6930 - acc: 0.5084 - val_loss: 0.6747 - val_acc: 0.6983\n",
      "Epoch 26/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6911 - acc: 0.5323 - val_loss: 0.6747 - val_acc: 0.6983\n",
      "Epoch 27/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6905 - acc: 0.5309 - val_loss: 0.6747 - val_acc: 0.6983\n",
      "Epoch 28/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6875 - acc: 0.5407 - val_loss: 0.6747 - val_acc: 0.6983\n",
      "Epoch 29/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6977 - acc: 0.5084 - val_loss: 0.6747 - val_acc: 0.6983\n",
      "Epoch 30/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6911 - acc: 0.5337 - val_loss: 0.6746 - val_acc: 0.6983\n",
      "Epoch 31/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6954 - acc: 0.5267 - val_loss: 0.6746 - val_acc: 0.6983\n",
      "Epoch 32/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6900 - acc: 0.5267 - val_loss: 0.6746 - val_acc: 0.6983\n",
      "Epoch 33/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6888 - acc: 0.5548 - val_loss: 0.6746 - val_acc: 0.6983\n",
      "Epoch 34/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6942 - acc: 0.5154 - val_loss: 0.6746 - val_acc: 0.6983\n",
      "Epoch 35/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6962 - acc: 0.5183 - val_loss: 0.6746 - val_acc: 0.6983\n",
      "Epoch 36/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6873 - acc: 0.5730 - val_loss: 0.6745 - val_acc: 0.6927\n",
      "Epoch 37/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6954 - acc: 0.5098 - val_loss: 0.6745 - val_acc: 0.6927\n",
      "Epoch 38/1000\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6927 - acc: 0.5309 - val_loss: 0.6745 - val_acc: 0.6927\n",
      "Epoch 39/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6903 - acc: 0.5140 - val_loss: 0.6745 - val_acc: 0.6927\n",
      "Epoch 40/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6928 - acc: 0.5140 - val_loss: 0.6745 - val_acc: 0.6927\n",
      "Epoch 41/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6949 - acc: 0.5239 - val_loss: 0.6744 - val_acc: 0.6927\n",
      "Epoch 42/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6844 - acc: 0.5463 - val_loss: 0.6744 - val_acc: 0.6927\n",
      "Epoch 43/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6926 - acc: 0.5169 - val_loss: 0.6744 - val_acc: 0.6927\n",
      "Epoch 44/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6939 - acc: 0.5211 - val_loss: 0.6744 - val_acc: 0.6927\n",
      "Epoch 45/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6953 - acc: 0.5112 - val_loss: 0.6744 - val_acc: 0.6927\n",
      "Epoch 46/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6987 - acc: 0.5056 - val_loss: 0.6744 - val_acc: 0.6927\n",
      "Epoch 47/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6913 - acc: 0.5197 - val_loss: 0.6743 - val_acc: 0.6927\n",
      "Epoch 48/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6834 - acc: 0.5590 - val_loss: 0.6743 - val_acc: 0.6927\n",
      "Epoch 49/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6857 - acc: 0.5548 - val_loss: 0.6743 - val_acc: 0.6927\n",
      "Epoch 50/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6908 - acc: 0.5253 - val_loss: 0.6743 - val_acc: 0.6927\n",
      "Epoch 51/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6932 - acc: 0.5337 - val_loss: 0.6743 - val_acc: 0.6927\n",
      "Epoch 52/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6862 - acc: 0.5421 - val_loss: 0.6743 - val_acc: 0.6927\n",
      "Epoch 53/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6937 - acc: 0.5295 - val_loss: 0.6742 - val_acc: 0.6927\n",
      "Epoch 54/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6873 - acc: 0.5393 - val_loss: 0.6742 - val_acc: 0.6927\n",
      "Epoch 55/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.6879 - acc: 0.5295 - val_loss: 0.6742 - val_acc: 0.6927\n",
      "Epoch 56/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6854 - acc: 0.5365 - val_loss: 0.6742 - val_acc: 0.6927\n",
      "Epoch 57/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6922 - acc: 0.5253 - val_loss: 0.6742 - val_acc: 0.6927\n",
      "Epoch 58/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6921 - acc: 0.5225 - val_loss: 0.6741 - val_acc: 0.6927\n",
      "Epoch 59/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6891 - acc: 0.5295 - val_loss: 0.6741 - val_acc: 0.6927\n",
      "Epoch 60/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6932 - acc: 0.5239 - val_loss: 0.6741 - val_acc: 0.6927\n",
      "Epoch 61/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6879 - acc: 0.5295 - val_loss: 0.6741 - val_acc: 0.6927\n",
      "Epoch 62/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6863 - acc: 0.5421 - val_loss: 0.6741 - val_acc: 0.6927\n",
      "Epoch 63/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6902 - acc: 0.5379 - val_loss: 0.6741 - val_acc: 0.6927\n",
      "Epoch 64/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6948 - acc: 0.4874 - val_loss: 0.6740 - val_acc: 0.6927\n",
      "Epoch 65/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6926 - acc: 0.5112 - val_loss: 0.6740 - val_acc: 0.6927\n",
      "Epoch 66/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6902 - acc: 0.5492 - val_loss: 0.6740 - val_acc: 0.6927\n",
      "Epoch 67/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6972 - acc: 0.5154 - val_loss: 0.6740 - val_acc: 0.6927\n",
      "Epoch 68/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6827 - acc: 0.5632 - val_loss: 0.6740 - val_acc: 0.6927\n",
      "Epoch 69/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6929 - acc: 0.5253 - val_loss: 0.6739 - val_acc: 0.6927\n",
      "Epoch 70/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6933 - acc: 0.5211 - val_loss: 0.6739 - val_acc: 0.6927\n",
      "Epoch 71/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6845 - acc: 0.5365 - val_loss: 0.6739 - val_acc: 0.6927\n",
      "Epoch 72/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6914 - acc: 0.5337 - val_loss: 0.6739 - val_acc: 0.6927\n",
      "Epoch 73/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6940 - acc: 0.5211 - val_loss: 0.6739 - val_acc: 0.6927\n",
      "Epoch 74/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6916 - acc: 0.5197 - val_loss: 0.6738 - val_acc: 0.6927\n",
      "Epoch 75/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6922 - acc: 0.5323 - val_loss: 0.6738 - val_acc: 0.6927\n",
      "Epoch 76/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6945 - acc: 0.5393 - val_loss: 0.6738 - val_acc: 0.6927\n",
      "Epoch 77/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6912 - acc: 0.5267 - val_loss: 0.6738 - val_acc: 0.6927\n",
      "Epoch 78/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6854 - acc: 0.5295 - val_loss: 0.6738 - val_acc: 0.6927\n",
      "Epoch 79/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6896 - acc: 0.5421 - val_loss: 0.6738 - val_acc: 0.6927\n",
      "Epoch 80/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6945 - acc: 0.5295 - val_loss: 0.6737 - val_acc: 0.6927\n",
      "Epoch 81/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6926 - acc: 0.5365 - val_loss: 0.6737 - val_acc: 0.6927\n",
      "Epoch 82/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6873 - acc: 0.5365 - val_loss: 0.6737 - val_acc: 0.6927\n",
      "Epoch 83/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6932 - acc: 0.4972 - val_loss: 0.6737 - val_acc: 0.6927\n",
      "Epoch 84/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6925 - acc: 0.5393 - val_loss: 0.6737 - val_acc: 0.6927\n",
      "Epoch 85/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6975 - acc: 0.5014 - val_loss: 0.6737 - val_acc: 0.6927\n",
      "Epoch 86/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6912 - acc: 0.5393 - val_loss: 0.6736 - val_acc: 0.6927\n",
      "Epoch 87/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6904 - acc: 0.5183 - val_loss: 0.6736 - val_acc: 0.6927\n",
      "Epoch 88/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6924 - acc: 0.5393 - val_loss: 0.6736 - val_acc: 0.6927\n",
      "Epoch 89/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6917 - acc: 0.5449 - val_loss: 0.6736 - val_acc: 0.6927\n",
      "Epoch 90/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6866 - acc: 0.5421 - val_loss: 0.6736 - val_acc: 0.6927\n",
      "Epoch 91/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6920 - acc: 0.5197 - val_loss: 0.6736 - val_acc: 0.6927\n",
      "Epoch 92/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6855 - acc: 0.5646 - val_loss: 0.6735 - val_acc: 0.6927\n",
      "Epoch 93/1000\n",
      "712/712 [==============================] - 0s 158us/step - loss: 0.6876 - acc: 0.5323 - val_loss: 0.6735 - val_acc: 0.6927\n",
      "Epoch 94/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6930 - acc: 0.5295 - val_loss: 0.6735 - val_acc: 0.6927\n",
      "Epoch 95/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6850 - acc: 0.5716 - val_loss: 0.6735 - val_acc: 0.6927\n",
      "Epoch 96/1000\n",
      "712/712 [==============================] - 0s 177us/step - loss: 0.6876 - acc: 0.5337 - val_loss: 0.6735 - val_acc: 0.6927\n",
      "Epoch 97/1000\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.6836 - acc: 0.5534 - val_loss: 0.6734 - val_acc: 0.6927\n",
      "Epoch 98/1000\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.6916 - acc: 0.5281 - val_loss: 0.6734 - val_acc: 0.6927\n",
      "Epoch 99/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6875 - acc: 0.5688 - val_loss: 0.6734 - val_acc: 0.6927\n",
      "Epoch 100/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6870 - acc: 0.5337 - val_loss: 0.6734 - val_acc: 0.6927\n",
      "Epoch 101/1000\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.6850 - acc: 0.5520 - val_loss: 0.6734 - val_acc: 0.6927\n",
      "Epoch 102/1000\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.6905 - acc: 0.5239 - val_loss: 0.6734 - val_acc: 0.6927\n",
      "Epoch 103/1000\n",
      "712/712 [==============================] - 0s 183us/step - loss: 0.6873 - acc: 0.5492 - val_loss: 0.6733 - val_acc: 0.6927\n",
      "Epoch 104/1000\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.6895 - acc: 0.5337 - val_loss: 0.6733 - val_acc: 0.6927\n",
      "Epoch 105/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6931 - acc: 0.5478 - val_loss: 0.6733 - val_acc: 0.6927\n",
      "Epoch 106/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6933 - acc: 0.5197 - val_loss: 0.6733 - val_acc: 0.6927\n",
      "Epoch 107/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6932 - acc: 0.5225 - val_loss: 0.6733 - val_acc: 0.6927\n",
      "Epoch 108/1000\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.6934 - acc: 0.5407 - val_loss: 0.6732 - val_acc: 0.6927\n",
      "Epoch 109/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6927 - acc: 0.5365 - val_loss: 0.6732 - val_acc: 0.6927\n",
      "Epoch 110/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6929 - acc: 0.5042 - val_loss: 0.6732 - val_acc: 0.6927\n",
      "Epoch 111/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6884 - acc: 0.5337 - val_loss: 0.6732 - val_acc: 0.6927\n",
      "Epoch 112/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6908 - acc: 0.5520 - val_loss: 0.6732 - val_acc: 0.6927\n",
      "Epoch 113/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6932 - acc: 0.5309 - val_loss: 0.6732 - val_acc: 0.6927\n",
      "Epoch 114/1000\n",
      "712/712 [==============================] - 0s 158us/step - loss: 0.6857 - acc: 0.5449 - val_loss: 0.6731 - val_acc: 0.6927\n",
      "Epoch 115/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6894 - acc: 0.5323 - val_loss: 0.6731 - val_acc: 0.6927\n",
      "Epoch 116/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6892 - acc: 0.5281 - val_loss: 0.6731 - val_acc: 0.6927\n",
      "Epoch 117/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6890 - acc: 0.5351 - val_loss: 0.6731 - val_acc: 0.6927\n",
      "Epoch 118/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6887 - acc: 0.5169 - val_loss: 0.6731 - val_acc: 0.6927\n",
      "Epoch 119/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6982 - acc: 0.4860 - val_loss: 0.6731 - val_acc: 0.6927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6967 - acc: 0.5154 - val_loss: 0.6730 - val_acc: 0.6927\n",
      "Epoch 121/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6897 - acc: 0.5351 - val_loss: 0.6730 - val_acc: 0.6927\n",
      "Epoch 122/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6908 - acc: 0.5407 - val_loss: 0.6730 - val_acc: 0.6927\n",
      "Epoch 123/1000\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.6868 - acc: 0.5548 - val_loss: 0.6730 - val_acc: 0.6927\n",
      "Epoch 124/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6871 - acc: 0.5323 - val_loss: 0.6730 - val_acc: 0.6927\n",
      "Epoch 125/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6915 - acc: 0.5421 - val_loss: 0.6729 - val_acc: 0.6927\n",
      "Epoch 126/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6932 - acc: 0.5379 - val_loss: 0.6729 - val_acc: 0.6927\n",
      "Epoch 127/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6850 - acc: 0.5449 - val_loss: 0.6729 - val_acc: 0.6927\n",
      "Epoch 128/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6891 - acc: 0.5463 - val_loss: 0.6729 - val_acc: 0.6927\n",
      "Epoch 129/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6837 - acc: 0.5590 - val_loss: 0.6729 - val_acc: 0.6927\n",
      "Epoch 130/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6929 - acc: 0.5267 - val_loss: 0.6729 - val_acc: 0.6927\n",
      "Epoch 131/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6946 - acc: 0.5393 - val_loss: 0.6728 - val_acc: 0.6927\n",
      "Epoch 132/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6911 - acc: 0.5084 - val_loss: 0.6728 - val_acc: 0.6927\n",
      "Epoch 133/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6917 - acc: 0.5281 - val_loss: 0.6728 - val_acc: 0.6927\n",
      "Epoch 134/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6849 - acc: 0.5506 - val_loss: 0.6728 - val_acc: 0.6927\n",
      "Epoch 135/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6950 - acc: 0.5225 - val_loss: 0.6728 - val_acc: 0.6927\n",
      "Epoch 136/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6905 - acc: 0.5548 - val_loss: 0.6728 - val_acc: 0.6927\n",
      "Epoch 137/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6947 - acc: 0.5183 - val_loss: 0.6727 - val_acc: 0.6927\n",
      "Epoch 138/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6867 - acc: 0.5421 - val_loss: 0.6727 - val_acc: 0.6927\n",
      "Epoch 139/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6916 - acc: 0.4972 - val_loss: 0.6727 - val_acc: 0.6927\n",
      "Epoch 140/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6914 - acc: 0.5407 - val_loss: 0.6727 - val_acc: 0.6927\n",
      "Epoch 141/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6929 - acc: 0.5365 - val_loss: 0.6727 - val_acc: 0.6927\n",
      "Epoch 142/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6852 - acc: 0.5463 - val_loss: 0.6727 - val_acc: 0.6927\n",
      "Epoch 143/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6957 - acc: 0.5295 - val_loss: 0.6726 - val_acc: 0.6927\n",
      "Epoch 144/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6954 - acc: 0.5140 - val_loss: 0.6726 - val_acc: 0.6927\n",
      "Epoch 145/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6861 - acc: 0.5449 - val_loss: 0.6726 - val_acc: 0.6927\n",
      "Epoch 146/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6838 - acc: 0.5379 - val_loss: 0.6726 - val_acc: 0.6927\n",
      "Epoch 147/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6938 - acc: 0.5183 - val_loss: 0.6726 - val_acc: 0.6927\n",
      "Epoch 148/1000\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.6848 - acc: 0.5449 - val_loss: 0.6725 - val_acc: 0.6927\n",
      "Epoch 149/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6970 - acc: 0.5028 - val_loss: 0.6725 - val_acc: 0.6927\n",
      "Epoch 150/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6938 - acc: 0.5267 - val_loss: 0.6725 - val_acc: 0.6927\n",
      "Epoch 151/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6861 - acc: 0.5492 - val_loss: 0.6725 - val_acc: 0.6927\n",
      "Epoch 152/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6879 - acc: 0.5492 - val_loss: 0.6725 - val_acc: 0.6927\n",
      "Epoch 153/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6850 - acc: 0.5604 - val_loss: 0.6725 - val_acc: 0.6927\n",
      "Epoch 154/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6856 - acc: 0.5520 - val_loss: 0.6724 - val_acc: 0.6927\n",
      "Epoch 155/1000\n",
      "712/712 [==============================] - 0s 170us/step - loss: 0.6926 - acc: 0.5183 - val_loss: 0.6724 - val_acc: 0.6927\n",
      "Epoch 156/1000\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.6796 - acc: 0.5871 - val_loss: 0.6724 - val_acc: 0.6927\n",
      "Epoch 157/1000\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.6904 - acc: 0.5225 - val_loss: 0.6724 - val_acc: 0.6927\n",
      "Epoch 158/1000\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.6824 - acc: 0.5688 - val_loss: 0.6724 - val_acc: 0.6927\n",
      "Epoch 159/1000\n",
      "712/712 [==============================] - 0s 164us/step - loss: 0.6854 - acc: 0.5506 - val_loss: 0.6724 - val_acc: 0.6927\n",
      "Epoch 160/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6903 - acc: 0.5379 - val_loss: 0.6723 - val_acc: 0.6927\n",
      "Epoch 161/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6887 - acc: 0.5534 - val_loss: 0.6723 - val_acc: 0.6927\n",
      "Epoch 162/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6875 - acc: 0.5337 - val_loss: 0.6723 - val_acc: 0.6927\n",
      "Epoch 163/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6921 - acc: 0.5169 - val_loss: 0.6723 - val_acc: 0.6927\n",
      "Epoch 164/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6891 - acc: 0.5449 - val_loss: 0.6723 - val_acc: 0.6927\n",
      "Epoch 165/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6974 - acc: 0.5309 - val_loss: 0.6723 - val_acc: 0.6927\n",
      "Epoch 166/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6965 - acc: 0.4972 - val_loss: 0.6722 - val_acc: 0.6927\n",
      "Epoch 167/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6873 - acc: 0.5435 - val_loss: 0.6722 - val_acc: 0.6927\n",
      "Epoch 168/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6842 - acc: 0.5632 - val_loss: 0.6722 - val_acc: 0.6927\n",
      "Epoch 169/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6885 - acc: 0.5520 - val_loss: 0.6722 - val_acc: 0.6927\n",
      "Epoch 170/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6864 - acc: 0.5183 - val_loss: 0.6722 - val_acc: 0.6927\n",
      "Epoch 171/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6878 - acc: 0.5295 - val_loss: 0.6721 - val_acc: 0.6927\n",
      "Epoch 172/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6891 - acc: 0.5562 - val_loss: 0.6721 - val_acc: 0.6927\n",
      "Epoch 173/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6967 - acc: 0.5084 - val_loss: 0.6721 - val_acc: 0.6927\n",
      "Epoch 174/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6867 - acc: 0.5548 - val_loss: 0.6721 - val_acc: 0.6927\n",
      "Epoch 175/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6897 - acc: 0.5183 - val_loss: 0.6721 - val_acc: 0.6927\n",
      "Epoch 176/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6919 - acc: 0.5379 - val_loss: 0.6721 - val_acc: 0.6927\n",
      "Epoch 177/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6895 - acc: 0.5492 - val_loss: 0.6720 - val_acc: 0.6927\n",
      "Epoch 178/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6897 - acc: 0.5281 - val_loss: 0.6720 - val_acc: 0.6927\n",
      "Epoch 179/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6928 - acc: 0.5449 - val_loss: 0.6720 - val_acc: 0.6927\n",
      "Epoch 180/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6908 - acc: 0.5154 - val_loss: 0.6720 - val_acc: 0.6927\n",
      "Epoch 181/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6865 - acc: 0.5365 - val_loss: 0.6720 - val_acc: 0.6927\n",
      "Epoch 182/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6858 - acc: 0.5646 - val_loss: 0.6720 - val_acc: 0.6927\n",
      "Epoch 183/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6829 - acc: 0.5393 - val_loss: 0.6719 - val_acc: 0.6927\n",
      "Epoch 184/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6905 - acc: 0.5267 - val_loss: 0.6719 - val_acc: 0.6927\n",
      "Epoch 185/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6888 - acc: 0.5393 - val_loss: 0.6719 - val_acc: 0.6927\n",
      "Epoch 186/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6879 - acc: 0.5267 - val_loss: 0.6719 - val_acc: 0.6927\n",
      "Epoch 187/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6828 - acc: 0.5365 - val_loss: 0.6719 - val_acc: 0.6927\n",
      "Epoch 188/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6887 - acc: 0.5183 - val_loss: 0.6718 - val_acc: 0.6927\n",
      "Epoch 189/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6912 - acc: 0.5463 - val_loss: 0.6718 - val_acc: 0.6927\n",
      "Epoch 190/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6898 - acc: 0.5281 - val_loss: 0.6718 - val_acc: 0.6927\n",
      "Epoch 191/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6886 - acc: 0.5478 - val_loss: 0.6718 - val_acc: 0.6927\n",
      "Epoch 192/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6943 - acc: 0.5154 - val_loss: 0.6718 - val_acc: 0.6927\n",
      "Epoch 193/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6871 - acc: 0.5253 - val_loss: 0.6718 - val_acc: 0.6927\n",
      "Epoch 194/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6849 - acc: 0.5407 - val_loss: 0.6717 - val_acc: 0.6927\n",
      "Epoch 195/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6873 - acc: 0.5351 - val_loss: 0.6717 - val_acc: 0.6927\n",
      "Epoch 196/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6909 - acc: 0.5169 - val_loss: 0.6717 - val_acc: 0.6927\n",
      "Epoch 197/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6897 - acc: 0.5140 - val_loss: 0.6717 - val_acc: 0.6927\n",
      "Epoch 198/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6886 - acc: 0.5281 - val_loss: 0.6717 - val_acc: 0.6927\n",
      "Epoch 199/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6918 - acc: 0.5309 - val_loss: 0.6717 - val_acc: 0.6927\n",
      "Epoch 200/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6836 - acc: 0.5562 - val_loss: 0.6716 - val_acc: 0.6927\n",
      "Epoch 201/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6956 - acc: 0.5183 - val_loss: 0.6716 - val_acc: 0.6927\n",
      "Epoch 202/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6898 - acc: 0.5211 - val_loss: 0.6716 - val_acc: 0.6927\n",
      "Epoch 203/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6828 - acc: 0.5744 - val_loss: 0.6716 - val_acc: 0.6927\n",
      "Epoch 204/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6870 - acc: 0.5042 - val_loss: 0.6716 - val_acc: 0.6927\n",
      "Epoch 205/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6884 - acc: 0.5562 - val_loss: 0.6716 - val_acc: 0.6927\n",
      "Epoch 206/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6847 - acc: 0.5632 - val_loss: 0.6715 - val_acc: 0.6927\n",
      "Epoch 207/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6891 - acc: 0.5407 - val_loss: 0.6715 - val_acc: 0.6927\n",
      "Epoch 208/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6890 - acc: 0.5267 - val_loss: 0.6715 - val_acc: 0.6927\n",
      "Epoch 209/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6798 - acc: 0.5674 - val_loss: 0.6715 - val_acc: 0.6927\n",
      "Epoch 210/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6896 - acc: 0.5421 - val_loss: 0.6715 - val_acc: 0.6927\n",
      "Epoch 211/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6862 - acc: 0.5463 - val_loss: 0.6715 - val_acc: 0.6927\n",
      "Epoch 212/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6793 - acc: 0.5632 - val_loss: 0.6714 - val_acc: 0.6927\n",
      "Epoch 213/1000\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6861 - acc: 0.5548 - val_loss: 0.6714 - val_acc: 0.6983\n",
      "Epoch 214/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6902 - acc: 0.5365 - val_loss: 0.6714 - val_acc: 0.6983\n",
      "Epoch 215/1000\n",
      "712/712 [==============================] - 0s 163us/step - loss: 0.6816 - acc: 0.5520 - val_loss: 0.6714 - val_acc: 0.6983\n",
      "Epoch 216/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6965 - acc: 0.5098 - val_loss: 0.6714 - val_acc: 0.6983\n",
      "Epoch 217/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6911 - acc: 0.5211 - val_loss: 0.6714 - val_acc: 0.6983\n",
      "Epoch 218/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6845 - acc: 0.5435 - val_loss: 0.6713 - val_acc: 0.6983\n",
      "Epoch 219/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6946 - acc: 0.5098 - val_loss: 0.6713 - val_acc: 0.6983\n",
      "Epoch 220/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6848 - acc: 0.5253 - val_loss: 0.6713 - val_acc: 0.6983\n",
      "Epoch 221/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6899 - acc: 0.5197 - val_loss: 0.6713 - val_acc: 0.6983\n",
      "Epoch 222/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6855 - acc: 0.5365 - val_loss: 0.6713 - val_acc: 0.6983\n",
      "Epoch 223/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6884 - acc: 0.5562 - val_loss: 0.6713 - val_acc: 0.6983\n",
      "Epoch 224/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6907 - acc: 0.5548 - val_loss: 0.6712 - val_acc: 0.6983\n",
      "Epoch 225/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6893 - acc: 0.5239 - val_loss: 0.6712 - val_acc: 0.6983\n",
      "Epoch 226/1000\n",
      "712/712 [==============================] - 0s 158us/step - loss: 0.6934 - acc: 0.5154 - val_loss: 0.6712 - val_acc: 0.6983\n",
      "Epoch 227/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6867 - acc: 0.5337 - val_loss: 0.6712 - val_acc: 0.6983\n",
      "Epoch 228/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6904 - acc: 0.5239 - val_loss: 0.6712 - val_acc: 0.6983\n",
      "Epoch 229/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6951 - acc: 0.5028 - val_loss: 0.6712 - val_acc: 0.6983\n",
      "Epoch 230/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6859 - acc: 0.5351 - val_loss: 0.6711 - val_acc: 0.6983\n",
      "Epoch 231/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6905 - acc: 0.5126 - val_loss: 0.6711 - val_acc: 0.6983\n",
      "Epoch 232/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6887 - acc: 0.5112 - val_loss: 0.6711 - val_acc: 0.6983\n",
      "Epoch 233/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6795 - acc: 0.5843 - val_loss: 0.6711 - val_acc: 0.6983\n",
      "Epoch 234/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6899 - acc: 0.5323 - val_loss: 0.6711 - val_acc: 0.6983\n",
      "Epoch 235/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6852 - acc: 0.5421 - val_loss: 0.6711 - val_acc: 0.6983\n",
      "Epoch 236/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6821 - acc: 0.5618 - val_loss: 0.6710 - val_acc: 0.6983\n",
      "Epoch 237/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6856 - acc: 0.5407 - val_loss: 0.6710 - val_acc: 0.6983\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 138us/step - loss: 0.6839 - acc: 0.5435 - val_loss: 0.6710 - val_acc: 0.6983\n",
      "Epoch 239/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6899 - acc: 0.5421 - val_loss: 0.6710 - val_acc: 0.6983\n",
      "Epoch 240/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6904 - acc: 0.5604 - val_loss: 0.6710 - val_acc: 0.6983\n",
      "Epoch 241/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6839 - acc: 0.5744 - val_loss: 0.6710 - val_acc: 0.6983\n",
      "Epoch 242/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6950 - acc: 0.5183 - val_loss: 0.6709 - val_acc: 0.6983\n",
      "Epoch 243/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6897 - acc: 0.5309 - val_loss: 0.6709 - val_acc: 0.6983\n",
      "Epoch 244/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6763 - acc: 0.5702 - val_loss: 0.6709 - val_acc: 0.6983\n",
      "Epoch 245/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6813 - acc: 0.5674 - val_loss: 0.6709 - val_acc: 0.6983\n",
      "Epoch 246/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6751 - acc: 0.5913 - val_loss: 0.6709 - val_acc: 0.6983\n",
      "Epoch 247/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6895 - acc: 0.5225 - val_loss: 0.6708 - val_acc: 0.6983\n",
      "Epoch 248/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6849 - acc: 0.5449 - val_loss: 0.6708 - val_acc: 0.6983\n",
      "Epoch 249/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6923 - acc: 0.5421 - val_loss: 0.6708 - val_acc: 0.6983\n",
      "Epoch 250/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6949 - acc: 0.5014 - val_loss: 0.6708 - val_acc: 0.6983\n",
      "Epoch 251/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6861 - acc: 0.5323 - val_loss: 0.6708 - val_acc: 0.6983\n",
      "Epoch 252/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6866 - acc: 0.5407 - val_loss: 0.6708 - val_acc: 0.6983\n",
      "Epoch 253/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.6808 - acc: 0.5646 - val_loss: 0.6707 - val_acc: 0.6983\n",
      "Epoch 254/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6847 - acc: 0.5506 - val_loss: 0.6707 - val_acc: 0.6983\n",
      "Epoch 255/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.6947 - acc: 0.5183 - val_loss: 0.6707 - val_acc: 0.6983\n",
      "Epoch 256/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6868 - acc: 0.5449 - val_loss: 0.6707 - val_acc: 0.6983\n",
      "Epoch 257/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6839 - acc: 0.5632 - val_loss: 0.6707 - val_acc: 0.6983\n",
      "Epoch 258/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6804 - acc: 0.5478 - val_loss: 0.6707 - val_acc: 0.6983\n",
      "Epoch 259/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6867 - acc: 0.5604 - val_loss: 0.6706 - val_acc: 0.6983\n",
      "Epoch 260/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6914 - acc: 0.5337 - val_loss: 0.6706 - val_acc: 0.6983\n",
      "Epoch 261/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6883 - acc: 0.5253 - val_loss: 0.6706 - val_acc: 0.6983\n",
      "Epoch 262/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6802 - acc: 0.5787 - val_loss: 0.6706 - val_acc: 0.6983\n",
      "Epoch 263/1000\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.6936 - acc: 0.5183 - val_loss: 0.6706 - val_acc: 0.6983\n",
      "Epoch 264/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6779 - acc: 0.5646 - val_loss: 0.6706 - val_acc: 0.6704\n",
      "Epoch 265/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6845 - acc: 0.5393 - val_loss: 0.6705 - val_acc: 0.6704\n",
      "Epoch 266/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6898 - acc: 0.5154 - val_loss: 0.6705 - val_acc: 0.6704\n",
      "Epoch 267/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6899 - acc: 0.5323 - val_loss: 0.6705 - val_acc: 0.6704\n",
      "Epoch 268/1000\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.6868 - acc: 0.5407 - val_loss: 0.6705 - val_acc: 0.6704\n",
      "Epoch 269/1000\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.6911 - acc: 0.5197 - val_loss: 0.6705 - val_acc: 0.6704\n",
      "Epoch 270/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6960 - acc: 0.4986 - val_loss: 0.6705 - val_acc: 0.6704\n",
      "Epoch 271/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6875 - acc: 0.5379 - val_loss: 0.6704 - val_acc: 0.6704\n",
      "Epoch 272/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6906 - acc: 0.5253 - val_loss: 0.6704 - val_acc: 0.6704\n",
      "Epoch 273/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6819 - acc: 0.5730 - val_loss: 0.6704 - val_acc: 0.6704\n",
      "Epoch 274/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6916 - acc: 0.5323 - val_loss: 0.6704 - val_acc: 0.6704\n",
      "Epoch 275/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6843 - acc: 0.5520 - val_loss: 0.6704 - val_acc: 0.6704\n",
      "Epoch 276/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6878 - acc: 0.5365 - val_loss: 0.6704 - val_acc: 0.6704\n",
      "Epoch 277/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6904 - acc: 0.5253 - val_loss: 0.6703 - val_acc: 0.6704\n",
      "Epoch 278/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6937 - acc: 0.5169 - val_loss: 0.6703 - val_acc: 0.6704\n",
      "Epoch 279/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6812 - acc: 0.5843 - val_loss: 0.6703 - val_acc: 0.6704\n",
      "Epoch 280/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6955 - acc: 0.5239 - val_loss: 0.6703 - val_acc: 0.6704\n",
      "Epoch 281/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6906 - acc: 0.5154 - val_loss: 0.6703 - val_acc: 0.6704\n",
      "Epoch 282/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6821 - acc: 0.5590 - val_loss: 0.6703 - val_acc: 0.6704\n",
      "Epoch 283/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6879 - acc: 0.5323 - val_loss: 0.6702 - val_acc: 0.6704\n",
      "Epoch 284/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6943 - acc: 0.5281 - val_loss: 0.6702 - val_acc: 0.6704\n",
      "Epoch 285/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6836 - acc: 0.5534 - val_loss: 0.6702 - val_acc: 0.6704\n",
      "Epoch 286/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6862 - acc: 0.5660 - val_loss: 0.6702 - val_acc: 0.6704\n",
      "Epoch 287/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6856 - acc: 0.5379 - val_loss: 0.6702 - val_acc: 0.6704\n",
      "Epoch 288/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6863 - acc: 0.5576 - val_loss: 0.6702 - val_acc: 0.6704\n",
      "Epoch 289/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6879 - acc: 0.5393 - val_loss: 0.6701 - val_acc: 0.6704\n",
      "Epoch 290/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6869 - acc: 0.5674 - val_loss: 0.6701 - val_acc: 0.6704\n",
      "Epoch 291/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6997 - acc: 0.4944 - val_loss: 0.6701 - val_acc: 0.6704\n",
      "Epoch 292/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6906 - acc: 0.5197 - val_loss: 0.6701 - val_acc: 0.6704\n",
      "Epoch 293/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6851 - acc: 0.5393 - val_loss: 0.6701 - val_acc: 0.6704\n",
      "Epoch 294/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6835 - acc: 0.5449 - val_loss: 0.6700 - val_acc: 0.6704\n",
      "Epoch 295/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6865 - acc: 0.5478 - val_loss: 0.6700 - val_acc: 0.6704\n",
      "Epoch 296/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6831 - acc: 0.5379 - val_loss: 0.6700 - val_acc: 0.6704\n",
      "Epoch 297/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6913 - acc: 0.5140 - val_loss: 0.6700 - val_acc: 0.6704\n",
      "Epoch 298/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6839 - acc: 0.5772 - val_loss: 0.6700 - val_acc: 0.6704\n",
      "Epoch 299/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6818 - acc: 0.5590 - val_loss: 0.6700 - val_acc: 0.6704\n",
      "Epoch 300/1000\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.6878 - acc: 0.5295 - val_loss: 0.6699 - val_acc: 0.6704\n",
      "Epoch 301/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6926 - acc: 0.5140 - val_loss: 0.6699 - val_acc: 0.6704\n",
      "Epoch 302/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6891 - acc: 0.5183 - val_loss: 0.6699 - val_acc: 0.6704\n",
      "Epoch 303/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6868 - acc: 0.5351 - val_loss: 0.6699 - val_acc: 0.6704\n",
      "Epoch 304/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6887 - acc: 0.5323 - val_loss: 0.6699 - val_acc: 0.6704\n",
      "Epoch 305/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6894 - acc: 0.5197 - val_loss: 0.6699 - val_acc: 0.6704\n",
      "Epoch 306/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6929 - acc: 0.5154 - val_loss: 0.6698 - val_acc: 0.6704\n",
      "Epoch 307/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6879 - acc: 0.5478 - val_loss: 0.6698 - val_acc: 0.6704\n",
      "Epoch 308/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6948 - acc: 0.5028 - val_loss: 0.6698 - val_acc: 0.6704\n",
      "Epoch 309/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6936 - acc: 0.5225 - val_loss: 0.6698 - val_acc: 0.6704\n",
      "Epoch 310/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6872 - acc: 0.5478 - val_loss: 0.6698 - val_acc: 0.6704\n",
      "Epoch 311/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6879 - acc: 0.5183 - val_loss: 0.6698 - val_acc: 0.6704\n",
      "Epoch 312/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6909 - acc: 0.5197 - val_loss: 0.6697 - val_acc: 0.6704\n",
      "Epoch 313/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6822 - acc: 0.5716 - val_loss: 0.6697 - val_acc: 0.6704\n",
      "Epoch 314/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6881 - acc: 0.5435 - val_loss: 0.6697 - val_acc: 0.6704\n",
      "Epoch 315/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6890 - acc: 0.5281 - val_loss: 0.6697 - val_acc: 0.6704\n",
      "Epoch 316/1000\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.6919 - acc: 0.5309 - val_loss: 0.6697 - val_acc: 0.6704\n",
      "Epoch 317/1000\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.6833 - acc: 0.5590 - val_loss: 0.6697 - val_acc: 0.6704\n",
      "Epoch 318/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6925 - acc: 0.5337 - val_loss: 0.6696 - val_acc: 0.6704\n",
      "Epoch 319/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6783 - acc: 0.5604 - val_loss: 0.6696 - val_acc: 0.6704\n",
      "Epoch 320/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6758 - acc: 0.6025 - val_loss: 0.6696 - val_acc: 0.6704\n",
      "Epoch 321/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6925 - acc: 0.5379 - val_loss: 0.6696 - val_acc: 0.6704\n",
      "Epoch 322/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6956 - acc: 0.5112 - val_loss: 0.6696 - val_acc: 0.6704\n",
      "Epoch 323/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.7000 - acc: 0.5070 - val_loss: 0.6696 - val_acc: 0.6704\n",
      "Epoch 324/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6747 - acc: 0.5969 - val_loss: 0.6695 - val_acc: 0.6704\n",
      "Epoch 325/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6890 - acc: 0.5351 - val_loss: 0.6695 - val_acc: 0.6704\n",
      "Epoch 326/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6957 - acc: 0.5281 - val_loss: 0.6695 - val_acc: 0.6704\n",
      "Epoch 327/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6854 - acc: 0.5463 - val_loss: 0.6695 - val_acc: 0.6704\n",
      "Epoch 328/1000\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6936 - acc: 0.5098 - val_loss: 0.6695 - val_acc: 0.6704\n",
      "Epoch 329/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6904 - acc: 0.5281 - val_loss: 0.6695 - val_acc: 0.6704\n",
      "Epoch 330/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6906 - acc: 0.5309 - val_loss: 0.6694 - val_acc: 0.6704\n",
      "Epoch 331/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6886 - acc: 0.5183 - val_loss: 0.6694 - val_acc: 0.6704\n",
      "Epoch 332/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6893 - acc: 0.5281 - val_loss: 0.6694 - val_acc: 0.6704\n",
      "Epoch 333/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6868 - acc: 0.5506 - val_loss: 0.6694 - val_acc: 0.6704\n",
      "Epoch 334/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6812 - acc: 0.5702 - val_loss: 0.6694 - val_acc: 0.6704\n",
      "Epoch 335/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6867 - acc: 0.5520 - val_loss: 0.6694 - val_acc: 0.6704\n",
      "Epoch 336/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6872 - acc: 0.5463 - val_loss: 0.6693 - val_acc: 0.6704\n",
      "Epoch 337/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6930 - acc: 0.5239 - val_loss: 0.6693 - val_acc: 0.6704\n",
      "Epoch 338/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6832 - acc: 0.5632 - val_loss: 0.6693 - val_acc: 0.6704\n",
      "Epoch 339/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6850 - acc: 0.5449 - val_loss: 0.6693 - val_acc: 0.6704\n",
      "Epoch 340/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6897 - acc: 0.5323 - val_loss: 0.6693 - val_acc: 0.6704\n",
      "Epoch 341/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6882 - acc: 0.5449 - val_loss: 0.6693 - val_acc: 0.6704\n",
      "Epoch 342/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6891 - acc: 0.5337 - val_loss: 0.6692 - val_acc: 0.6704\n",
      "Epoch 343/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6860 - acc: 0.5267 - val_loss: 0.6692 - val_acc: 0.6704\n",
      "Epoch 344/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6870 - acc: 0.5449 - val_loss: 0.6692 - val_acc: 0.6704\n",
      "Epoch 345/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6910 - acc: 0.5295 - val_loss: 0.6692 - val_acc: 0.6704\n",
      "Epoch 346/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6947 - acc: 0.5309 - val_loss: 0.6692 - val_acc: 0.6704\n",
      "Epoch 347/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6770 - acc: 0.5857 - val_loss: 0.6692 - val_acc: 0.6704\n",
      "Epoch 348/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6854 - acc: 0.5590 - val_loss: 0.6691 - val_acc: 0.6704\n",
      "Epoch 349/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6887 - acc: 0.5183 - val_loss: 0.6691 - val_acc: 0.6704\n",
      "Epoch 350/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6874 - acc: 0.5126 - val_loss: 0.6691 - val_acc: 0.6704\n",
      "Epoch 351/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.6790 - acc: 0.5885 - val_loss: 0.6691 - val_acc: 0.6704\n",
      "Epoch 352/1000\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.6816 - acc: 0.5758 - val_loss: 0.6691 - val_acc: 0.6704\n",
      "Epoch 353/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.6896 - acc: 0.5351 - val_loss: 0.6691 - val_acc: 0.6704\n",
      "Epoch 354/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.6800 - acc: 0.5562 - val_loss: 0.6690 - val_acc: 0.6704\n",
      "Epoch 355/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.6837 - acc: 0.5281 - val_loss: 0.6690 - val_acc: 0.6704\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 109us/step - loss: 0.6889 - acc: 0.5478 - val_loss: 0.6690 - val_acc: 0.6704\n",
      "Epoch 357/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6941 - acc: 0.5112 - val_loss: 0.6690 - val_acc: 0.6704\n",
      "Epoch 358/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6838 - acc: 0.5646 - val_loss: 0.6690 - val_acc: 0.6704\n",
      "Epoch 359/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6912 - acc: 0.5112 - val_loss: 0.6690 - val_acc: 0.6704\n",
      "Epoch 360/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6926 - acc: 0.5351 - val_loss: 0.6689 - val_acc: 0.6704\n",
      "Epoch 361/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6870 - acc: 0.5463 - val_loss: 0.6689 - val_acc: 0.6704\n",
      "Epoch 362/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6884 - acc: 0.5295 - val_loss: 0.6689 - val_acc: 0.6704\n",
      "Epoch 363/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6920 - acc: 0.5140 - val_loss: 0.6689 - val_acc: 0.6704\n",
      "Epoch 364/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.6872 - acc: 0.5407 - val_loss: 0.6689 - val_acc: 0.6704\n",
      "Epoch 365/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.6856 - acc: 0.5520 - val_loss: 0.6688 - val_acc: 0.6704\n",
      "Epoch 366/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6881 - acc: 0.5239 - val_loss: 0.6688 - val_acc: 0.6704\n",
      "Epoch 367/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6895 - acc: 0.5393 - val_loss: 0.6688 - val_acc: 0.6704\n",
      "Epoch 368/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6813 - acc: 0.5604 - val_loss: 0.6688 - val_acc: 0.6704\n",
      "Epoch 369/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6897 - acc: 0.5225 - val_loss: 0.6688 - val_acc: 0.6704\n",
      "Epoch 370/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6838 - acc: 0.5688 - val_loss: 0.6688 - val_acc: 0.6704\n",
      "Epoch 371/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6918 - acc: 0.5421 - val_loss: 0.6688 - val_acc: 0.6704\n",
      "Epoch 372/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6878 - acc: 0.5365 - val_loss: 0.6687 - val_acc: 0.6704\n",
      "Epoch 373/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6896 - acc: 0.5295 - val_loss: 0.6687 - val_acc: 0.6704\n",
      "Epoch 374/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6872 - acc: 0.5267 - val_loss: 0.6687 - val_acc: 0.6704\n",
      "Epoch 375/1000\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.6905 - acc: 0.5225 - val_loss: 0.6687 - val_acc: 0.6704\n",
      "Epoch 376/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6903 - acc: 0.5351 - val_loss: 0.6687 - val_acc: 0.6592\n",
      "Epoch 377/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6876 - acc: 0.5281 - val_loss: 0.6687 - val_acc: 0.6592\n",
      "Epoch 378/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6866 - acc: 0.5379 - val_loss: 0.6686 - val_acc: 0.6592\n",
      "Epoch 379/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6832 - acc: 0.5407 - val_loss: 0.6686 - val_acc: 0.6592\n",
      "Epoch 380/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.6886 - acc: 0.5478 - val_loss: 0.6686 - val_acc: 0.6592\n",
      "Epoch 381/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6864 - acc: 0.5365 - val_loss: 0.6686 - val_acc: 0.6592\n",
      "Epoch 382/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.6797 - acc: 0.5492 - val_loss: 0.6686 - val_acc: 0.6592\n",
      "Epoch 383/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.6902 - acc: 0.5309 - val_loss: 0.6686 - val_acc: 0.6592\n",
      "Epoch 384/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6860 - acc: 0.5506 - val_loss: 0.6685 - val_acc: 0.6592\n",
      "Epoch 385/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.6900 - acc: 0.5351 - val_loss: 0.6685 - val_acc: 0.6592\n",
      "Epoch 386/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6879 - acc: 0.5351 - val_loss: 0.6685 - val_acc: 0.6592\n",
      "Epoch 387/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6854 - acc: 0.5744 - val_loss: 0.6685 - val_acc: 0.6592\n",
      "Epoch 388/1000\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.6848 - acc: 0.5674 - val_loss: 0.6685 - val_acc: 0.6592\n",
      "Epoch 389/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6878 - acc: 0.5506 - val_loss: 0.6685 - val_acc: 0.6592\n",
      "Epoch 390/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6850 - acc: 0.5435 - val_loss: 0.6684 - val_acc: 0.6592\n",
      "Epoch 391/1000\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.6793 - acc: 0.5899 - val_loss: 0.6684 - val_acc: 0.6592\n",
      "Epoch 392/1000\n",
      "712/712 [==============================] - 0s 163us/step - loss: 0.6870 - acc: 0.5309 - val_loss: 0.6684 - val_acc: 0.6592\n",
      "Epoch 393/1000\n",
      "712/712 [==============================] - 0s 171us/step - loss: 0.6882 - acc: 0.5337 - val_loss: 0.6684 - val_acc: 0.6592\n",
      "Epoch 394/1000\n",
      "712/712 [==============================] - 0s 169us/step - loss: 0.6784 - acc: 0.5857 - val_loss: 0.6684 - val_acc: 0.6592\n",
      "Epoch 395/1000\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.6825 - acc: 0.5688 - val_loss: 0.6684 - val_acc: 0.6592\n",
      "Epoch 396/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6868 - acc: 0.5323 - val_loss: 0.6683 - val_acc: 0.6592\n",
      "Epoch 397/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6909 - acc: 0.5534 - val_loss: 0.6683 - val_acc: 0.6592\n",
      "Epoch 398/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6944 - acc: 0.5211 - val_loss: 0.6683 - val_acc: 0.6592\n",
      "Epoch 399/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6864 - acc: 0.5492 - val_loss: 0.6683 - val_acc: 0.6592\n",
      "Epoch 400/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6909 - acc: 0.5225 - val_loss: 0.6683 - val_acc: 0.6592\n",
      "Epoch 401/1000\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6903 - acc: 0.5126 - val_loss: 0.6683 - val_acc: 0.6592\n",
      "Epoch 402/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6873 - acc: 0.5351 - val_loss: 0.6682 - val_acc: 0.6592\n",
      "Epoch 403/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6849 - acc: 0.5435 - val_loss: 0.6682 - val_acc: 0.6592\n",
      "Epoch 404/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6829 - acc: 0.5562 - val_loss: 0.6682 - val_acc: 0.6592\n",
      "Epoch 405/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.6858 - acc: 0.5323 - val_loss: 0.6682 - val_acc: 0.6592\n",
      "Epoch 406/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6839 - acc: 0.5365 - val_loss: 0.6682 - val_acc: 0.6592\n",
      "Epoch 407/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6916 - acc: 0.5323 - val_loss: 0.6682 - val_acc: 0.6592\n",
      "Epoch 408/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6886 - acc: 0.5295 - val_loss: 0.6681 - val_acc: 0.6592\n",
      "Epoch 409/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6934 - acc: 0.5140 - val_loss: 0.6681 - val_acc: 0.6592\n",
      "Epoch 410/1000\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.6865 - acc: 0.5435 - val_loss: 0.6681 - val_acc: 0.6592\n",
      "Epoch 411/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6830 - acc: 0.5758 - val_loss: 0.6681 - val_acc: 0.6592\n",
      "Epoch 412/1000\n",
      "712/712 [==============================] - 0s 176us/step - loss: 0.6882 - acc: 0.5506 - val_loss: 0.6681 - val_acc: 0.6592\n",
      "Epoch 413/1000\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6810 - acc: 0.5618 - val_loss: 0.6681 - val_acc: 0.6592\n",
      "Epoch 414/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6860 - acc: 0.5548 - val_loss: 0.6680 - val_acc: 0.6592\n",
      "Epoch 415/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6856 - acc: 0.5604 - val_loss: 0.6680 - val_acc: 0.6592\n",
      "Epoch 416/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6810 - acc: 0.5576 - val_loss: 0.6680 - val_acc: 0.6592\n",
      "Epoch 417/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6900 - acc: 0.5463 - val_loss: 0.6680 - val_acc: 0.6592\n",
      "Epoch 418/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.6885 - acc: 0.5267 - val_loss: 0.6680 - val_acc: 0.6592\n",
      "Epoch 419/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6847 - acc: 0.5744 - val_loss: 0.6680 - val_acc: 0.6592\n",
      "Epoch 420/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6876 - acc: 0.5562 - val_loss: 0.6679 - val_acc: 0.6592\n",
      "Epoch 421/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6821 - acc: 0.5660 - val_loss: 0.6679 - val_acc: 0.6592\n",
      "Epoch 422/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6890 - acc: 0.5183 - val_loss: 0.6679 - val_acc: 0.6592\n",
      "Epoch 423/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6856 - acc: 0.5548 - val_loss: 0.6679 - val_acc: 0.6592\n",
      "Epoch 424/1000\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.6934 - acc: 0.5211 - val_loss: 0.6679 - val_acc: 0.6592\n",
      "Epoch 425/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6841 - acc: 0.5604 - val_loss: 0.6679 - val_acc: 0.6592\n",
      "Epoch 426/1000\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.6996 - acc: 0.502 - 0s 135us/step - loss: 0.6954 - acc: 0.5239 - val_loss: 0.6678 - val_acc: 0.6592\n",
      "Epoch 427/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.6847 - acc: 0.5337 - val_loss: 0.6678 - val_acc: 0.6592\n",
      "Epoch 428/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.6895 - acc: 0.5520 - val_loss: 0.6678 - val_acc: 0.6592\n",
      "Epoch 429/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.6920 - acc: 0.5478 - val_loss: 0.6678 - val_acc: 0.6592\n",
      "Epoch 430/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6807 - acc: 0.5520 - val_loss: 0.6678 - val_acc: 0.6592\n",
      "Epoch 431/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6900 - acc: 0.5239 - val_loss: 0.6678 - val_acc: 0.6592\n",
      "Epoch 432/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6883 - acc: 0.5309 - val_loss: 0.6677 - val_acc: 0.6592\n",
      "Epoch 433/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6857 - acc: 0.5506 - val_loss: 0.6677 - val_acc: 0.6592\n",
      "Epoch 434/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6930 - acc: 0.5098 - val_loss: 0.6677 - val_acc: 0.6592\n",
      "Epoch 435/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6870 - acc: 0.5351 - val_loss: 0.6677 - val_acc: 0.6592\n",
      "Epoch 436/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6833 - acc: 0.5688 - val_loss: 0.6677 - val_acc: 0.6592\n",
      "Epoch 437/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6932 - acc: 0.5225 - val_loss: 0.6677 - val_acc: 0.6592\n",
      "Epoch 438/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.6891 - acc: 0.5365 - val_loss: 0.6676 - val_acc: 0.6592\n",
      "Epoch 439/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6864 - acc: 0.5351 - val_loss: 0.6676 - val_acc: 0.6592\n",
      "Epoch 440/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6890 - acc: 0.5140 - val_loss: 0.6676 - val_acc: 0.6592\n",
      "Epoch 441/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6868 - acc: 0.5393 - val_loss: 0.6676 - val_acc: 0.6592\n",
      "Epoch 442/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.6820 - acc: 0.5520 - val_loss: 0.6676 - val_acc: 0.6592\n",
      "Epoch 443/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.6810 - acc: 0.5590 - val_loss: 0.6676 - val_acc: 0.6592\n",
      "Epoch 444/1000\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.6856 - acc: 0.5393 - val_loss: 0.6675 - val_acc: 0.6592\n",
      "Epoch 445/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6837 - acc: 0.5618 - val_loss: 0.6675 - val_acc: 0.6592\n",
      "Epoch 446/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.6901 - acc: 0.5449 - val_loss: 0.6675 - val_acc: 0.6592\n",
      "Epoch 447/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.6927 - acc: 0.5211 - val_loss: 0.6675 - val_acc: 0.6592\n",
      "Epoch 448/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.6824 - acc: 0.5435 - val_loss: 0.6675 - val_acc: 0.6592\n",
      "Epoch 449/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6750 - acc: 0.5829 - val_loss: 0.6675 - val_acc: 0.6592\n",
      "Epoch 450/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6865 - acc: 0.5534 - val_loss: 0.6675 - val_acc: 0.6592\n",
      "Epoch 451/1000\n",
      "712/712 [==============================] - 0s 158us/step - loss: 0.6866 - acc: 0.5421 - val_loss: 0.6674 - val_acc: 0.6592\n",
      "Epoch 452/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6794 - acc: 0.5815 - val_loss: 0.6674 - val_acc: 0.6592\n",
      "Epoch 453/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6832 - acc: 0.5463 - val_loss: 0.6674 - val_acc: 0.6592\n",
      "Epoch 454/1000\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.6781 - acc: 0.5787 - val_loss: 0.6674 - val_acc: 0.6592\n",
      "Epoch 455/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6806 - acc: 0.5365 - val_loss: 0.6674 - val_acc: 0.6592\n",
      "Epoch 456/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6813 - acc: 0.5801 - val_loss: 0.6674 - val_acc: 0.6592\n",
      "Epoch 457/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6766 - acc: 0.5801 - val_loss: 0.6673 - val_acc: 0.6592\n",
      "Epoch 458/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6839 - acc: 0.5646 - val_loss: 0.6673 - val_acc: 0.6592\n",
      "Epoch 459/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6890 - acc: 0.5323 - val_loss: 0.6673 - val_acc: 0.6592\n",
      "Epoch 460/1000\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6910 - acc: 0.5169 - val_loss: 0.6673 - val_acc: 0.6592\n",
      "Epoch 461/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6906 - acc: 0.5323 - val_loss: 0.6673 - val_acc: 0.6592\n",
      "Epoch 462/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6862 - acc: 0.5492 - val_loss: 0.6673 - val_acc: 0.6592\n",
      "Epoch 463/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6825 - acc: 0.5548 - val_loss: 0.6672 - val_acc: 0.6592\n",
      "Epoch 464/1000\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.6908 - acc: 0.5449 - val_loss: 0.6672 - val_acc: 0.6592\n",
      "Epoch 465/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6910 - acc: 0.5295 - val_loss: 0.6672 - val_acc: 0.6592\n",
      "Epoch 466/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6915 - acc: 0.5239 - val_loss: 0.6672 - val_acc: 0.6592\n",
      "Epoch 467/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6808 - acc: 0.5548 - val_loss: 0.6672 - val_acc: 0.6592\n",
      "Epoch 468/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6871 - acc: 0.5492 - val_loss: 0.6672 - val_acc: 0.6592\n",
      "Epoch 469/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6828 - acc: 0.5576 - val_loss: 0.6671 - val_acc: 0.6592\n",
      "Epoch 470/1000\n",
      "712/712 [==============================] - 0s 164us/step - loss: 0.6817 - acc: 0.5393 - val_loss: 0.6671 - val_acc: 0.6592\n",
      "Epoch 471/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6845 - acc: 0.5646 - val_loss: 0.6671 - val_acc: 0.6592\n",
      "Epoch 472/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6827 - acc: 0.5829 - val_loss: 0.6671 - val_acc: 0.6592\n",
      "Epoch 473/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6809 - acc: 0.5492 - val_loss: 0.6671 - val_acc: 0.6592\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 128us/step - loss: 0.6874 - acc: 0.5463 - val_loss: 0.6671 - val_acc: 0.6592\n",
      "Epoch 475/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6838 - acc: 0.5534 - val_loss: 0.6670 - val_acc: 0.6592\n",
      "Epoch 476/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6828 - acc: 0.5478 - val_loss: 0.6670 - val_acc: 0.6592\n",
      "Epoch 477/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6805 - acc: 0.5646 - val_loss: 0.6670 - val_acc: 0.6592\n",
      "Epoch 478/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6914 - acc: 0.5225 - val_loss: 0.6670 - val_acc: 0.6592\n",
      "Epoch 479/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6775 - acc: 0.5955 - val_loss: 0.6670 - val_acc: 0.6592\n",
      "Epoch 480/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6898 - acc: 0.5435 - val_loss: 0.6670 - val_acc: 0.6592\n",
      "Epoch 481/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6866 - acc: 0.5506 - val_loss: 0.6670 - val_acc: 0.6592\n",
      "Epoch 482/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6807 - acc: 0.5604 - val_loss: 0.6669 - val_acc: 0.6592\n",
      "Epoch 483/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6815 - acc: 0.5590 - val_loss: 0.6669 - val_acc: 0.6592\n",
      "Epoch 484/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6869 - acc: 0.5351 - val_loss: 0.6669 - val_acc: 0.6592\n",
      "Epoch 485/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6842 - acc: 0.5674 - val_loss: 0.6669 - val_acc: 0.6592\n",
      "Epoch 486/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6799 - acc: 0.5632 - val_loss: 0.6669 - val_acc: 0.6592\n",
      "Epoch 487/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6809 - acc: 0.5435 - val_loss: 0.6669 - val_acc: 0.6592\n",
      "Epoch 488/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6923 - acc: 0.5337 - val_loss: 0.6668 - val_acc: 0.6592\n",
      "Epoch 489/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6888 - acc: 0.5337 - val_loss: 0.6668 - val_acc: 0.6592\n",
      "Epoch 490/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6810 - acc: 0.5688 - val_loss: 0.6668 - val_acc: 0.6592\n",
      "Epoch 491/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6785 - acc: 0.5815 - val_loss: 0.6668 - val_acc: 0.6592\n",
      "Epoch 492/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6879 - acc: 0.5351 - val_loss: 0.6668 - val_acc: 0.6592\n",
      "Epoch 493/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6817 - acc: 0.5660 - val_loss: 0.6668 - val_acc: 0.6592\n",
      "Epoch 494/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6828 - acc: 0.5449 - val_loss: 0.6667 - val_acc: 0.6592\n",
      "Epoch 495/1000\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.6853 - acc: 0.5646 - val_loss: 0.6667 - val_acc: 0.6592\n",
      "Epoch 496/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6837 - acc: 0.5562 - val_loss: 0.6667 - val_acc: 0.6592\n",
      "Epoch 497/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6871 - acc: 0.5323 - val_loss: 0.6667 - val_acc: 0.6592\n",
      "Epoch 498/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6821 - acc: 0.5787 - val_loss: 0.6667 - val_acc: 0.6592\n",
      "Epoch 499/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6910 - acc: 0.4944 - val_loss: 0.6667 - val_acc: 0.6592\n",
      "Epoch 500/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6920 - acc: 0.5140 - val_loss: 0.6666 - val_acc: 0.6592\n",
      "Epoch 501/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6879 - acc: 0.5407 - val_loss: 0.6666 - val_acc: 0.6592\n",
      "Epoch 502/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6890 - acc: 0.5253 - val_loss: 0.6666 - val_acc: 0.6592\n",
      "Epoch 503/1000\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6860 - acc: 0.5506 - val_loss: 0.6666 - val_acc: 0.6592\n",
      "Epoch 504/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6808 - acc: 0.5365 - val_loss: 0.6666 - val_acc: 0.6592\n",
      "Epoch 505/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6865 - acc: 0.5463 - val_loss: 0.6666 - val_acc: 0.6592\n",
      "Epoch 506/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6882 - acc: 0.5478 - val_loss: 0.6666 - val_acc: 0.6592\n",
      "Epoch 507/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6871 - acc: 0.5351 - val_loss: 0.6665 - val_acc: 0.6592\n",
      "Epoch 508/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6863 - acc: 0.5548 - val_loss: 0.6665 - val_acc: 0.6592\n",
      "Epoch 509/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6823 - acc: 0.5927 - val_loss: 0.6665 - val_acc: 0.6592\n",
      "Epoch 510/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6781 - acc: 0.5772 - val_loss: 0.6665 - val_acc: 0.6592\n",
      "Epoch 511/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6806 - acc: 0.5618 - val_loss: 0.6665 - val_acc: 0.6592\n",
      "Epoch 512/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6876 - acc: 0.5197 - val_loss: 0.6665 - val_acc: 0.6592\n",
      "Epoch 513/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6915 - acc: 0.5112 - val_loss: 0.6664 - val_acc: 0.6592\n",
      "Epoch 514/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6884 - acc: 0.5169 - val_loss: 0.6664 - val_acc: 0.6592\n",
      "Epoch 515/1000\n",
      "712/712 [==============================] - 0s 163us/step - loss: 0.6869 - acc: 0.5281 - val_loss: 0.6664 - val_acc: 0.6592\n",
      "Epoch 516/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6863 - acc: 0.5534 - val_loss: 0.6664 - val_acc: 0.6592\n",
      "Epoch 517/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6815 - acc: 0.5787 - val_loss: 0.6664 - val_acc: 0.6592\n",
      "Epoch 518/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6854 - acc: 0.5463 - val_loss: 0.6664 - val_acc: 0.6592\n",
      "Epoch 519/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6845 - acc: 0.5632 - val_loss: 0.6663 - val_acc: 0.6592\n",
      "Epoch 520/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6874 - acc: 0.5393 - val_loss: 0.6663 - val_acc: 0.6592\n",
      "Epoch 521/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6850 - acc: 0.5744 - val_loss: 0.6663 - val_acc: 0.6592\n",
      "Epoch 522/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6863 - acc: 0.5463 - val_loss: 0.6663 - val_acc: 0.6592\n",
      "Epoch 523/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6872 - acc: 0.5534 - val_loss: 0.6663 - val_acc: 0.6592\n",
      "Epoch 524/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6790 - acc: 0.5660 - val_loss: 0.6663 - val_acc: 0.6592\n",
      "Epoch 525/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6847 - acc: 0.5365 - val_loss: 0.6662 - val_acc: 0.6592\n",
      "Epoch 526/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6826 - acc: 0.5449 - val_loss: 0.6662 - val_acc: 0.6592\n",
      "Epoch 527/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6861 - acc: 0.5506 - val_loss: 0.6662 - val_acc: 0.6592\n",
      "Epoch 528/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6933 - acc: 0.5520 - val_loss: 0.6662 - val_acc: 0.6592\n",
      "Epoch 529/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6877 - acc: 0.5351 - val_loss: 0.6662 - val_acc: 0.6592\n",
      "Epoch 530/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6845 - acc: 0.5562 - val_loss: 0.6662 - val_acc: 0.6592\n",
      "Epoch 531/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6867 - acc: 0.5337 - val_loss: 0.6661 - val_acc: 0.6592\n",
      "Epoch 532/1000\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6923 - acc: 0.5239 - val_loss: 0.6661 - val_acc: 0.6592\n",
      "Epoch 533/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6846 - acc: 0.5548 - val_loss: 0.6661 - val_acc: 0.6592\n",
      "Epoch 534/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6839 - acc: 0.5506 - val_loss: 0.6661 - val_acc: 0.6592\n",
      "Epoch 535/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6906 - acc: 0.5042 - val_loss: 0.6661 - val_acc: 0.6592\n",
      "Epoch 536/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6940 - acc: 0.5154 - val_loss: 0.6661 - val_acc: 0.6592\n",
      "Epoch 537/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6807 - acc: 0.5871 - val_loss: 0.6661 - val_acc: 0.6592\n",
      "Epoch 538/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6838 - acc: 0.5492 - val_loss: 0.6660 - val_acc: 0.6592\n",
      "Epoch 539/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6815 - acc: 0.5618 - val_loss: 0.6660 - val_acc: 0.6592\n",
      "Epoch 540/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6784 - acc: 0.5646 - val_loss: 0.6660 - val_acc: 0.6592\n",
      "Epoch 541/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6915 - acc: 0.5421 - val_loss: 0.6660 - val_acc: 0.6592\n",
      "Epoch 542/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6863 - acc: 0.5478 - val_loss: 0.6660 - val_acc: 0.6592\n",
      "Epoch 543/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6878 - acc: 0.5267 - val_loss: 0.6660 - val_acc: 0.6592\n",
      "Epoch 544/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6772 - acc: 0.5772 - val_loss: 0.6659 - val_acc: 0.6592\n",
      "Epoch 545/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6848 - acc: 0.5548 - val_loss: 0.6659 - val_acc: 0.6592\n",
      "Epoch 546/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6857 - acc: 0.5435 - val_loss: 0.6659 - val_acc: 0.6592\n",
      "Epoch 547/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6851 - acc: 0.5435 - val_loss: 0.6659 - val_acc: 0.6592\n",
      "Epoch 548/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6835 - acc: 0.5478 - val_loss: 0.6659 - val_acc: 0.6592\n",
      "Epoch 549/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6816 - acc: 0.5604 - val_loss: 0.6659 - val_acc: 0.6592\n",
      "Epoch 550/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6832 - acc: 0.5815 - val_loss: 0.6658 - val_acc: 0.6592\n",
      "Epoch 551/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6875 - acc: 0.5463 - val_loss: 0.6658 - val_acc: 0.6592\n",
      "Epoch 552/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6783 - acc: 0.5660 - val_loss: 0.6658 - val_acc: 0.6592\n",
      "Epoch 553/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6928 - acc: 0.5211 - val_loss: 0.6658 - val_acc: 0.6592\n",
      "Epoch 554/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6879 - acc: 0.5393 - val_loss: 0.6658 - val_acc: 0.6592\n",
      "Epoch 555/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6845 - acc: 0.5590 - val_loss: 0.6658 - val_acc: 0.6592\n",
      "Epoch 556/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6820 - acc: 0.5365 - val_loss: 0.6657 - val_acc: 0.6592\n",
      "Epoch 557/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.6801 - acc: 0.5463 - val_loss: 0.6657 - val_acc: 0.6592\n",
      "Epoch 558/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6872 - acc: 0.5365 - val_loss: 0.6657 - val_acc: 0.6592\n",
      "Epoch 559/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.6831 - acc: 0.5590 - val_loss: 0.6657 - val_acc: 0.6592\n",
      "Epoch 560/1000\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.6852 - acc: 0.5393 - val_loss: 0.6657 - val_acc: 0.6592\n",
      "Epoch 561/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6844 - acc: 0.5365 - val_loss: 0.6657 - val_acc: 0.6592\n",
      "Epoch 562/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6861 - acc: 0.5632 - val_loss: 0.6657 - val_acc: 0.6592\n",
      "Epoch 563/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6772 - acc: 0.5955 - val_loss: 0.6656 - val_acc: 0.6592\n",
      "Epoch 564/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6843 - acc: 0.5590 - val_loss: 0.6656 - val_acc: 0.6592\n",
      "Epoch 565/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6825 - acc: 0.5534 - val_loss: 0.6656 - val_acc: 0.6592\n",
      "Epoch 566/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6789 - acc: 0.5632 - val_loss: 0.6656 - val_acc: 0.6592\n",
      "Epoch 567/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6870 - acc: 0.5534 - val_loss: 0.6656 - val_acc: 0.6592\n",
      "Epoch 568/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6901 - acc: 0.5548 - val_loss: 0.6656 - val_acc: 0.6592\n",
      "Epoch 569/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6837 - acc: 0.5660 - val_loss: 0.6655 - val_acc: 0.6592\n",
      "Epoch 570/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6840 - acc: 0.5548 - val_loss: 0.6655 - val_acc: 0.6592\n",
      "Epoch 571/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6777 - acc: 0.5801 - val_loss: 0.6655 - val_acc: 0.6592\n",
      "Epoch 572/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6959 - acc: 0.5042 - val_loss: 0.6655 - val_acc: 0.6592\n",
      "Epoch 573/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6791 - acc: 0.5618 - val_loss: 0.6655 - val_acc: 0.6592\n",
      "Epoch 574/1000\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.6830 - acc: 0.5492 - val_loss: 0.6655 - val_acc: 0.6592\n",
      "Epoch 575/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6867 - acc: 0.5309 - val_loss: 0.6654 - val_acc: 0.6592\n",
      "Epoch 576/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6836 - acc: 0.5548 - val_loss: 0.6654 - val_acc: 0.6592\n",
      "Epoch 577/1000\n",
      "712/712 [==============================] - 0s 166us/step - loss: 0.6899 - acc: 0.5365 - val_loss: 0.6654 - val_acc: 0.6592\n",
      "Epoch 578/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6840 - acc: 0.5604 - val_loss: 0.6654 - val_acc: 0.6592\n",
      "Epoch 579/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6859 - acc: 0.5365 - val_loss: 0.6654 - val_acc: 0.6592\n",
      "Epoch 580/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6847 - acc: 0.5548 - val_loss: 0.6654 - val_acc: 0.6592\n",
      "Epoch 581/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6922 - acc: 0.5169 - val_loss: 0.6654 - val_acc: 0.6592\n",
      "Epoch 582/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6868 - acc: 0.5393 - val_loss: 0.6653 - val_acc: 0.6592\n",
      "Epoch 583/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6873 - acc: 0.5253 - val_loss: 0.6653 - val_acc: 0.6592\n",
      "Epoch 584/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6904 - acc: 0.5323 - val_loss: 0.6653 - val_acc: 0.6592\n",
      "Epoch 585/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6893 - acc: 0.5604 - val_loss: 0.6653 - val_acc: 0.6592\n",
      "Epoch 586/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6817 - acc: 0.5843 - val_loss: 0.6653 - val_acc: 0.6592\n",
      "Epoch 587/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6809 - acc: 0.5674 - val_loss: 0.6653 - val_acc: 0.6592\n",
      "Epoch 588/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6784 - acc: 0.5632 - val_loss: 0.6652 - val_acc: 0.6592\n",
      "Epoch 589/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6868 - acc: 0.5126 - val_loss: 0.6652 - val_acc: 0.6592\n",
      "Epoch 590/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6823 - acc: 0.5576 - val_loss: 0.6652 - val_acc: 0.6592\n",
      "Epoch 591/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6830 - acc: 0.5548 - val_loss: 0.6652 - val_acc: 0.6592\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 146us/step - loss: 0.6797 - acc: 0.5758 - val_loss: 0.6652 - val_acc: 0.6592\n",
      "Epoch 593/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6801 - acc: 0.5618 - val_loss: 0.6652 - val_acc: 0.6592\n",
      "Epoch 594/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6843 - acc: 0.5562 - val_loss: 0.6651 - val_acc: 0.6592\n",
      "Epoch 595/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6913 - acc: 0.5253 - val_loss: 0.6651 - val_acc: 0.6592\n",
      "Epoch 596/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6854 - acc: 0.5407 - val_loss: 0.6651 - val_acc: 0.6592\n",
      "Epoch 597/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6757 - acc: 0.5548 - val_loss: 0.6651 - val_acc: 0.6592\n",
      "Epoch 598/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6788 - acc: 0.5520 - val_loss: 0.6651 - val_acc: 0.6592\n",
      "Epoch 599/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6858 - acc: 0.5449 - val_loss: 0.6651 - val_acc: 0.6592\n",
      "Epoch 600/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6813 - acc: 0.5520 - val_loss: 0.6651 - val_acc: 0.6592\n",
      "Epoch 601/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6809 - acc: 0.5576 - val_loss: 0.6650 - val_acc: 0.6592\n",
      "Epoch 602/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6903 - acc: 0.5351 - val_loss: 0.6650 - val_acc: 0.6592\n",
      "Epoch 603/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6841 - acc: 0.5688 - val_loss: 0.6650 - val_acc: 0.6592\n",
      "Epoch 604/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6801 - acc: 0.5379 - val_loss: 0.6650 - val_acc: 0.6592\n",
      "Epoch 605/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6882 - acc: 0.5407 - val_loss: 0.6650 - val_acc: 0.6592\n",
      "Epoch 606/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6868 - acc: 0.5281 - val_loss: 0.6650 - val_acc: 0.6592\n",
      "Epoch 607/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6827 - acc: 0.5435 - val_loss: 0.6650 - val_acc: 0.6592\n",
      "Epoch 608/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6853 - acc: 0.5463 - val_loss: 0.6649 - val_acc: 0.6592\n",
      "Epoch 609/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6796 - acc: 0.5815 - val_loss: 0.6649 - val_acc: 0.6592\n",
      "Epoch 610/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6876 - acc: 0.5421 - val_loss: 0.6649 - val_acc: 0.6592\n",
      "Epoch 611/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6832 - acc: 0.5337 - val_loss: 0.6649 - val_acc: 0.6592\n",
      "Epoch 612/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6871 - acc: 0.5632 - val_loss: 0.6649 - val_acc: 0.6592\n",
      "Epoch 613/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6846 - acc: 0.5646 - val_loss: 0.6649 - val_acc: 0.6592\n",
      "Epoch 614/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6867 - acc: 0.5421 - val_loss: 0.6648 - val_acc: 0.6592\n",
      "Epoch 615/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6889 - acc: 0.5618 - val_loss: 0.6648 - val_acc: 0.6592\n",
      "Epoch 616/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6849 - acc: 0.5534 - val_loss: 0.6648 - val_acc: 0.6592\n",
      "Epoch 617/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6906 - acc: 0.5365 - val_loss: 0.6648 - val_acc: 0.6592\n",
      "Epoch 618/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6864 - acc: 0.5365 - val_loss: 0.6648 - val_acc: 0.6592\n",
      "Epoch 619/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6772 - acc: 0.5730 - val_loss: 0.6648 - val_acc: 0.6592\n",
      "Epoch 620/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6813 - acc: 0.5590 - val_loss: 0.6648 - val_acc: 0.6592\n",
      "Epoch 621/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6840 - acc: 0.5660 - val_loss: 0.6647 - val_acc: 0.6536\n",
      "Epoch 622/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6908 - acc: 0.5478 - val_loss: 0.6647 - val_acc: 0.6536\n",
      "Epoch 623/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6819 - acc: 0.5688 - val_loss: 0.6647 - val_acc: 0.6536\n",
      "Epoch 624/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6813 - acc: 0.5618 - val_loss: 0.6647 - val_acc: 0.6536\n",
      "Epoch 625/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6903 - acc: 0.5211 - val_loss: 0.6647 - val_acc: 0.6536\n",
      "Epoch 626/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6855 - acc: 0.5393 - val_loss: 0.6647 - val_acc: 0.6536\n",
      "Epoch 627/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6804 - acc: 0.5590 - val_loss: 0.6646 - val_acc: 0.6536\n",
      "Epoch 628/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6890 - acc: 0.5323 - val_loss: 0.6646 - val_acc: 0.6536\n",
      "Epoch 629/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6818 - acc: 0.5674 - val_loss: 0.6646 - val_acc: 0.6536\n",
      "Epoch 630/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6815 - acc: 0.5646 - val_loss: 0.6646 - val_acc: 0.6536\n",
      "Epoch 631/1000\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.6773 - acc: 0.5688 - val_loss: 0.6646 - val_acc: 0.6536\n",
      "Epoch 632/1000\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.6771 - acc: 0.5787 - val_loss: 0.6646 - val_acc: 0.6536\n",
      "Epoch 633/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6839 - acc: 0.5309 - val_loss: 0.6645 - val_acc: 0.6536\n",
      "Epoch 634/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6898 - acc: 0.5534 - val_loss: 0.6645 - val_acc: 0.6536\n",
      "Epoch 635/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6937 - acc: 0.5351 - val_loss: 0.6645 - val_acc: 0.6536\n",
      "Epoch 636/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6815 - acc: 0.5576 - val_loss: 0.6645 - val_acc: 0.6536\n",
      "Epoch 637/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6854 - acc: 0.5520 - val_loss: 0.6645 - val_acc: 0.6536\n",
      "Epoch 638/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6853 - acc: 0.5421 - val_loss: 0.6645 - val_acc: 0.6536\n",
      "Epoch 639/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6806 - acc: 0.5632 - val_loss: 0.6645 - val_acc: 0.6536\n",
      "Epoch 640/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6864 - acc: 0.5492 - val_loss: 0.6644 - val_acc: 0.6536\n",
      "Epoch 641/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6924 - acc: 0.5154 - val_loss: 0.6644 - val_acc: 0.6536\n",
      "Epoch 642/1000\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.6887 - acc: 0.5506 - val_loss: 0.6644 - val_acc: 0.6536\n",
      "Epoch 643/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6917 - acc: 0.5421 - val_loss: 0.6644 - val_acc: 0.6536\n",
      "Epoch 644/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6817 - acc: 0.5632 - val_loss: 0.6644 - val_acc: 0.6536\n",
      "Epoch 645/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6790 - acc: 0.5899 - val_loss: 0.6644 - val_acc: 0.6536\n",
      "Epoch 646/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6845 - acc: 0.5449 - val_loss: 0.6643 - val_acc: 0.6536\n",
      "Epoch 647/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6868 - acc: 0.5646 - val_loss: 0.6643 - val_acc: 0.6536\n",
      "Epoch 648/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6961 - acc: 0.5126 - val_loss: 0.6643 - val_acc: 0.6536\n",
      "Epoch 649/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6825 - acc: 0.5548 - val_loss: 0.6643 - val_acc: 0.6536\n",
      "Epoch 650/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6871 - acc: 0.5478 - val_loss: 0.6643 - val_acc: 0.6536\n",
      "Epoch 651/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6824 - acc: 0.5506 - val_loss: 0.6643 - val_acc: 0.6536\n",
      "Epoch 652/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6941 - acc: 0.5351 - val_loss: 0.6642 - val_acc: 0.6536\n",
      "Epoch 653/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6835 - acc: 0.5744 - val_loss: 0.6642 - val_acc: 0.6536\n",
      "Epoch 654/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6875 - acc: 0.5253 - val_loss: 0.6642 - val_acc: 0.6536\n",
      "Epoch 655/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6752 - acc: 0.5969 - val_loss: 0.6642 - val_acc: 0.6536\n",
      "Epoch 656/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6898 - acc: 0.5520 - val_loss: 0.6642 - val_acc: 0.6536\n",
      "Epoch 657/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6904 - acc: 0.5337 - val_loss: 0.6642 - val_acc: 0.6536\n",
      "Epoch 658/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6794 - acc: 0.5520 - val_loss: 0.6642 - val_acc: 0.6536\n",
      "Epoch 659/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6839 - acc: 0.5534 - val_loss: 0.6641 - val_acc: 0.6536\n",
      "Epoch 660/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6823 - acc: 0.5548 - val_loss: 0.6641 - val_acc: 0.6536\n",
      "Epoch 661/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6786 - acc: 0.5688 - val_loss: 0.6641 - val_acc: 0.6536\n",
      "Epoch 662/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6889 - acc: 0.5309 - val_loss: 0.6641 - val_acc: 0.6536\n",
      "Epoch 663/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6817 - acc: 0.5618 - val_loss: 0.6641 - val_acc: 0.6536\n",
      "Epoch 664/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6942 - acc: 0.5225 - val_loss: 0.6641 - val_acc: 0.6536\n",
      "Epoch 665/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6871 - acc: 0.5815 - val_loss: 0.6640 - val_acc: 0.6536\n",
      "Epoch 666/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6782 - acc: 0.5927 - val_loss: 0.6640 - val_acc: 0.6536\n",
      "Epoch 667/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6871 - acc: 0.5520 - val_loss: 0.6640 - val_acc: 0.6536\n",
      "Epoch 668/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6835 - acc: 0.5576 - val_loss: 0.6640 - val_acc: 0.6536\n",
      "Epoch 669/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6827 - acc: 0.5435 - val_loss: 0.6640 - val_acc: 0.6536\n",
      "Epoch 670/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6906 - acc: 0.5267 - val_loss: 0.6640 - val_acc: 0.6536\n",
      "Epoch 671/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6834 - acc: 0.5506 - val_loss: 0.6640 - val_acc: 0.6536\n",
      "Epoch 672/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6870 - acc: 0.5393 - val_loss: 0.6639 - val_acc: 0.6536\n",
      "Epoch 673/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6840 - acc: 0.5506 - val_loss: 0.6639 - val_acc: 0.6536\n",
      "Epoch 674/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.6805 - acc: 0.5716 - val_loss: 0.6639 - val_acc: 0.6536\n",
      "Epoch 675/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.6909 - acc: 0.5211 - val_loss: 0.6639 - val_acc: 0.6536\n",
      "Epoch 676/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6830 - acc: 0.5646 - val_loss: 0.6639 - val_acc: 0.6536\n",
      "Epoch 677/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6853 - acc: 0.5548 - val_loss: 0.6639 - val_acc: 0.6536\n",
      "Epoch 678/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6799 - acc: 0.5744 - val_loss: 0.6639 - val_acc: 0.6536\n",
      "Epoch 679/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6808 - acc: 0.5632 - val_loss: 0.6638 - val_acc: 0.6536\n",
      "Epoch 680/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6796 - acc: 0.5506 - val_loss: 0.6638 - val_acc: 0.6536\n",
      "Epoch 681/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6792 - acc: 0.5857 - val_loss: 0.6638 - val_acc: 0.6536\n",
      "Epoch 682/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6809 - acc: 0.5520 - val_loss: 0.6638 - val_acc: 0.6536\n",
      "Epoch 683/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6896 - acc: 0.5309 - val_loss: 0.6638 - val_acc: 0.6536\n",
      "Epoch 684/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6775 - acc: 0.5646 - val_loss: 0.6638 - val_acc: 0.6536\n",
      "Epoch 685/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6772 - acc: 0.5815 - val_loss: 0.6637 - val_acc: 0.6536\n",
      "Epoch 686/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6824 - acc: 0.5548 - val_loss: 0.6637 - val_acc: 0.6536\n",
      "Epoch 687/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6846 - acc: 0.5576 - val_loss: 0.6637 - val_acc: 0.6536\n",
      "Epoch 688/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6778 - acc: 0.5787 - val_loss: 0.6637 - val_acc: 0.6536\n",
      "Epoch 689/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6762 - acc: 0.5688 - val_loss: 0.6637 - val_acc: 0.6536\n",
      "Epoch 690/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6799 - acc: 0.5744 - val_loss: 0.6637 - val_acc: 0.6536\n",
      "Epoch 691/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6885 - acc: 0.5632 - val_loss: 0.6637 - val_acc: 0.6536\n",
      "Epoch 692/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6863 - acc: 0.5365 - val_loss: 0.6636 - val_acc: 0.6536\n",
      "Epoch 693/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6804 - acc: 0.5632 - val_loss: 0.6636 - val_acc: 0.6536\n",
      "Epoch 694/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6864 - acc: 0.5520 - val_loss: 0.6636 - val_acc: 0.6536\n",
      "Epoch 695/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6844 - acc: 0.5660 - val_loss: 0.6636 - val_acc: 0.6536\n",
      "Epoch 696/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6790 - acc: 0.5829 - val_loss: 0.6636 - val_acc: 0.6536\n",
      "Epoch 697/1000\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.6874 - acc: 0.5576 - val_loss: 0.6636 - val_acc: 0.6536\n",
      "Epoch 698/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6809 - acc: 0.5660 - val_loss: 0.6635 - val_acc: 0.6536\n",
      "Epoch 699/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6728 - acc: 0.5955 - val_loss: 0.6635 - val_acc: 0.6536\n",
      "Epoch 700/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6870 - acc: 0.5702 - val_loss: 0.6635 - val_acc: 0.6536\n",
      "Epoch 701/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6831 - acc: 0.5492 - val_loss: 0.6635 - val_acc: 0.6536\n",
      "Epoch 702/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6863 - acc: 0.5618 - val_loss: 0.6635 - val_acc: 0.6536\n",
      "Epoch 703/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6784 - acc: 0.5646 - val_loss: 0.6635 - val_acc: 0.6536\n",
      "Epoch 704/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6824 - acc: 0.5534 - val_loss: 0.6635 - val_acc: 0.6536\n",
      "Epoch 705/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6820 - acc: 0.5562 - val_loss: 0.6634 - val_acc: 0.6536\n",
      "Epoch 706/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6878 - acc: 0.5492 - val_loss: 0.6634 - val_acc: 0.6536\n",
      "Epoch 707/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.6732 - acc: 0.5955 - val_loss: 0.6634 - val_acc: 0.6536\n",
      "Epoch 708/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6847 - acc: 0.5772 - val_loss: 0.6634 - val_acc: 0.6536\n",
      "Epoch 709/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6880 - acc: 0.5323 - val_loss: 0.6634 - val_acc: 0.6536\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 109us/step - loss: 0.6789 - acc: 0.5618 - val_loss: 0.6634 - val_acc: 0.6536\n",
      "Epoch 711/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6825 - acc: 0.5295 - val_loss: 0.6634 - val_acc: 0.6536\n",
      "Epoch 712/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6792 - acc: 0.5520 - val_loss: 0.6633 - val_acc: 0.6536\n",
      "Epoch 713/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6854 - acc: 0.5744 - val_loss: 0.6633 - val_acc: 0.6536\n",
      "Epoch 714/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.6877 - acc: 0.5562 - val_loss: 0.6633 - val_acc: 0.6536\n",
      "Epoch 715/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.6827 - acc: 0.5534 - val_loss: 0.6633 - val_acc: 0.6536\n",
      "Epoch 716/1000\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.6863 - acc: 0.5323 - val_loss: 0.6633 - val_acc: 0.6536\n",
      "Epoch 717/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.6850 - acc: 0.5562 - val_loss: 0.6633 - val_acc: 0.6536\n",
      "Epoch 718/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.6827 - acc: 0.5632 - val_loss: 0.6632 - val_acc: 0.6536\n",
      "Epoch 719/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.6815 - acc: 0.5618 - val_loss: 0.6632 - val_acc: 0.6536\n",
      "Epoch 720/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.6846 - acc: 0.5520 - val_loss: 0.6632 - val_acc: 0.6536\n",
      "Epoch 721/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6803 - acc: 0.5646 - val_loss: 0.6632 - val_acc: 0.6536\n",
      "Epoch 722/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6843 - acc: 0.5604 - val_loss: 0.6632 - val_acc: 0.6536\n",
      "Epoch 723/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6853 - acc: 0.5534 - val_loss: 0.6632 - val_acc: 0.6536\n",
      "Epoch 724/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6875 - acc: 0.5323 - val_loss: 0.6632 - val_acc: 0.6536\n",
      "Epoch 725/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6764 - acc: 0.5716 - val_loss: 0.6631 - val_acc: 0.6536\n",
      "Epoch 726/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6831 - acc: 0.5506 - val_loss: 0.6631 - val_acc: 0.6536\n",
      "Epoch 727/1000\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.6915 - acc: 0.5225 - val_loss: 0.6631 - val_acc: 0.6536\n",
      "Epoch 728/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6773 - acc: 0.5772 - val_loss: 0.6631 - val_acc: 0.6536\n",
      "Epoch 729/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6795 - acc: 0.5520 - val_loss: 0.6631 - val_acc: 0.6536\n",
      "Epoch 730/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.6796 - acc: 0.5590 - val_loss: 0.6631 - val_acc: 0.6536\n",
      "Epoch 731/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6873 - acc: 0.5379 - val_loss: 0.6631 - val_acc: 0.6536\n",
      "Epoch 732/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6817 - acc: 0.5520 - val_loss: 0.6630 - val_acc: 0.6536\n",
      "Epoch 733/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6822 - acc: 0.5463 - val_loss: 0.6630 - val_acc: 0.6536\n",
      "Epoch 734/1000\n",
      "712/712 [==============================] - 0s 168us/step - loss: 0.6776 - acc: 0.5815 - val_loss: 0.6630 - val_acc: 0.6536\n",
      "Epoch 735/1000\n",
      "712/712 [==============================] - 0s 174us/step - loss: 0.6765 - acc: 0.5857 - val_loss: 0.6630 - val_acc: 0.6536\n",
      "Epoch 736/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6799 - acc: 0.5632 - val_loss: 0.6630 - val_acc: 0.6536\n",
      "Epoch 737/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6761 - acc: 0.5857 - val_loss: 0.6630 - val_acc: 0.6536\n",
      "Epoch 738/1000\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.6762 - acc: 0.5660 - val_loss: 0.6629 - val_acc: 0.6536\n",
      "Epoch 739/1000\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.6770 - acc: 0.5492 - val_loss: 0.6629 - val_acc: 0.6536\n",
      "Epoch 740/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6824 - acc: 0.5463 - val_loss: 0.6629 - val_acc: 0.6536\n",
      "Epoch 741/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6779 - acc: 0.5801 - val_loss: 0.6629 - val_acc: 0.6536\n",
      "Epoch 742/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6878 - acc: 0.5520 - val_loss: 0.6629 - val_acc: 0.6536\n",
      "Epoch 743/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6836 - acc: 0.5520 - val_loss: 0.6629 - val_acc: 0.6536\n",
      "Epoch 744/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6879 - acc: 0.5534 - val_loss: 0.6629 - val_acc: 0.6536\n",
      "Epoch 745/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6823 - acc: 0.5590 - val_loss: 0.6628 - val_acc: 0.6536\n",
      "Epoch 746/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6780 - acc: 0.5913 - val_loss: 0.6628 - val_acc: 0.6536\n",
      "Epoch 747/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6774 - acc: 0.5787 - val_loss: 0.6628 - val_acc: 0.6536\n",
      "Epoch 748/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6924 - acc: 0.5253 - val_loss: 0.6628 - val_acc: 0.6536\n",
      "Epoch 749/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6782 - acc: 0.5801 - val_loss: 0.6628 - val_acc: 0.6536\n",
      "Epoch 750/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6860 - acc: 0.5421 - val_loss: 0.6628 - val_acc: 0.6536\n",
      "Epoch 751/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6818 - acc: 0.5393 - val_loss: 0.6627 - val_acc: 0.6536\n",
      "Epoch 752/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6816 - acc: 0.5492 - val_loss: 0.6627 - val_acc: 0.6536\n",
      "Epoch 753/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6822 - acc: 0.5857 - val_loss: 0.6627 - val_acc: 0.6536\n",
      "Epoch 754/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6825 - acc: 0.5590 - val_loss: 0.6627 - val_acc: 0.6536\n",
      "Epoch 755/1000\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.6801 - acc: 0.5646 - val_loss: 0.6627 - val_acc: 0.6536\n",
      "Epoch 756/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6806 - acc: 0.5660 - val_loss: 0.6627 - val_acc: 0.6536\n",
      "Epoch 757/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6820 - acc: 0.5688 - val_loss: 0.6627 - val_acc: 0.6536\n",
      "Epoch 758/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.6844 - acc: 0.5449 - val_loss: 0.6626 - val_acc: 0.6536\n",
      "Epoch 759/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6905 - acc: 0.5225 - val_loss: 0.6626 - val_acc: 0.6536\n",
      "Epoch 760/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.6903 - acc: 0.5379 - val_loss: 0.6626 - val_acc: 0.6536\n",
      "Epoch 761/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6907 - acc: 0.5309 - val_loss: 0.6626 - val_acc: 0.6536\n",
      "Epoch 762/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6831 - acc: 0.5702 - val_loss: 0.6626 - val_acc: 0.6536\n",
      "Epoch 763/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6733 - acc: 0.5871 - val_loss: 0.6626 - val_acc: 0.6536\n",
      "Epoch 764/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6862 - acc: 0.5646 - val_loss: 0.6625 - val_acc: 0.6536\n",
      "Epoch 765/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.6776 - acc: 0.5674 - val_loss: 0.6625 - val_acc: 0.6536\n",
      "Epoch 766/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6900 - acc: 0.5534 - val_loss: 0.6625 - val_acc: 0.6536\n",
      "Epoch 767/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6846 - acc: 0.5435 - val_loss: 0.6625 - val_acc: 0.6536\n",
      "Epoch 768/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.6811 - acc: 0.5674 - val_loss: 0.6625 - val_acc: 0.6536\n",
      "Epoch 769/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.6788 - acc: 0.5674 - val_loss: 0.6625 - val_acc: 0.6536\n",
      "Epoch 770/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6841 - acc: 0.5534 - val_loss: 0.6625 - val_acc: 0.6536\n",
      "Epoch 771/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6767 - acc: 0.5758 - val_loss: 0.6624 - val_acc: 0.6536\n",
      "Epoch 772/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6794 - acc: 0.5646 - val_loss: 0.6624 - val_acc: 0.6536\n",
      "Epoch 773/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6800 - acc: 0.5829 - val_loss: 0.6624 - val_acc: 0.6536\n",
      "Epoch 774/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6736 - acc: 0.5829 - val_loss: 0.6624 - val_acc: 0.6536\n",
      "Epoch 775/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6820 - acc: 0.5688 - val_loss: 0.6624 - val_acc: 0.6536\n",
      "Epoch 776/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.6728 - acc: 0.6039 - val_loss: 0.6624 - val_acc: 0.6536\n",
      "Epoch 777/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.6858 - acc: 0.5407 - val_loss: 0.6623 - val_acc: 0.6536\n",
      "Epoch 778/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6809 - acc: 0.5337 - val_loss: 0.6623 - val_acc: 0.6536\n",
      "Epoch 779/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.6868 - acc: 0.5478 - val_loss: 0.6623 - val_acc: 0.6536\n",
      "Epoch 780/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.6904 - acc: 0.5211 - val_loss: 0.6623 - val_acc: 0.6536\n",
      "Epoch 781/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6908 - acc: 0.5435 - val_loss: 0.6623 - val_acc: 0.6536\n",
      "Epoch 782/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6821 - acc: 0.5590 - val_loss: 0.6623 - val_acc: 0.6536\n",
      "Epoch 783/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6810 - acc: 0.5548 - val_loss: 0.6623 - val_acc: 0.6536\n",
      "Epoch 784/1000\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.6803 - acc: 0.5702 - val_loss: 0.6622 - val_acc: 0.6536\n",
      "Epoch 785/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.6877 - acc: 0.5506 - val_loss: 0.6622 - val_acc: 0.6536\n",
      "Epoch 786/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.6777 - acc: 0.5857 - val_loss: 0.6622 - val_acc: 0.6536\n",
      "Epoch 787/1000\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.6851 - acc: 0.5393 - val_loss: 0.6622 - val_acc: 0.6536\n",
      "Epoch 788/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6815 - acc: 0.5716 - val_loss: 0.6622 - val_acc: 0.6536\n",
      "Epoch 789/1000\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.6895 - acc: 0.5295 - val_loss: 0.6622 - val_acc: 0.6536\n",
      "Epoch 790/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6840 - acc: 0.5730 - val_loss: 0.6622 - val_acc: 0.6536\n",
      "Epoch 791/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6862 - acc: 0.5295 - val_loss: 0.6621 - val_acc: 0.6536\n",
      "Epoch 792/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6817 - acc: 0.5674 - val_loss: 0.6621 - val_acc: 0.6536\n",
      "Epoch 793/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6765 - acc: 0.5787 - val_loss: 0.6621 - val_acc: 0.6536\n",
      "Epoch 794/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6828 - acc: 0.5351 - val_loss: 0.6621 - val_acc: 0.6536\n",
      "Epoch 795/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6840 - acc: 0.5506 - val_loss: 0.6621 - val_acc: 0.6536\n",
      "Epoch 796/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6741 - acc: 0.5829 - val_loss: 0.6621 - val_acc: 0.6536\n",
      "Epoch 797/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6728 - acc: 0.5758 - val_loss: 0.6620 - val_acc: 0.6536\n",
      "Epoch 798/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6815 - acc: 0.5772 - val_loss: 0.6620 - val_acc: 0.6536\n",
      "Epoch 799/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6828 - acc: 0.5674 - val_loss: 0.6620 - val_acc: 0.6536\n",
      "Epoch 800/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6771 - acc: 0.5730 - val_loss: 0.6620 - val_acc: 0.6536\n",
      "Epoch 801/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6855 - acc: 0.5576 - val_loss: 0.6620 - val_acc: 0.6536\n",
      "Epoch 802/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6894 - acc: 0.5211 - val_loss: 0.6620 - val_acc: 0.6536\n",
      "Epoch 803/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6853 - acc: 0.5646 - val_loss: 0.6620 - val_acc: 0.6536\n",
      "Epoch 804/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6856 - acc: 0.5478 - val_loss: 0.6619 - val_acc: 0.6536\n",
      "Epoch 805/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6751 - acc: 0.5871 - val_loss: 0.6619 - val_acc: 0.6536\n",
      "Epoch 806/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6814 - acc: 0.5730 - val_loss: 0.6619 - val_acc: 0.6536\n",
      "Epoch 807/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6784 - acc: 0.5548 - val_loss: 0.6619 - val_acc: 0.6536\n",
      "Epoch 808/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6789 - acc: 0.5913 - val_loss: 0.6619 - val_acc: 0.6536\n",
      "Epoch 809/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6805 - acc: 0.5421 - val_loss: 0.6619 - val_acc: 0.6536\n",
      "Epoch 810/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6828 - acc: 0.5618 - val_loss: 0.6619 - val_acc: 0.6536\n",
      "Epoch 811/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6858 - acc: 0.5449 - val_loss: 0.6618 - val_acc: 0.6536\n",
      "Epoch 812/1000\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.6819 - acc: 0.5646 - val_loss: 0.6618 - val_acc: 0.6536\n",
      "Epoch 813/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6821 - acc: 0.5337 - val_loss: 0.6618 - val_acc: 0.6536\n",
      "Epoch 814/1000\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.6764 - acc: 0.5829 - val_loss: 0.6618 - val_acc: 0.6536\n",
      "Epoch 815/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6835 - acc: 0.5801 - val_loss: 0.6618 - val_acc: 0.6536\n",
      "Epoch 816/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6795 - acc: 0.5632 - val_loss: 0.6618 - val_acc: 0.6536\n",
      "Epoch 817/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6896 - acc: 0.5154 - val_loss: 0.6617 - val_acc: 0.6536\n",
      "Epoch 818/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6833 - acc: 0.5379 - val_loss: 0.6617 - val_acc: 0.6536\n",
      "Epoch 819/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6830 - acc: 0.5253 - val_loss: 0.6617 - val_acc: 0.6536\n",
      "Epoch 820/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6827 - acc: 0.5478 - val_loss: 0.6617 - val_acc: 0.6536\n",
      "Epoch 821/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6803 - acc: 0.5730 - val_loss: 0.6617 - val_acc: 0.6536\n",
      "Epoch 822/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6915 - acc: 0.5323 - val_loss: 0.6617 - val_acc: 0.6536\n",
      "Epoch 823/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6832 - acc: 0.5534 - val_loss: 0.6617 - val_acc: 0.6536\n",
      "Epoch 824/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6760 - acc: 0.5702 - val_loss: 0.6616 - val_acc: 0.6536\n",
      "Epoch 825/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6768 - acc: 0.5815 - val_loss: 0.6616 - val_acc: 0.6536\n",
      "Epoch 826/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6841 - acc: 0.5506 - val_loss: 0.6616 - val_acc: 0.6536\n",
      "Epoch 827/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6828 - acc: 0.5435 - val_loss: 0.6616 - val_acc: 0.6536\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 146us/step - loss: 0.6783 - acc: 0.5772 - val_loss: 0.6616 - val_acc: 0.6536\n",
      "Epoch 829/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6827 - acc: 0.5562 - val_loss: 0.6616 - val_acc: 0.6536\n",
      "Epoch 830/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6788 - acc: 0.5632 - val_loss: 0.6616 - val_acc: 0.6536\n",
      "Epoch 831/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6819 - acc: 0.5576 - val_loss: 0.6615 - val_acc: 0.6536\n",
      "Epoch 832/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6760 - acc: 0.5829 - val_loss: 0.6615 - val_acc: 0.6536\n",
      "Epoch 833/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6785 - acc: 0.5801 - val_loss: 0.6615 - val_acc: 0.6536\n",
      "Epoch 834/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6775 - acc: 0.5688 - val_loss: 0.6615 - val_acc: 0.6536\n",
      "Epoch 835/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6903 - acc: 0.5295 - val_loss: 0.6615 - val_acc: 0.6536\n",
      "Epoch 836/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6840 - acc: 0.5590 - val_loss: 0.6615 - val_acc: 0.6536\n",
      "Epoch 837/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6838 - acc: 0.5506 - val_loss: 0.6614 - val_acc: 0.6536\n",
      "Epoch 838/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6886 - acc: 0.5393 - val_loss: 0.6614 - val_acc: 0.6536\n",
      "Epoch 839/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6827 - acc: 0.5801 - val_loss: 0.6614 - val_acc: 0.6536\n",
      "Epoch 840/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6837 - acc: 0.5646 - val_loss: 0.6614 - val_acc: 0.6536\n",
      "Epoch 841/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6773 - acc: 0.5744 - val_loss: 0.6614 - val_acc: 0.6536\n",
      "Epoch 842/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6808 - acc: 0.5576 - val_loss: 0.6614 - val_acc: 0.6536\n",
      "Epoch 843/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6765 - acc: 0.5843 - val_loss: 0.6614 - val_acc: 0.6536\n",
      "Epoch 844/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6787 - acc: 0.5744 - val_loss: 0.6613 - val_acc: 0.6536\n",
      "Epoch 845/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6831 - acc: 0.5688 - val_loss: 0.6613 - val_acc: 0.6536\n",
      "Epoch 846/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6873 - acc: 0.5253 - val_loss: 0.6613 - val_acc: 0.6536\n",
      "Epoch 847/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6853 - acc: 0.5478 - val_loss: 0.6613 - val_acc: 0.6536\n",
      "Epoch 848/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6710 - acc: 0.6081 - val_loss: 0.6613 - val_acc: 0.6536\n",
      "Epoch 849/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6773 - acc: 0.5702 - val_loss: 0.6613 - val_acc: 0.6536\n",
      "Epoch 850/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6827 - acc: 0.5604 - val_loss: 0.6613 - val_acc: 0.6536\n",
      "Epoch 851/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6783 - acc: 0.5562 - val_loss: 0.6612 - val_acc: 0.6536\n",
      "Epoch 852/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6780 - acc: 0.5604 - val_loss: 0.6612 - val_acc: 0.6536\n",
      "Epoch 853/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6799 - acc: 0.5674 - val_loss: 0.6612 - val_acc: 0.6536\n",
      "Epoch 854/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6803 - acc: 0.5506 - val_loss: 0.6612 - val_acc: 0.6536\n",
      "Epoch 855/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6760 - acc: 0.5885 - val_loss: 0.6612 - val_acc: 0.6536\n",
      "Epoch 856/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6776 - acc: 0.5758 - val_loss: 0.6612 - val_acc: 0.6536\n",
      "Epoch 857/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6913 - acc: 0.5337 - val_loss: 0.6611 - val_acc: 0.6536\n",
      "Epoch 858/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6864 - acc: 0.5211 - val_loss: 0.6611 - val_acc: 0.6536\n",
      "Epoch 859/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6830 - acc: 0.5632 - val_loss: 0.6611 - val_acc: 0.6536\n",
      "Epoch 860/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6850 - acc: 0.5492 - val_loss: 0.6611 - val_acc: 0.6536\n",
      "Epoch 861/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6795 - acc: 0.5730 - val_loss: 0.6611 - val_acc: 0.6536\n",
      "Epoch 862/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6850 - acc: 0.5379 - val_loss: 0.6611 - val_acc: 0.6536\n",
      "Epoch 863/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.6847 - acc: 0.5449 - val_loss: 0.6611 - val_acc: 0.6536\n",
      "Epoch 864/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.6850 - acc: 0.5449 - val_loss: 0.6610 - val_acc: 0.6536\n",
      "Epoch 865/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.6771 - acc: 0.5927 - val_loss: 0.6610 - val_acc: 0.6536\n",
      "Epoch 866/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6828 - acc: 0.5660 - val_loss: 0.6610 - val_acc: 0.6536\n",
      "Epoch 867/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6841 - acc: 0.5618 - val_loss: 0.6610 - val_acc: 0.6536\n",
      "Epoch 868/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6758 - acc: 0.5787 - val_loss: 0.6610 - val_acc: 0.6536\n",
      "Epoch 869/1000\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.6734 - acc: 0.5857 - val_loss: 0.6610 - val_acc: 0.6536\n",
      "Epoch 870/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6849 - acc: 0.5463 - val_loss: 0.6609 - val_acc: 0.6536\n",
      "Epoch 871/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6835 - acc: 0.5548 - val_loss: 0.6609 - val_acc: 0.6536\n",
      "Epoch 872/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6831 - acc: 0.5337 - val_loss: 0.6609 - val_acc: 0.6536\n",
      "Epoch 873/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.6769 - acc: 0.5843 - val_loss: 0.6609 - val_acc: 0.6536\n",
      "Epoch 874/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.6794 - acc: 0.5660 - val_loss: 0.6609 - val_acc: 0.6536\n",
      "Epoch 875/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6758 - acc: 0.5618 - val_loss: 0.6609 - val_acc: 0.6536\n",
      "Epoch 876/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.6862 - acc: 0.5534 - val_loss: 0.6609 - val_acc: 0.6536\n",
      "Epoch 877/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6801 - acc: 0.5590 - val_loss: 0.6608 - val_acc: 0.6536\n",
      "Epoch 878/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.6774 - acc: 0.5562 - val_loss: 0.6608 - val_acc: 0.6536\n",
      "Epoch 879/1000\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.6752 - acc: 0.5871 - val_loss: 0.6608 - val_acc: 0.6536\n",
      "Epoch 880/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6848 - acc: 0.5379 - val_loss: 0.6608 - val_acc: 0.6536\n",
      "Epoch 881/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6844 - acc: 0.5492 - val_loss: 0.6608 - val_acc: 0.6536\n",
      "Epoch 882/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6752 - acc: 0.5744 - val_loss: 0.6608 - val_acc: 0.6536\n",
      "Epoch 883/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6866 - acc: 0.5506 - val_loss: 0.6607 - val_acc: 0.6536\n",
      "Epoch 884/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6806 - acc: 0.5520 - val_loss: 0.6607 - val_acc: 0.6536\n",
      "Epoch 885/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6870 - acc: 0.5435 - val_loss: 0.6607 - val_acc: 0.6536\n",
      "Epoch 886/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6783 - acc: 0.5646 - val_loss: 0.6607 - val_acc: 0.6536\n",
      "Epoch 887/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6792 - acc: 0.5534 - val_loss: 0.6607 - val_acc: 0.6536\n",
      "Epoch 888/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6783 - acc: 0.5604 - val_loss: 0.6607 - val_acc: 0.6536\n",
      "Epoch 889/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6812 - acc: 0.5562 - val_loss: 0.6607 - val_acc: 0.6536\n",
      "Epoch 890/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6823 - acc: 0.5463 - val_loss: 0.6606 - val_acc: 0.6536\n",
      "Epoch 891/1000\n",
      " 32/712 [>.............................] - ETA: 0s - loss: 0.7262 - acc: 0.3438"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-a6024ef984eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reduced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn = Sequential([\n",
    "    Dense(64, input_shape=(train_reduced.shape[1],), activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, verbose=1, mode='auto')\n",
    "callback_list = [earlystop]\n",
    "sgd = optimizers.SGD(lr=1e-6, decay=1e-8, momentum=0.9, nesterov=True)\n",
    "# For a binary classification problem\n",
    "nn.compile(optimizer=sgd,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "nn.fit(train_reduced, y, epochs=1000, batch_size=32, validation_split=0.2, shuffle=True, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
