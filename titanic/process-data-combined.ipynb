{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:56:37.126876Z",
     "start_time": "2018-09-24T07:56:34.525485Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import re\n",
    "# try using stacking\n",
    "from mlxtend.classifier import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T03:57:29.048469Z",
     "start_time": "2018-09-24T03:57:29.026727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "----------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_df.info()\n",
    "print('-'*40)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pal = dict(man=\"#4682B4\", woman=\"#CD5C5C\", child=\"#2E8B57\", male=\"#6495ED\", female=\"#F08080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff2ec22eda0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train_df['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f343bd9e978>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot('Sex', data=train_df, kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f33ff6ee160>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot('Who', data=train_df, kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7faad05e4b70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 437.975x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot('Pclass', data=train_df, hue='Sex', kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7faad043f128>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 439.85x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot('Pclass', data=train_df, hue='Who', kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f33ff75b940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432.25x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot('Survived', data=train_df, hue='Who', kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f33fd552358>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 402.375x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot('Survived', data=train_df, hue='Pclass', kind='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "? re.sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T09:05:38.503189Z",
     "start_time": "2018-09-24T09:05:37.737215Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akai/virtualenvs/tensor_flow/lib/python3.5/site-packages/ipykernel_launcher.py:24: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/akai/virtualenvs/tensor_flow/lib/python3.5/site-packages/ipykernel_launcher.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 16\n",
      "1 16 32\n",
      "2 32 48\n",
      "3 48 64\n",
      "4 64 80\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'AgeBand'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/virtualenvs/tensor_flow/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AgeBand'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-22ea68166cf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m#     dataset.loc[(dataset['Age'] > 55) & (dataset['Age'] <= 65), 'AgeBand'] = 6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m#     dataset.loc[(dataset['Age'] > 65), 'AgeBand'] = 7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AgeBand'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AgeBand'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fare'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Fare'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fare'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FareBand'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tensor_flow/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tensor_flow/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tensor_flow/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tensor_flow/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tensor_flow/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AgeBand'"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "combine = [train_df, test_df]\n",
    "y = train_df['Survived']\n",
    "# train_df.drop(['Survived'], axis=1, inplace=True)\n",
    "test_ids = test_df['PassengerId']\n",
    "def woman_child_or_man(passenger):\n",
    "    age, sex = passenger\n",
    "    if age < 16:\n",
    "        return \"child\"\n",
    "    else:\n",
    "        return dict(male=\"man\", female=\"woman\")[sex]\n",
    "    \n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    dataset.loc[dataset.Title=='Ms', 'Title'] = 'Miss' # unify the naming\n",
    "    dataset['Title'] = dataset['Title'].replace(['Mme', 'Mlle'], 'Mrs') # seem to be the title for old lady\n",
    "    dataset.loc[((dataset.Title=='Master') | (dataset.Title.isnull())) & (dataset.Age<15) & (dataset.Sex=='male'), 'Title'] = 'Boy'\n",
    "    dataset.loc[((dataset.Title=='Mrs') | dataset.Title.isnull() | (dataset.Title=='Miss') ) & (dataset.Sex=='female') & (dataset.Age<15), 'Title'] = 'Girl'\n",
    "    dataset['Title'] = dataset['Title'].replace(['Jonkheer', 'Don', 'Sir', 'Countess', 'Lady', 'Dona'], 'Royalty')\n",
    "    dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer')\n",
    "    \n",
    "combined = pd.concat([train_df, test_df])\n",
    "grouped_median_age = combined[train_df.Age.notnull()].groupby(['Sex', 'Pclass', 'Title']).median()\n",
    "grouped_median_age = grouped_median_age.reset_index()[['Sex', 'Pclass', 'Title', 'Age']]\n",
    "\n",
    "def assign_age(row):\n",
    "    condition = (\n",
    "        (grouped_median_age['Sex'] == row['Sex']) & \n",
    "        (grouped_median_age['Title'] == row['Title']) & \n",
    "        (grouped_median_age['Pclass'] == row['Pclass'])\n",
    "    )\n",
    "    return grouped_median_age[condition]['Age'].values[0]\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Age'] = dataset.apply(lambda row: assign_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)\n",
    "    dataset.loc[(dataset.Sex=='male') & (dataset.Pclass==3) & (dataset.Title=='Master'), 'Age'] = 35\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    dataset.loc[dataset.Embarked.isnull(), 'Embarked'] = 'S'\n",
    "    dataset.loc[dataset.Cabin.notnull(), 'Cabin'] = dataset.loc[dataset.Cabin.notnull(), 'Cabin'].map(lambda x: x[0])\n",
    "    dataset.loc[dataset.Cabin.isnull(), 'Cabin'] = 'U' #unknown\n",
    "    \n",
    "def cleanTicket(ticket):\n",
    "    original_ticket = ticket\n",
    "    ticket = ticket.split()\n",
    "    ticket = [''.join(ticket[:-1]), ticket[-1]]\n",
    "    ticket = ' '.join(ticket)\n",
    "    ticket = re.sub('/.+ ',' ', ticket)\n",
    "    ticket = ticket.replace('.', '')\n",
    "    ticket = ticket.replace('/', '')\n",
    "    ticket = ticket.split()\n",
    "    ticket = list(map(lambda t : t.strip().upper(), ticket))\n",
    "    if len(ticket)>2:\n",
    "        number = ticket[-1]\n",
    "        non_number = \"\".join(ticket[:-1])\n",
    "        ticket = [non_number, number]\n",
    "#     ticket = list(filter(lambda t : not t.isdigit(), ticket))\n",
    "    \n",
    "    if len(ticket) ==2:\n",
    "        res =  [ticket[0], int(ticket[1])]\n",
    "    elif len(ticket)==1:\n",
    "        try:\n",
    "            res =  ['XXX', int(ticket[0])]\n",
    "        except:\n",
    "            res = [ticket[0], 0]\n",
    "    if ticket[0] in ('AS', 'A4', 'A5', 'A2', 'AQ'):\n",
    "        res = ['A', ticket[1]]\n",
    "    elif ticket[0] in ('WE', 'WEP'):\n",
    "        res = ['W', ticket[1]]\n",
    "            \n",
    "#     print(original_ticket, res)\n",
    "    return res\n",
    "max_age = combined.Age.max()\n",
    "max_fare = combined.Fare.max()\n",
    "age_bands = np.linspace(0, max_age, 6, dtype=int)\n",
    "fare_bands = np.linspace(0, max_fare, 50)\n",
    "age_bins = zip(age_bands[:-1], age_bands[1:])\n",
    "fare_bins = zip(fare_bands[:-1], fare_bands[1:])\n",
    "\n",
    "for dataset in combine:    \n",
    "#     print(dataset.loc[dataset.Ticket.notnull(), 'Ticket'].size)\n",
    "    for i, (age_bin_left, age_bin_right) in enumerate(age_bins):\n",
    "        print(i, age_bin_left, age_bin_right)\n",
    "        dataset.loc[(dataset['Age']>=age_bin_left) & (dataset['Age']<age_bin_right), 'AgeBand'] = i+1\n",
    "#     print(dataset.AgeBand)\n",
    "#     dataset.loc[dataset['Fare'].isnull(), 'Fare'] = 8\n",
    "#     for i, (fare_bin_left, fare_bin_right) in enumerate(fare_bins):\n",
    "#         dataset.loc[(dataset['Fare']>=fare_bin_left) & (dataset['Fare']<fare_bin_right), 'FareBand'] = i+1\n",
    "#     dataset.loc[ dataset['Age'] <= 15, 'AgeBand'] = 1\n",
    "#     dataset.loc[(dataset['Age'] > 15) & (dataset['Age'] <= 25), 'AgeBand'] = 2\n",
    "#     dataset.loc[(dataset['Age'] > 25) & (dataset['Age'] <= 35), 'AgeBand'] = 3\n",
    "#     dataset.loc[(dataset['Age'] > 35) & (dataset['Age'] <= 45), 'AgeBand'] = 4\n",
    "#     dataset.loc[(dataset['Age'] > 45) & (dataset['Age'] <= 55), 'AgeBand'] = 5\n",
    "#     dataset.loc[(dataset['Age'] > 55) & (dataset['Age'] <= 65), 'AgeBand'] = 6\n",
    "#     dataset.loc[(dataset['Age'] > 65), 'AgeBand'] = 7\n",
    "    dataset['AgeBand'] = dataset['AgeBand'].astype(str)\n",
    "    dataset.loc[dataset['Fare'].isnull(), 'Fare'] = 8\n",
    "    dataset.loc[dataset['Fare'] <= 8, 'FareBand'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 8) & (dataset['Fare'] <= 50), 'FareBand'] = 2\n",
    "    dataset.loc[(dataset['Fare'] > 50) & (dataset['Fare'] <= 100), 'FareBand'] = 3\n",
    "    dataset.loc[ dataset['Fare'] > 100, 'FareBand'] = 4\n",
    "    dataset['FareBand'] = dataset['FareBand'].astype(str)\n",
    "    dataset['Pclass'] = dataset['Pclass'].astype(str)\n",
    "    dataset[['Ticket_NonNumber', 'Ticket_Number']] = pd.DataFrame(dataset['Ticket'].map(cleanTicket).values.tolist(), index=dataset.index)\n",
    "\n",
    "sns.distplot(train_df['Fare'])\n",
    "sns.distplot(test_df['Fare'])\n",
    "test_infos = test_df[['PassengerId', 'Name', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'Ticket', 'Title', 'Ticket_Number', 'FareBand', 'AgeBand', 'Pclass', 'IsAlone']]\n",
    "for dataset in combine:\n",
    "    dataset.drop(['PassengerId', 'Name', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'Ticket', 'Ticket_Number'], axis=1, inplace=True)\n",
    "print('columns before', train_df.columns)\n",
    "train_df.drop(['Survived'], axis=1, inplace=True)\n",
    "train_df = pd.get_dummies(train_df)\n",
    "print('columns after', train_df.columns)\n",
    "print(\"\\tnumber of columns\", len(train_df.columns))\n",
    "test_df = pd.get_dummies(test_df)\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set( train_df.columns ) - set( test_df.columns )\n",
    "print(\"\\tmissing columns\", missing_cols)\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    test_df[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "test_df = test_df[train_df.columns]\n",
    "train_df.to_csv('train_temp.csv')\n",
    "# print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T09:06:00.540343Z",
     "start_time": "2018-09-24T09:05:52.433236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** before reduced = [0.78212291 0.79888268 0.81460674 0.74719101 0.81355932]\n",
      "reduced shape (891, 13) (418, 13)\n",
      "*** retrain after reducing***\n",
      "0.7912158258762099\n",
      "Cross-validation of : <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "CV score = 0.7811283618230739\n",
      "**********\n",
      "Cross-validation of : <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>\n",
      "CV score = 0.7800298745969111\n",
      "**********\n",
      "Cross-validation of : <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "CV score = 0.8104177372262514\n",
      "**********\n",
      "Cross-validation of : <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
      "CV score = 0.818295672687334\n",
      "**********\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## array([0.81564246, 0.80446927, 0.80898876, 0.79213483, 0.8079096 ])\n",
    "# clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, min_samples_leaf=100, max_depth=2, random_state=random_state)\n",
    "\n",
    "## array([0.79888268, 0.81564246, 0.81460674, 0.80337079, 0.85875706])\n",
    "clf = RandomForestClassifier(max_depth=4, max_features=3, n_estimators=400)\n",
    "\n",
    "## array([0.75977654, 0.75977654, 0.7752809 , 0.76966292, 0.82485876])\n",
    "# clf = VotingClassifier(\n",
    "#     estimators=[\n",
    "#         ('lr', LogisticRegression()),\n",
    "#         ('svc', SVC()),\n",
    "#         ('tree', DecisionTreeClassifier(max_depth=2, max_features=3)),\n",
    "#         ('sgd', SGDClassifier()),\n",
    "#         ('linear_svc', LinearSVC()),\n",
    "#         ('gaussian', GaussianNB()),\n",
    "#         ('knn', KNeighborsClassifier(n_neighbors = 2))\n",
    "#     ],\n",
    "#     voting='hard',\n",
    "# )\n",
    "\n",
    "## array([0.82122905, 0.80446927, 0.79775281, 0.75842697, 0.8079096 ])\n",
    "# clf = AdaBoostClassifier(\n",
    "#     DecisionTreeClassifier(max_depth=1), n_estimators=300,\n",
    "#     algorithm='SAMME', learning_rate=0.2\n",
    "# )\n",
    "\n",
    "# clf = DecisionTreeClassifier()\n",
    "# cv = cross_val_score(clf, train_df, y, cv=5)\n",
    "# print(cv)\n",
    "clf.fit(train_df, y)\n",
    "# print(\"*\"*40, \"running grid search\")\n",
    "# param_test = {'n_estimators': np.linspace(100,500,5, dtype=np.int),\n",
    "#               'max_depth': [1,2,3,4,6,8],\n",
    "#               'max_features': ['sqrt', 'auto', 'log2'],\n",
    "#               'min_samples_split': [2, 3, 10],\n",
    "#               'min_samples_leaf': [1, 3, 10],\n",
    "#               'bootstrap': [True, False],\n",
    "#              }\n",
    "# gs = GridSearchCV(estimator=clf, param_grid=param_test, cv=5, n_jobs=5, verbose=1)\n",
    "# gs.fit(train_df, y)\n",
    "# print(\"*\"*40, \"best params\", gs.best_params_, gs.best_score_)\n",
    "# clf.fit(train_df, y)\n",
    "cv = cross_val_score(clf, train_df, y, cv=5)\n",
    "print(\"** before reduced = {}\".format(cv))\n",
    "features = pd.DataFrame()\n",
    "features['feature'] = train_df.columns\n",
    "features['importance'] = clf.feature_importances_\n",
    "features.sort_values(by=['importance'], ascending=True, inplace=True)\n",
    "features.set_index('feature', inplace=True)\n",
    "features.plot(kind='barh', figsize=(25, 25))\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "train_reduced = model.transform(train_df)\n",
    "test_reduced = model.transform(test_df)\n",
    "print(\"reduced shape\", train_reduced.shape, test_reduced.shape)\n",
    "print(\"*** retrain after reducing***\")\n",
    "print(np.mean(cross_val_score(clf, train_reduced, y, cv=5)))\n",
    "clf.fit(train_reduced, y)\n",
    "logreg = LogisticRegression()\n",
    "logreg_cv = LogisticRegressionCV()\n",
    "rf = RandomForestClassifier()\n",
    "gboost = GradientBoostingClassifier()\n",
    "\n",
    "models = [logreg, logreg_cv, rf, gboost]\n",
    "for m in models:\n",
    "    print('Cross-validation of : {0}'.format(m.__class__))\n",
    "    score = np.mean(cross_val_score(m, X=train_reduced, y=y, scoring='accuracy', cv=5))\n",
    "    print('CV score = {0}'.format(score))\n",
    "    print('*'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T08:29:14.890139Z",
     "start_time": "2018-09-24T08:02:31.531399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************** running grid search\n",
      "Fitting 5 folds for each of 3240 candidates, totalling 16200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=5)]: Done 190 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=5)]: Done 440 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=5)]: Done 790 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=5)]: Done 1240 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=5)]: Done 1790 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=5)]: Done 2440 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=5)]: Done 3190 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=5)]: Done 4040 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=5)]: Done 4990 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=5)]: Done 6040 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=5)]: Done 7190 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=5)]: Done 8440 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=5)]: Done 9790 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=5)]: Done 11240 tasks      | elapsed: 32.8min\n",
      "[Parallel(n_jobs=5)]: Done 12790 tasks      | elapsed: 37.2min\n",
      "[Parallel(n_jobs=5)]: Done 14440 tasks      | elapsed: 42.1min\n",
      "[Parallel(n_jobs=5)]: Done 16190 tasks      | elapsed: 47.4min\n",
      "[Parallel(n_jobs=5)]: Done 16200 out of 16200 | elapsed: 47.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************** best params for random forest {'min_samples_split': 3, 'min_samples_leaf': 3, 'max_depth': 8, 'bootstrap': True, 'n_estimators': 300, 'max_features': 4} 0.8249158249158249\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*40, \"running grid search\")\n",
    "param_test = {'n_estimators': np.linspace(100,500,5, dtype=np.int),\n",
    "              'max_depth': [1,2,3,4,6,8],\n",
    "              'max_features': ['sqrt', 'auto', 'log2', 2, 3, 4],\n",
    "              'min_samples_split': [2, 3, 10],\n",
    "              'min_samples_leaf': [1, 3, 10],\n",
    "              'bootstrap': [True, False],\n",
    "             }\n",
    "gs = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_test, cv=5, n_jobs=5, verbose=1)\n",
    "gs.fit(train_reduced, y)\n",
    "print(\"*\"*40, \"best params for random forest\", gs.best_params_, gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** best score for random forest = 0.8182704934805359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=100, max_features=10, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest = RandomForestClassifier(**{\n",
    "    'min_samples_split': 3,                                     \n",
    "    'min_samples_leaf': 3, \n",
    "    'max_depth': 100, \n",
    "    'bootstrap': True, \n",
    "    'n_estimators': 400, \n",
    "    'max_features': 10})\n",
    "score = np.mean(cross_val_score(best_forest, train_reduced, y, cv=5))\n",
    "print(\"** best score for random forest = {}\".format(score))\n",
    "best_forest.fit(train_reduced, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:14:45.501102Z",
     "start_time": "2018-09-24T06:39:03.922274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3600 candidates, totalling 18000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done 175 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=5)]: Done 625 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=5)]: Done 1017 tasks      | elapsed:   46.6s\n",
      "[Parallel(n_jobs=5)]: Done 1367 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=5)]: Done 1817 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=5)]: Done 2367 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=5)]: Done 3017 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=5)]: Done 3767 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=5)]: Done 4617 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=5)]: Done 5567 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=5)]: Done 6617 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=5)]: Done 7767 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=5)]: Done 9017 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=5)]: Done 10367 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=5)]: Done 11817 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=5)]: Done 13367 tasks      | elapsed: 24.8min\n",
      "[Parallel(n_jobs=5)]: Done 15017 tasks      | elapsed: 28.6min\n",
      "[Parallel(n_jobs=5)]: Done 16767 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=5)]: Done 18000 out of 18000 | elapsed: 35.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=5,\n",
       "       param_grid={'learning_rate': array([0.1, 0.2, 0.3, 0.4, 0.5]), 'n_estimators': array([ 100,  212,  325,  437,  550,  662,  775,  887, 1000]), 'max_depth': array([1, 2, 3, 4, 5]), 'min_samples_split': [2, 5, 10, 20], 'max_features': [2, 4, 6, 8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test = {\n",
    "    'learning_rate': np.linspace(0.1, 0.5, 5),\n",
    "    'n_estimators': np.linspace(100, 1000, 9, dtype=np.int),\n",
    "    'max_depth': np.linspace(1, 5, 5, dtype=np.int),\n",
    "    'min_samples_split': [2,5,10,20],\n",
    "    'max_features': [2,4,6,8]\n",
    "}\n",
    "gs = GridSearchCV(estimator=GradientBoostingClassifier(), param_grid=param_test, cv=5, n_jobs=5, verbose=1)\n",
    "gs.fit(train_reduced, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T03:58:02.373900Z",
     "start_time": "2018-09-24T03:57:27.405Z"
    }
   },
   "outputs": [],
   "source": [
    "gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T09:35:36.158814Z",
     "start_time": "2018-09-24T09:35:33.144719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** score = 0.7732880887811738\n"
     ]
    }
   ],
   "source": [
    "ada_boosting = AdaBoostClassifier(n_estimators=500, learning_rate=0.1, algorithm='SAMME', random_state=random_state)\n",
    "score = np.mean(cross_val_score(ada_boosting, train_reduced, y, cv=5))\n",
    "print(\"** score = {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:38:41.024658Z",
     "start_time": "2018-09-24T06:38:39.833955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** score = 0.8148742440475114\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting = GradientBoostingClassifier(\n",
    "    learning_rate=0.5,\n",
    "    n_estimators=437, \n",
    "    max_depth= 2,\n",
    "    min_samples_leaf= 2,\n",
    "    min_samples_split=2)\n",
    "score = np.mean(cross_val_score(gradient_boosting, train_reduced, y, cv=5))\n",
    "gradient_boosting.fit(train_reduced, y)\n",
    "print(\"** score = {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:28:29.698641Z",
     "start_time": "2018-09-24T06:28:29.664494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId                                          Name   Age  SibSp  \\\n",
      "0          892                              Kelly, Mr. James  34.5      0   \n",
      "1          893              Wilkes, Mrs. James (Ellen Needs)  47.0      1   \n",
      "2          894                     Myles, Mr. Thomas Francis  62.0      0   \n",
      "3          895                              Wirz, Mr. Albert  27.0      0   \n",
      "4          896  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  22.0      1   \n",
      "\n",
      "   Parch     Fare  FamilySize   Ticket Title Ticket_Number FareBand AgeBand  \\\n",
      "0      0   7.8292           1   330911    Mr        330911      0.0     1.0   \n",
      "1      0   7.0000           2   363272   Mrs        363272      0.0     2.0   \n",
      "2      0   9.6875           1   240276    Mr        240276      1.0     2.0   \n",
      "3      0   8.6625           1   315154    Mr        315154      1.0     1.0   \n",
      "4      1  12.2875           3  3101298   Mrs       3101298      1.0     1.0   \n",
      "\n",
      "  Pclass  IsAlone  Survived  \n",
      "0      3        1         0  \n",
      "1      3        0         1  \n",
      "2      2        1         0  \n",
      "3      3        1         0  \n",
      "4      3        0         0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akai/virtualenvs/tensor_flow/lib/python3.5/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_pred = best_forest.predict(test_reduced)\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_ids,\n",
    "    \"Survived\": y_pred\n",
    "})\n",
    "test_infos['Survived'] = y_pred\n",
    "print(test_infos.head())\n",
    "test_infos.to_csv('titanic_result_feature_engineer_random_forest_inspection.csv')\n",
    "submission.to_csv('titanic_result_feature_engineer_random_forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeBand_0.0</th>\n",
       "      <th>AgeBand_1.0</th>\n",
       "      <th>AgeBand_2.0</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_NonNumber_W</th>\n",
       "      <th>Ticket_NonNumber_XXX</th>\n",
       "      <th>Title_Boy</th>\n",
       "      <th>Title_Girl</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AgeBand_0.0  AgeBand_1.0  AgeBand_2.0  Cabin_A  Cabin_B  Cabin_C  Cabin_D  \\\n",
       "0           0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "1           0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "2           0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "3           0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "4           0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "5           1.0          0.0          0.0      0.0      0.0      0.0      0.0   \n",
       "6           0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "7           0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "8           0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "9           0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "10          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "11          0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "12          0.0          1.0          0.0      0.0      1.0      0.0      0.0   \n",
       "13          0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "14          0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "15          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "16          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "17          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "18          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "19          0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "20          0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "21          1.0          0.0          0.0      0.0      0.0      0.0      0.0   \n",
       "22          0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "23          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "24          0.0          0.0          1.0      0.0      1.0      0.0      0.0   \n",
       "25          0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "26          0.0          1.0          0.0      0.0      1.0      0.0      0.0   \n",
       "27          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "28          0.0          0.0          1.0      1.0      0.0      0.0      0.0   \n",
       "29          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "..          ...          ...          ...      ...      ...      ...      ...   \n",
       "70          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "71          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "72          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "73          0.0          1.0          0.0      0.0      0.0      0.0      1.0   \n",
       "74          0.0          1.0          0.0      0.0      0.0      1.0      0.0   \n",
       "75          0.0          1.0          0.0      0.0      0.0      1.0      0.0   \n",
       "76          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "77          0.0          0.0          1.0      0.0      0.0      1.0      0.0   \n",
       "78          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "79          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "80          1.0          0.0          0.0      0.0      0.0      0.0      0.0   \n",
       "81          0.0          0.0          1.0      0.0      0.0      1.0      0.0   \n",
       "82          0.0          0.0          1.0      0.0      0.0      0.0      0.0   \n",
       "83          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "84          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "85          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "86          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "87          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "88          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "89          1.0          0.0          0.0      0.0      0.0      0.0      0.0   \n",
       "90          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "91          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "92          0.0          1.0          0.0      0.0      1.0      0.0      0.0   \n",
       "93          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "94          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "95          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "96          0.0          0.0          1.0      0.0      0.0      1.0      0.0   \n",
       "97          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "98          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "99          0.0          1.0          0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "    Cabin_E  Cabin_F  Cabin_G      ...        Ticket_NonNumber_W  \\\n",
       "0       0.0      0.0      0.0      ...                       0.0   \n",
       "1       0.0      0.0      0.0      ...                       0.0   \n",
       "2       0.0      0.0      0.0      ...                       0.0   \n",
       "3       0.0      0.0      0.0      ...                       0.0   \n",
       "4       0.0      0.0      0.0      ...                       0.0   \n",
       "5       0.0      0.0      0.0      ...                       0.0   \n",
       "6       0.0      0.0      0.0      ...                       0.0   \n",
       "7       0.0      0.0      0.0      ...                       0.0   \n",
       "8       0.0      0.0      0.0      ...                       0.0   \n",
       "9       0.0      0.0      0.0      ...                       0.0   \n",
       "10      0.0      0.0      0.0      ...                       0.0   \n",
       "11      0.0      0.0      0.0      ...                       0.0   \n",
       "12      0.0      0.0      0.0      ...                       0.0   \n",
       "13      0.0      0.0      0.0      ...                       0.0   \n",
       "14      1.0      0.0      0.0      ...                       1.0   \n",
       "15      0.0      0.0      0.0      ...                       0.0   \n",
       "16      0.0      0.0      0.0      ...                       0.0   \n",
       "17      0.0      0.0      0.0      ...                       0.0   \n",
       "18      0.0      0.0      0.0      ...                       0.0   \n",
       "19      0.0      0.0      0.0      ...                       0.0   \n",
       "20      0.0      0.0      0.0      ...                       0.0   \n",
       "21      0.0      0.0      0.0      ...                       0.0   \n",
       "22      0.0      0.0      0.0      ...                       0.0   \n",
       "23      0.0      0.0      0.0      ...                       0.0   \n",
       "24      0.0      0.0      0.0      ...                       0.0   \n",
       "25      0.0      0.0      0.0      ...                       0.0   \n",
       "26      0.0      0.0      0.0      ...                       0.0   \n",
       "27      0.0      0.0      0.0      ...                       0.0   \n",
       "28      0.0      0.0      0.0      ...                       0.0   \n",
       "29      0.0      0.0      0.0      ...                       0.0   \n",
       "..      ...      ...      ...      ...                       ...   \n",
       "70      0.0      0.0      0.0      ...                       0.0   \n",
       "71      0.0      0.0      0.0      ...                       0.0   \n",
       "72      0.0      0.0      0.0      ...                       0.0   \n",
       "73      0.0      0.0      0.0      ...                       0.0   \n",
       "74      0.0      0.0      0.0      ...                       0.0   \n",
       "75      0.0      0.0      0.0      ...                       0.0   \n",
       "76      0.0      0.0      0.0      ...                       0.0   \n",
       "77      0.0      0.0      0.0      ...                       0.0   \n",
       "78      0.0      0.0      0.0      ...                       0.0   \n",
       "79      0.0      0.0      0.0      ...                       0.0   \n",
       "80      0.0      0.0      0.0      ...                       0.0   \n",
       "81      0.0      0.0      0.0      ...                       0.0   \n",
       "82      0.0      0.0      0.0      ...                       0.0   \n",
       "83      0.0      0.0      0.0      ...                       0.0   \n",
       "84      0.0      0.0      0.0      ...                       0.0   \n",
       "85      0.0      0.0      0.0      ...                       0.0   \n",
       "86      0.0      0.0      0.0      ...                       0.0   \n",
       "87      0.0      0.0      0.0      ...                       0.0   \n",
       "88      0.0      0.0      0.0      ...                       0.0   \n",
       "89      0.0      0.0      0.0      ...                       0.0   \n",
       "90      0.0      0.0      0.0      ...                       0.0   \n",
       "91      0.0      0.0      0.0      ...                       0.0   \n",
       "92      0.0      0.0      0.0      ...                       0.0   \n",
       "93      0.0      0.0      0.0      ...                       0.0   \n",
       "94      0.0      0.0      0.0      ...                       0.0   \n",
       "95      0.0      0.0      0.0      ...                       0.0   \n",
       "96      0.0      0.0      0.0      ...                       0.0   \n",
       "97      0.0      0.0      0.0      ...                       0.0   \n",
       "98      0.0      0.0      0.0      ...                       0.0   \n",
       "99      0.0      0.0      0.0      ...                       0.0   \n",
       "\n",
       "    Ticket_NonNumber_XXX  Title_Boy  Title_Girl  Title_Master  Title_Miss  \\\n",
       "0                    1.0        0.0         0.0           0.0         0.0   \n",
       "1                    1.0        0.0         0.0           0.0         0.0   \n",
       "2                    1.0        0.0         0.0           0.0         0.0   \n",
       "3                    1.0        0.0         0.0           0.0         0.0   \n",
       "4                    1.0        0.0         0.0           0.0         0.0   \n",
       "5                    1.0        0.0         0.0           0.0         0.0   \n",
       "6                    1.0        0.0         0.0           0.0         1.0   \n",
       "7                    1.0        0.0         0.0           0.0         0.0   \n",
       "8                    1.0        0.0         0.0           0.0         0.0   \n",
       "9                    0.0        0.0         0.0           0.0         0.0   \n",
       "10                   1.0        0.0         0.0           0.0         0.0   \n",
       "11                   1.0        0.0         0.0           0.0         0.0   \n",
       "12                   1.0        0.0         0.0           0.0         0.0   \n",
       "13                   1.0        0.0         0.0           0.0         0.0   \n",
       "14                   0.0        0.0         0.0           0.0         0.0   \n",
       "15                   0.0        0.0         0.0           0.0         0.0   \n",
       "16                   1.0        0.0         0.0           0.0         0.0   \n",
       "17                   1.0        0.0         0.0           0.0         0.0   \n",
       "18                   0.0        0.0         0.0           0.0         1.0   \n",
       "19                   1.0        0.0         0.0           0.0         0.0   \n",
       "20                   0.0        0.0         0.0           0.0         0.0   \n",
       "21                   0.0        1.0         0.0           0.0         0.0   \n",
       "22                   0.0        0.0         0.0           0.0         0.0   \n",
       "23                   0.0        0.0         0.0           0.0         0.0   \n",
       "24                   0.0        0.0         0.0           0.0         0.0   \n",
       "25                   0.0        0.0         0.0           0.0         0.0   \n",
       "26                   1.0        0.0         0.0           0.0         1.0   \n",
       "27                   1.0        0.0         0.0           0.0         0.0   \n",
       "28                   1.0        0.0         0.0           0.0         0.0   \n",
       "29                   1.0        0.0         0.0           0.0         0.0   \n",
       "..                   ...        ...         ...           ...         ...   \n",
       "70                   1.0        0.0         0.0           0.0         1.0   \n",
       "71                   1.0        0.0         0.0           0.0         0.0   \n",
       "72                   1.0        0.0         0.0           0.0         1.0   \n",
       "73                   0.0        0.0         0.0           0.0         0.0   \n",
       "74                   1.0        0.0         0.0           0.0         1.0   \n",
       "75                   1.0        0.0         0.0           0.0         0.0   \n",
       "76                   1.0        0.0         0.0           0.0         0.0   \n",
       "77                   1.0        0.0         0.0           0.0         0.0   \n",
       "78                   1.0        0.0         0.0           0.0         0.0   \n",
       "79                   1.0        0.0         0.0           0.0         1.0   \n",
       "80                   1.0        1.0         0.0           0.0         0.0   \n",
       "81                   0.0        0.0         0.0           0.0         0.0   \n",
       "82                   1.0        0.0         0.0           0.0         0.0   \n",
       "83                   1.0        0.0         0.0           0.0         0.0   \n",
       "84                   1.0        0.0         0.0           0.0         0.0   \n",
       "85                   1.0        0.0         0.0           0.0         0.0   \n",
       "86                   1.0        0.0         0.0           0.0         1.0   \n",
       "87                   0.0        0.0         0.0           0.0         1.0   \n",
       "88                   1.0        0.0         0.0           0.0         1.0   \n",
       "89                   1.0        1.0         0.0           0.0         0.0   \n",
       "90                   1.0        0.0         0.0           0.0         0.0   \n",
       "91                   1.0        0.0         0.0           0.0         0.0   \n",
       "92                   0.0        0.0         0.0           0.0         0.0   \n",
       "93                   1.0        0.0         0.0           0.0         0.0   \n",
       "94                   1.0        0.0         0.0           0.0         0.0   \n",
       "95                   1.0        0.0         0.0           0.0         0.0   \n",
       "96                   1.0        0.0         0.0           0.0         0.0   \n",
       "97                   0.0        0.0         0.0           0.0         0.0   \n",
       "98                   1.0        0.0         0.0           0.0         1.0   \n",
       "99                   0.0        0.0         0.0           0.0         0.0   \n",
       "\n",
       "    Title_Mr  Title_Mrs  Title_Officer  Title_Royalty  \n",
       "0        1.0        0.0            0.0            0.0  \n",
       "1        0.0        1.0            0.0            0.0  \n",
       "2        1.0        0.0            0.0            0.0  \n",
       "3        1.0        0.0            0.0            0.0  \n",
       "4        0.0        1.0            0.0            0.0  \n",
       "5        1.0        0.0            0.0            0.0  \n",
       "6        0.0        0.0            0.0            0.0  \n",
       "7        1.0        0.0            0.0            0.0  \n",
       "8        0.0        1.0            0.0            0.0  \n",
       "9        1.0        0.0            0.0            0.0  \n",
       "10       1.0        0.0            0.0            0.0  \n",
       "11       1.0        0.0            0.0            0.0  \n",
       "12       0.0        1.0            0.0            0.0  \n",
       "13       1.0        0.0            0.0            0.0  \n",
       "14       0.0        1.0            0.0            0.0  \n",
       "15       0.0        1.0            0.0            0.0  \n",
       "16       1.0        0.0            0.0            0.0  \n",
       "17       1.0        0.0            0.0            0.0  \n",
       "18       0.0        0.0            0.0            0.0  \n",
       "19       0.0        1.0            0.0            0.0  \n",
       "20       1.0        0.0            0.0            0.0  \n",
       "21       0.0        0.0            0.0            0.0  \n",
       "22       0.0        1.0            0.0            0.0  \n",
       "23       1.0        0.0            0.0            0.0  \n",
       "24       0.0        1.0            0.0            0.0  \n",
       "25       1.0        0.0            0.0            0.0  \n",
       "26       0.0        0.0            0.0            0.0  \n",
       "27       1.0        0.0            0.0            0.0  \n",
       "28       1.0        0.0            0.0            0.0  \n",
       "29       1.0        0.0            0.0            0.0  \n",
       "..       ...        ...            ...            ...  \n",
       "70       0.0        0.0            0.0            0.0  \n",
       "71       1.0        0.0            0.0            0.0  \n",
       "72       0.0        0.0            0.0            0.0  \n",
       "73       1.0        0.0            0.0            0.0  \n",
       "74       0.0        0.0            0.0            0.0  \n",
       "75       1.0        0.0            0.0            0.0  \n",
       "76       1.0        0.0            0.0            0.0  \n",
       "77       0.0        1.0            0.0            0.0  \n",
       "78       1.0        0.0            0.0            0.0  \n",
       "79       0.0        0.0            0.0            0.0  \n",
       "80       0.0        0.0            0.0            0.0  \n",
       "81       1.0        0.0            0.0            0.0  \n",
       "82       1.0        0.0            0.0            0.0  \n",
       "83       1.0        0.0            0.0            0.0  \n",
       "84       1.0        0.0            0.0            0.0  \n",
       "85       1.0        0.0            0.0            0.0  \n",
       "86       0.0        0.0            0.0            0.0  \n",
       "87       0.0        0.0            0.0            0.0  \n",
       "88       0.0        0.0            0.0            0.0  \n",
       "89       0.0        0.0            0.0            0.0  \n",
       "90       0.0        1.0            0.0            0.0  \n",
       "91       1.0        0.0            0.0            0.0  \n",
       "92       0.0        1.0            0.0            0.0  \n",
       "93       1.0        0.0            0.0            0.0  \n",
       "94       1.0        0.0            0.0            0.0  \n",
       "95       1.0        0.0            0.0            0.0  \n",
       "96       0.0        1.0            0.0            0.0  \n",
       "97       1.0        0.0            0.0            0.0  \n",
       "98       0.0        0.0            0.0            0.0  \n",
       "99       1.0        0.0            0.0            0.0  \n",
       "\n",
       "[100 rows x 55 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_inspection.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:28:49.681804Z",
     "start_time": "2018-09-24T06:28:44.861953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Titanic: Machine Learning from Disaster"
     ]
    }
   ],
   "source": [
    "! kaggle competitions submit titanic -f titanic_result_feature_engineer_random_forest.csv -m \"feature engineer (fix ticket) + random forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:48:03.184053Z",
     "start_time": "2018-09-24T07:47:57.010174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "          classifiers=[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=8, max_features=4, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=3, min_samples_split=3,\n",
       "            min_weight_fraction_...c_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
       "           weights='uniform'), GaussianNB(priors=None)],\n",
       "          meta_classifier=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          store_train_meta_features=False, use_clones=True,\n",
       "          use_features_in_secondary=False, use_probas=False, verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = KNeighborsClassifier(n_neighbors=2)\n",
    "clf3 = GaussianNB()\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[best_forest, ada_boosting, gradient_boosting, clf1, clf3], \n",
    "                          meta_classifier=lr)\n",
    "np.mean(cross_val_score(sclf, train_reduced, y, cv=5))\n",
    "sclf.fit(train_reduced, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T07:57:28.036289Z",
     "start_time": "2018-09-24T07:57:28.032290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reduced.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T08:02:18.986796Z",
     "start_time": "2018-09-24T08:00:53.707652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 179 samples\n",
      "Epoch 1/1000\n",
      "712/712 [==============================] - 1s 971us/step - loss: 0.6998 - acc: 0.5084 - val_loss: 0.6752 - val_acc: 0.7095\n",
      "Epoch 2/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6893 - acc: 0.5478 - val_loss: 0.6751 - val_acc: 0.7095\n",
      "Epoch 3/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6964 - acc: 0.5028 - val_loss: 0.6751 - val_acc: 0.7095\n",
      "Epoch 4/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6903 - acc: 0.5295 - val_loss: 0.6751 - val_acc: 0.7095\n",
      "Epoch 5/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6889 - acc: 0.5520 - val_loss: 0.6751 - val_acc: 0.7095\n",
      "Epoch 6/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6967 - acc: 0.5098 - val_loss: 0.6751 - val_acc: 0.7095\n",
      "Epoch 7/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6919 - acc: 0.5281 - val_loss: 0.6751 - val_acc: 0.7095\n",
      "Epoch 8/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6953 - acc: 0.5154 - val_loss: 0.6750 - val_acc: 0.7095\n",
      "Epoch 9/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6930 - acc: 0.5239 - val_loss: 0.6750 - val_acc: 0.7095\n",
      "Epoch 10/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6935 - acc: 0.5295 - val_loss: 0.6750 - val_acc: 0.7095\n",
      "Epoch 11/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6908 - acc: 0.5028 - val_loss: 0.6750 - val_acc: 0.7095\n",
      "Epoch 12/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6877 - acc: 0.5393 - val_loss: 0.6750 - val_acc: 0.7095\n",
      "Epoch 13/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6969 - acc: 0.5098 - val_loss: 0.6749 - val_acc: 0.7095\n",
      "Epoch 14/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6940 - acc: 0.5309 - val_loss: 0.6749 - val_acc: 0.7095\n",
      "Epoch 15/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6845 - acc: 0.5646 - val_loss: 0.6749 - val_acc: 0.7095\n",
      "Epoch 16/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6863 - acc: 0.5646 - val_loss: 0.6749 - val_acc: 0.7095\n",
      "Epoch 17/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6926 - acc: 0.5365 - val_loss: 0.6749 - val_acc: 0.7095\n",
      "Epoch 18/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6955 - acc: 0.5379 - val_loss: 0.6749 - val_acc: 0.7095\n",
      "Epoch 19/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6871 - acc: 0.5492 - val_loss: 0.6748 - val_acc: 0.7095\n",
      "Epoch 20/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6883 - acc: 0.5506 - val_loss: 0.6748 - val_acc: 0.6983\n",
      "Epoch 21/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6934 - acc: 0.5070 - val_loss: 0.6748 - val_acc: 0.6983\n",
      "Epoch 22/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6989 - acc: 0.5056 - val_loss: 0.6748 - val_acc: 0.6983\n",
      "Epoch 23/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6856 - acc: 0.5379 - val_loss: 0.6748 - val_acc: 0.6983\n",
      "Epoch 24/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6954 - acc: 0.5028 - val_loss: 0.6747 - val_acc: 0.6983\n",
      "Epoch 25/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6930 - acc: 0.5084 - val_loss: 0.6747 - val_acc: 0.6983\n",
      "Epoch 26/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6911 - acc: 0.5323 - val_loss: 0.6747 - val_acc: 0.6983\n",
      "Epoch 27/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6905 - acc: 0.5309 - val_loss: 0.6747 - val_acc: 0.6983\n",
      "Epoch 28/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6875 - acc: 0.5407 - val_loss: 0.6747 - val_acc: 0.6983\n",
      "Epoch 29/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6977 - acc: 0.5084 - val_loss: 0.6747 - val_acc: 0.6983\n",
      "Epoch 30/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6911 - acc: 0.5337 - val_loss: 0.6746 - val_acc: 0.6983\n",
      "Epoch 31/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6954 - acc: 0.5267 - val_loss: 0.6746 - val_acc: 0.6983\n",
      "Epoch 32/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6900 - acc: 0.5267 - val_loss: 0.6746 - val_acc: 0.6983\n",
      "Epoch 33/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6888 - acc: 0.5548 - val_loss: 0.6746 - val_acc: 0.6983\n",
      "Epoch 34/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6942 - acc: 0.5154 - val_loss: 0.6746 - val_acc: 0.6983\n",
      "Epoch 35/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6962 - acc: 0.5183 - val_loss: 0.6746 - val_acc: 0.6983\n",
      "Epoch 36/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6873 - acc: 0.5730 - val_loss: 0.6745 - val_acc: 0.6927\n",
      "Epoch 37/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6954 - acc: 0.5098 - val_loss: 0.6745 - val_acc: 0.6927\n",
      "Epoch 38/1000\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6927 - acc: 0.5309 - val_loss: 0.6745 - val_acc: 0.6927\n",
      "Epoch 39/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6903 - acc: 0.5140 - val_loss: 0.6745 - val_acc: 0.6927\n",
      "Epoch 40/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6928 - acc: 0.5140 - val_loss: 0.6745 - val_acc: 0.6927\n",
      "Epoch 41/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6949 - acc: 0.5239 - val_loss: 0.6744 - val_acc: 0.6927\n",
      "Epoch 42/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6844 - acc: 0.5463 - val_loss: 0.6744 - val_acc: 0.6927\n",
      "Epoch 43/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6926 - acc: 0.5169 - val_loss: 0.6744 - val_acc: 0.6927\n",
      "Epoch 44/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6939 - acc: 0.5211 - val_loss: 0.6744 - val_acc: 0.6927\n",
      "Epoch 45/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6953 - acc: 0.5112 - val_loss: 0.6744 - val_acc: 0.6927\n",
      "Epoch 46/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6987 - acc: 0.5056 - val_loss: 0.6744 - val_acc: 0.6927\n",
      "Epoch 47/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6913 - acc: 0.5197 - val_loss: 0.6743 - val_acc: 0.6927\n",
      "Epoch 48/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6834 - acc: 0.5590 - val_loss: 0.6743 - val_acc: 0.6927\n",
      "Epoch 49/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6857 - acc: 0.5548 - val_loss: 0.6743 - val_acc: 0.6927\n",
      "Epoch 50/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6908 - acc: 0.5253 - val_loss: 0.6743 - val_acc: 0.6927\n",
      "Epoch 51/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6932 - acc: 0.5337 - val_loss: 0.6743 - val_acc: 0.6927\n",
      "Epoch 52/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6862 - acc: 0.5421 - val_loss: 0.6743 - val_acc: 0.6927\n",
      "Epoch 53/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6937 - acc: 0.5295 - val_loss: 0.6742 - val_acc: 0.6927\n",
      "Epoch 54/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6873 - acc: 0.5393 - val_loss: 0.6742 - val_acc: 0.6927\n",
      "Epoch 55/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.6879 - acc: 0.5295 - val_loss: 0.6742 - val_acc: 0.6927\n",
      "Epoch 56/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6854 - acc: 0.5365 - val_loss: 0.6742 - val_acc: 0.6927\n",
      "Epoch 57/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6922 - acc: 0.5253 - val_loss: 0.6742 - val_acc: 0.6927\n",
      "Epoch 58/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6921 - acc: 0.5225 - val_loss: 0.6741 - val_acc: 0.6927\n",
      "Epoch 59/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6891 - acc: 0.5295 - val_loss: 0.6741 - val_acc: 0.6927\n",
      "Epoch 60/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6932 - acc: 0.5239 - val_loss: 0.6741 - val_acc: 0.6927\n",
      "Epoch 61/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6879 - acc: 0.5295 - val_loss: 0.6741 - val_acc: 0.6927\n",
      "Epoch 62/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6863 - acc: 0.5421 - val_loss: 0.6741 - val_acc: 0.6927\n",
      "Epoch 63/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6902 - acc: 0.5379 - val_loss: 0.6741 - val_acc: 0.6927\n",
      "Epoch 64/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6948 - acc: 0.4874 - val_loss: 0.6740 - val_acc: 0.6927\n",
      "Epoch 65/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6926 - acc: 0.5112 - val_loss: 0.6740 - val_acc: 0.6927\n",
      "Epoch 66/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6902 - acc: 0.5492 - val_loss: 0.6740 - val_acc: 0.6927\n",
      "Epoch 67/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6972 - acc: 0.5154 - val_loss: 0.6740 - val_acc: 0.6927\n",
      "Epoch 68/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6827 - acc: 0.5632 - val_loss: 0.6740 - val_acc: 0.6927\n",
      "Epoch 69/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6929 - acc: 0.5253 - val_loss: 0.6739 - val_acc: 0.6927\n",
      "Epoch 70/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6933 - acc: 0.5211 - val_loss: 0.6739 - val_acc: 0.6927\n",
      "Epoch 71/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6845 - acc: 0.5365 - val_loss: 0.6739 - val_acc: 0.6927\n",
      "Epoch 72/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6914 - acc: 0.5337 - val_loss: 0.6739 - val_acc: 0.6927\n",
      "Epoch 73/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6940 - acc: 0.5211 - val_loss: 0.6739 - val_acc: 0.6927\n",
      "Epoch 74/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6916 - acc: 0.5197 - val_loss: 0.6738 - val_acc: 0.6927\n",
      "Epoch 75/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6922 - acc: 0.5323 - val_loss: 0.6738 - val_acc: 0.6927\n",
      "Epoch 76/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6945 - acc: 0.5393 - val_loss: 0.6738 - val_acc: 0.6927\n",
      "Epoch 77/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6912 - acc: 0.5267 - val_loss: 0.6738 - val_acc: 0.6927\n",
      "Epoch 78/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6854 - acc: 0.5295 - val_loss: 0.6738 - val_acc: 0.6927\n",
      "Epoch 79/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6896 - acc: 0.5421 - val_loss: 0.6738 - val_acc: 0.6927\n",
      "Epoch 80/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6945 - acc: 0.5295 - val_loss: 0.6737 - val_acc: 0.6927\n",
      "Epoch 81/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6926 - acc: 0.5365 - val_loss: 0.6737 - val_acc: 0.6927\n",
      "Epoch 82/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6873 - acc: 0.5365 - val_loss: 0.6737 - val_acc: 0.6927\n",
      "Epoch 83/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6932 - acc: 0.4972 - val_loss: 0.6737 - val_acc: 0.6927\n",
      "Epoch 84/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6925 - acc: 0.5393 - val_loss: 0.6737 - val_acc: 0.6927\n",
      "Epoch 85/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6975 - acc: 0.5014 - val_loss: 0.6737 - val_acc: 0.6927\n",
      "Epoch 86/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6912 - acc: 0.5393 - val_loss: 0.6736 - val_acc: 0.6927\n",
      "Epoch 87/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6904 - acc: 0.5183 - val_loss: 0.6736 - val_acc: 0.6927\n",
      "Epoch 88/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6924 - acc: 0.5393 - val_loss: 0.6736 - val_acc: 0.6927\n",
      "Epoch 89/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6917 - acc: 0.5449 - val_loss: 0.6736 - val_acc: 0.6927\n",
      "Epoch 90/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6866 - acc: 0.5421 - val_loss: 0.6736 - val_acc: 0.6927\n",
      "Epoch 91/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6920 - acc: 0.5197 - val_loss: 0.6736 - val_acc: 0.6927\n",
      "Epoch 92/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6855 - acc: 0.5646 - val_loss: 0.6735 - val_acc: 0.6927\n",
      "Epoch 93/1000\n",
      "712/712 [==============================] - 0s 158us/step - loss: 0.6876 - acc: 0.5323 - val_loss: 0.6735 - val_acc: 0.6927\n",
      "Epoch 94/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6930 - acc: 0.5295 - val_loss: 0.6735 - val_acc: 0.6927\n",
      "Epoch 95/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6850 - acc: 0.5716 - val_loss: 0.6735 - val_acc: 0.6927\n",
      "Epoch 96/1000\n",
      "712/712 [==============================] - 0s 177us/step - loss: 0.6876 - acc: 0.5337 - val_loss: 0.6735 - val_acc: 0.6927\n",
      "Epoch 97/1000\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.6836 - acc: 0.5534 - val_loss: 0.6734 - val_acc: 0.6927\n",
      "Epoch 98/1000\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.6916 - acc: 0.5281 - val_loss: 0.6734 - val_acc: 0.6927\n",
      "Epoch 99/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6875 - acc: 0.5688 - val_loss: 0.6734 - val_acc: 0.6927\n",
      "Epoch 100/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6870 - acc: 0.5337 - val_loss: 0.6734 - val_acc: 0.6927\n",
      "Epoch 101/1000\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.6850 - acc: 0.5520 - val_loss: 0.6734 - val_acc: 0.6927\n",
      "Epoch 102/1000\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.6905 - acc: 0.5239 - val_loss: 0.6734 - val_acc: 0.6927\n",
      "Epoch 103/1000\n",
      "712/712 [==============================] - 0s 183us/step - loss: 0.6873 - acc: 0.5492 - val_loss: 0.6733 - val_acc: 0.6927\n",
      "Epoch 104/1000\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.6895 - acc: 0.5337 - val_loss: 0.6733 - val_acc: 0.6927\n",
      "Epoch 105/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6931 - acc: 0.5478 - val_loss: 0.6733 - val_acc: 0.6927\n",
      "Epoch 106/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6933 - acc: 0.5197 - val_loss: 0.6733 - val_acc: 0.6927\n",
      "Epoch 107/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6932 - acc: 0.5225 - val_loss: 0.6733 - val_acc: 0.6927\n",
      "Epoch 108/1000\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.6934 - acc: 0.5407 - val_loss: 0.6732 - val_acc: 0.6927\n",
      "Epoch 109/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6927 - acc: 0.5365 - val_loss: 0.6732 - val_acc: 0.6927\n",
      "Epoch 110/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6929 - acc: 0.5042 - val_loss: 0.6732 - val_acc: 0.6927\n",
      "Epoch 111/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6884 - acc: 0.5337 - val_loss: 0.6732 - val_acc: 0.6927\n",
      "Epoch 112/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6908 - acc: 0.5520 - val_loss: 0.6732 - val_acc: 0.6927\n",
      "Epoch 113/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6932 - acc: 0.5309 - val_loss: 0.6732 - val_acc: 0.6927\n",
      "Epoch 114/1000\n",
      "712/712 [==============================] - 0s 158us/step - loss: 0.6857 - acc: 0.5449 - val_loss: 0.6731 - val_acc: 0.6927\n",
      "Epoch 115/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6894 - acc: 0.5323 - val_loss: 0.6731 - val_acc: 0.6927\n",
      "Epoch 116/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6892 - acc: 0.5281 - val_loss: 0.6731 - val_acc: 0.6927\n",
      "Epoch 117/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6890 - acc: 0.5351 - val_loss: 0.6731 - val_acc: 0.6927\n",
      "Epoch 118/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6887 - acc: 0.5169 - val_loss: 0.6731 - val_acc: 0.6927\n",
      "Epoch 119/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6982 - acc: 0.4860 - val_loss: 0.6731 - val_acc: 0.6927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6967 - acc: 0.5154 - val_loss: 0.6730 - val_acc: 0.6927\n",
      "Epoch 121/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6897 - acc: 0.5351 - val_loss: 0.6730 - val_acc: 0.6927\n",
      "Epoch 122/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6908 - acc: 0.5407 - val_loss: 0.6730 - val_acc: 0.6927\n",
      "Epoch 123/1000\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.6868 - acc: 0.5548 - val_loss: 0.6730 - val_acc: 0.6927\n",
      "Epoch 124/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6871 - acc: 0.5323 - val_loss: 0.6730 - val_acc: 0.6927\n",
      "Epoch 125/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6915 - acc: 0.5421 - val_loss: 0.6729 - val_acc: 0.6927\n",
      "Epoch 126/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6932 - acc: 0.5379 - val_loss: 0.6729 - val_acc: 0.6927\n",
      "Epoch 127/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6850 - acc: 0.5449 - val_loss: 0.6729 - val_acc: 0.6927\n",
      "Epoch 128/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6891 - acc: 0.5463 - val_loss: 0.6729 - val_acc: 0.6927\n",
      "Epoch 129/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6837 - acc: 0.5590 - val_loss: 0.6729 - val_acc: 0.6927\n",
      "Epoch 130/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6929 - acc: 0.5267 - val_loss: 0.6729 - val_acc: 0.6927\n",
      "Epoch 131/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6946 - acc: 0.5393 - val_loss: 0.6728 - val_acc: 0.6927\n",
      "Epoch 132/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6911 - acc: 0.5084 - val_loss: 0.6728 - val_acc: 0.6927\n",
      "Epoch 133/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6917 - acc: 0.5281 - val_loss: 0.6728 - val_acc: 0.6927\n",
      "Epoch 134/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6849 - acc: 0.5506 - val_loss: 0.6728 - val_acc: 0.6927\n",
      "Epoch 135/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6950 - acc: 0.5225 - val_loss: 0.6728 - val_acc: 0.6927\n",
      "Epoch 136/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6905 - acc: 0.5548 - val_loss: 0.6728 - val_acc: 0.6927\n",
      "Epoch 137/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6947 - acc: 0.5183 - val_loss: 0.6727 - val_acc: 0.6927\n",
      "Epoch 138/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6867 - acc: 0.5421 - val_loss: 0.6727 - val_acc: 0.6927\n",
      "Epoch 139/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6916 - acc: 0.4972 - val_loss: 0.6727 - val_acc: 0.6927\n",
      "Epoch 140/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6914 - acc: 0.5407 - val_loss: 0.6727 - val_acc: 0.6927\n",
      "Epoch 141/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6929 - acc: 0.5365 - val_loss: 0.6727 - val_acc: 0.6927\n",
      "Epoch 142/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6852 - acc: 0.5463 - val_loss: 0.6727 - val_acc: 0.6927\n",
      "Epoch 143/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6957 - acc: 0.5295 - val_loss: 0.6726 - val_acc: 0.6927\n",
      "Epoch 144/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6954 - acc: 0.5140 - val_loss: 0.6726 - val_acc: 0.6927\n",
      "Epoch 145/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6861 - acc: 0.5449 - val_loss: 0.6726 - val_acc: 0.6927\n",
      "Epoch 146/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6838 - acc: 0.5379 - val_loss: 0.6726 - val_acc: 0.6927\n",
      "Epoch 147/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6938 - acc: 0.5183 - val_loss: 0.6726 - val_acc: 0.6927\n",
      "Epoch 148/1000\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.6848 - acc: 0.5449 - val_loss: 0.6725 - val_acc: 0.6927\n",
      "Epoch 149/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6970 - acc: 0.5028 - val_loss: 0.6725 - val_acc: 0.6927\n",
      "Epoch 150/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6938 - acc: 0.5267 - val_loss: 0.6725 - val_acc: 0.6927\n",
      "Epoch 151/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6861 - acc: 0.5492 - val_loss: 0.6725 - val_acc: 0.6927\n",
      "Epoch 152/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6879 - acc: 0.5492 - val_loss: 0.6725 - val_acc: 0.6927\n",
      "Epoch 153/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6850 - acc: 0.5604 - val_loss: 0.6725 - val_acc: 0.6927\n",
      "Epoch 154/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6856 - acc: 0.5520 - val_loss: 0.6724 - val_acc: 0.6927\n",
      "Epoch 155/1000\n",
      "712/712 [==============================] - 0s 170us/step - loss: 0.6926 - acc: 0.5183 - val_loss: 0.6724 - val_acc: 0.6927\n",
      "Epoch 156/1000\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.6796 - acc: 0.5871 - val_loss: 0.6724 - val_acc: 0.6927\n",
      "Epoch 157/1000\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.6904 - acc: 0.5225 - val_loss: 0.6724 - val_acc: 0.6927\n",
      "Epoch 158/1000\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.6824 - acc: 0.5688 - val_loss: 0.6724 - val_acc: 0.6927\n",
      "Epoch 159/1000\n",
      "712/712 [==============================] - 0s 164us/step - loss: 0.6854 - acc: 0.5506 - val_loss: 0.6724 - val_acc: 0.6927\n",
      "Epoch 160/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6903 - acc: 0.5379 - val_loss: 0.6723 - val_acc: 0.6927\n",
      "Epoch 161/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6887 - acc: 0.5534 - val_loss: 0.6723 - val_acc: 0.6927\n",
      "Epoch 162/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6875 - acc: 0.5337 - val_loss: 0.6723 - val_acc: 0.6927\n",
      "Epoch 163/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6921 - acc: 0.5169 - val_loss: 0.6723 - val_acc: 0.6927\n",
      "Epoch 164/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6891 - acc: 0.5449 - val_loss: 0.6723 - val_acc: 0.6927\n",
      "Epoch 165/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6974 - acc: 0.5309 - val_loss: 0.6723 - val_acc: 0.6927\n",
      "Epoch 166/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6965 - acc: 0.4972 - val_loss: 0.6722 - val_acc: 0.6927\n",
      "Epoch 167/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6873 - acc: 0.5435 - val_loss: 0.6722 - val_acc: 0.6927\n",
      "Epoch 168/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6842 - acc: 0.5632 - val_loss: 0.6722 - val_acc: 0.6927\n",
      "Epoch 169/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6885 - acc: 0.5520 - val_loss: 0.6722 - val_acc: 0.6927\n",
      "Epoch 170/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6864 - acc: 0.5183 - val_loss: 0.6722 - val_acc: 0.6927\n",
      "Epoch 171/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6878 - acc: 0.5295 - val_loss: 0.6721 - val_acc: 0.6927\n",
      "Epoch 172/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6891 - acc: 0.5562 - val_loss: 0.6721 - val_acc: 0.6927\n",
      "Epoch 173/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6967 - acc: 0.5084 - val_loss: 0.6721 - val_acc: 0.6927\n",
      "Epoch 174/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6867 - acc: 0.5548 - val_loss: 0.6721 - val_acc: 0.6927\n",
      "Epoch 175/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6897 - acc: 0.5183 - val_loss: 0.6721 - val_acc: 0.6927\n",
      "Epoch 176/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6919 - acc: 0.5379 - val_loss: 0.6721 - val_acc: 0.6927\n",
      "Epoch 177/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6895 - acc: 0.5492 - val_loss: 0.6720 - val_acc: 0.6927\n",
      "Epoch 178/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6897 - acc: 0.5281 - val_loss: 0.6720 - val_acc: 0.6927\n",
      "Epoch 179/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6928 - acc: 0.5449 - val_loss: 0.6720 - val_acc: 0.6927\n",
      "Epoch 180/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6908 - acc: 0.5154 - val_loss: 0.6720 - val_acc: 0.6927\n",
      "Epoch 181/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6865 - acc: 0.5365 - val_loss: 0.6720 - val_acc: 0.6927\n",
      "Epoch 182/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6858 - acc: 0.5646 - val_loss: 0.6720 - val_acc: 0.6927\n",
      "Epoch 183/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6829 - acc: 0.5393 - val_loss: 0.6719 - val_acc: 0.6927\n",
      "Epoch 184/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6905 - acc: 0.5267 - val_loss: 0.6719 - val_acc: 0.6927\n",
      "Epoch 185/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6888 - acc: 0.5393 - val_loss: 0.6719 - val_acc: 0.6927\n",
      "Epoch 186/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6879 - acc: 0.5267 - val_loss: 0.6719 - val_acc: 0.6927\n",
      "Epoch 187/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6828 - acc: 0.5365 - val_loss: 0.6719 - val_acc: 0.6927\n",
      "Epoch 188/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6887 - acc: 0.5183 - val_loss: 0.6718 - val_acc: 0.6927\n",
      "Epoch 189/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6912 - acc: 0.5463 - val_loss: 0.6718 - val_acc: 0.6927\n",
      "Epoch 190/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6898 - acc: 0.5281 - val_loss: 0.6718 - val_acc: 0.6927\n",
      "Epoch 191/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6886 - acc: 0.5478 - val_loss: 0.6718 - val_acc: 0.6927\n",
      "Epoch 192/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6943 - acc: 0.5154 - val_loss: 0.6718 - val_acc: 0.6927\n",
      "Epoch 193/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6871 - acc: 0.5253 - val_loss: 0.6718 - val_acc: 0.6927\n",
      "Epoch 194/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6849 - acc: 0.5407 - val_loss: 0.6717 - val_acc: 0.6927\n",
      "Epoch 195/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6873 - acc: 0.5351 - val_loss: 0.6717 - val_acc: 0.6927\n",
      "Epoch 196/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6909 - acc: 0.5169 - val_loss: 0.6717 - val_acc: 0.6927\n",
      "Epoch 197/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6897 - acc: 0.5140 - val_loss: 0.6717 - val_acc: 0.6927\n",
      "Epoch 198/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6886 - acc: 0.5281 - val_loss: 0.6717 - val_acc: 0.6927\n",
      "Epoch 199/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6918 - acc: 0.5309 - val_loss: 0.6717 - val_acc: 0.6927\n",
      "Epoch 200/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6836 - acc: 0.5562 - val_loss: 0.6716 - val_acc: 0.6927\n",
      "Epoch 201/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6956 - acc: 0.5183 - val_loss: 0.6716 - val_acc: 0.6927\n",
      "Epoch 202/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6898 - acc: 0.5211 - val_loss: 0.6716 - val_acc: 0.6927\n",
      "Epoch 203/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6828 - acc: 0.5744 - val_loss: 0.6716 - val_acc: 0.6927\n",
      "Epoch 204/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6870 - acc: 0.5042 - val_loss: 0.6716 - val_acc: 0.6927\n",
      "Epoch 205/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6884 - acc: 0.5562 - val_loss: 0.6716 - val_acc: 0.6927\n",
      "Epoch 206/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6847 - acc: 0.5632 - val_loss: 0.6715 - val_acc: 0.6927\n",
      "Epoch 207/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6891 - acc: 0.5407 - val_loss: 0.6715 - val_acc: 0.6927\n",
      "Epoch 208/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6890 - acc: 0.5267 - val_loss: 0.6715 - val_acc: 0.6927\n",
      "Epoch 209/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6798 - acc: 0.5674 - val_loss: 0.6715 - val_acc: 0.6927\n",
      "Epoch 210/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6896 - acc: 0.5421 - val_loss: 0.6715 - val_acc: 0.6927\n",
      "Epoch 211/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6862 - acc: 0.5463 - val_loss: 0.6715 - val_acc: 0.6927\n",
      "Epoch 212/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6793 - acc: 0.5632 - val_loss: 0.6714 - val_acc: 0.6927\n",
      "Epoch 213/1000\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6861 - acc: 0.5548 - val_loss: 0.6714 - val_acc: 0.6983\n",
      "Epoch 214/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6902 - acc: 0.5365 - val_loss: 0.6714 - val_acc: 0.6983\n",
      "Epoch 215/1000\n",
      "712/712 [==============================] - 0s 163us/step - loss: 0.6816 - acc: 0.5520 - val_loss: 0.6714 - val_acc: 0.6983\n",
      "Epoch 216/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6965 - acc: 0.5098 - val_loss: 0.6714 - val_acc: 0.6983\n",
      "Epoch 217/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6911 - acc: 0.5211 - val_loss: 0.6714 - val_acc: 0.6983\n",
      "Epoch 218/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6845 - acc: 0.5435 - val_loss: 0.6713 - val_acc: 0.6983\n",
      "Epoch 219/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6946 - acc: 0.5098 - val_loss: 0.6713 - val_acc: 0.6983\n",
      "Epoch 220/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6848 - acc: 0.5253 - val_loss: 0.6713 - val_acc: 0.6983\n",
      "Epoch 221/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6899 - acc: 0.5197 - val_loss: 0.6713 - val_acc: 0.6983\n",
      "Epoch 222/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6855 - acc: 0.5365 - val_loss: 0.6713 - val_acc: 0.6983\n",
      "Epoch 223/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6884 - acc: 0.5562 - val_loss: 0.6713 - val_acc: 0.6983\n",
      "Epoch 224/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6907 - acc: 0.5548 - val_loss: 0.6712 - val_acc: 0.6983\n",
      "Epoch 225/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6893 - acc: 0.5239 - val_loss: 0.6712 - val_acc: 0.6983\n",
      "Epoch 226/1000\n",
      "712/712 [==============================] - 0s 158us/step - loss: 0.6934 - acc: 0.5154 - val_loss: 0.6712 - val_acc: 0.6983\n",
      "Epoch 227/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6867 - acc: 0.5337 - val_loss: 0.6712 - val_acc: 0.6983\n",
      "Epoch 228/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6904 - acc: 0.5239 - val_loss: 0.6712 - val_acc: 0.6983\n",
      "Epoch 229/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6951 - acc: 0.5028 - val_loss: 0.6712 - val_acc: 0.6983\n",
      "Epoch 230/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6859 - acc: 0.5351 - val_loss: 0.6711 - val_acc: 0.6983\n",
      "Epoch 231/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6905 - acc: 0.5126 - val_loss: 0.6711 - val_acc: 0.6983\n",
      "Epoch 232/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6887 - acc: 0.5112 - val_loss: 0.6711 - val_acc: 0.6983\n",
      "Epoch 233/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6795 - acc: 0.5843 - val_loss: 0.6711 - val_acc: 0.6983\n",
      "Epoch 234/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6899 - acc: 0.5323 - val_loss: 0.6711 - val_acc: 0.6983\n",
      "Epoch 235/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6852 - acc: 0.5421 - val_loss: 0.6711 - val_acc: 0.6983\n",
      "Epoch 236/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6821 - acc: 0.5618 - val_loss: 0.6710 - val_acc: 0.6983\n",
      "Epoch 237/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6856 - acc: 0.5407 - val_loss: 0.6710 - val_acc: 0.6983\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 138us/step - loss: 0.6839 - acc: 0.5435 - val_loss: 0.6710 - val_acc: 0.6983\n",
      "Epoch 239/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6899 - acc: 0.5421 - val_loss: 0.6710 - val_acc: 0.6983\n",
      "Epoch 240/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6904 - acc: 0.5604 - val_loss: 0.6710 - val_acc: 0.6983\n",
      "Epoch 241/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6839 - acc: 0.5744 - val_loss: 0.6710 - val_acc: 0.6983\n",
      "Epoch 242/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6950 - acc: 0.5183 - val_loss: 0.6709 - val_acc: 0.6983\n",
      "Epoch 243/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6897 - acc: 0.5309 - val_loss: 0.6709 - val_acc: 0.6983\n",
      "Epoch 244/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6763 - acc: 0.5702 - val_loss: 0.6709 - val_acc: 0.6983\n",
      "Epoch 245/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6813 - acc: 0.5674 - val_loss: 0.6709 - val_acc: 0.6983\n",
      "Epoch 246/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6751 - acc: 0.5913 - val_loss: 0.6709 - val_acc: 0.6983\n",
      "Epoch 247/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6895 - acc: 0.5225 - val_loss: 0.6708 - val_acc: 0.6983\n",
      "Epoch 248/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6849 - acc: 0.5449 - val_loss: 0.6708 - val_acc: 0.6983\n",
      "Epoch 249/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6923 - acc: 0.5421 - val_loss: 0.6708 - val_acc: 0.6983\n",
      "Epoch 250/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6949 - acc: 0.5014 - val_loss: 0.6708 - val_acc: 0.6983\n",
      "Epoch 251/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6861 - acc: 0.5323 - val_loss: 0.6708 - val_acc: 0.6983\n",
      "Epoch 252/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6866 - acc: 0.5407 - val_loss: 0.6708 - val_acc: 0.6983\n",
      "Epoch 253/1000\n",
      "712/712 [==============================] - 0s 90us/step - loss: 0.6808 - acc: 0.5646 - val_loss: 0.6707 - val_acc: 0.6983\n",
      "Epoch 254/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6847 - acc: 0.5506 - val_loss: 0.6707 - val_acc: 0.6983\n",
      "Epoch 255/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.6947 - acc: 0.5183 - val_loss: 0.6707 - val_acc: 0.6983\n",
      "Epoch 256/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6868 - acc: 0.5449 - val_loss: 0.6707 - val_acc: 0.6983\n",
      "Epoch 257/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6839 - acc: 0.5632 - val_loss: 0.6707 - val_acc: 0.6983\n",
      "Epoch 258/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6804 - acc: 0.5478 - val_loss: 0.6707 - val_acc: 0.6983\n",
      "Epoch 259/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6867 - acc: 0.5604 - val_loss: 0.6706 - val_acc: 0.6983\n",
      "Epoch 260/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6914 - acc: 0.5337 - val_loss: 0.6706 - val_acc: 0.6983\n",
      "Epoch 261/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6883 - acc: 0.5253 - val_loss: 0.6706 - val_acc: 0.6983\n",
      "Epoch 262/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6802 - acc: 0.5787 - val_loss: 0.6706 - val_acc: 0.6983\n",
      "Epoch 263/1000\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.6936 - acc: 0.5183 - val_loss: 0.6706 - val_acc: 0.6983\n",
      "Epoch 264/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6779 - acc: 0.5646 - val_loss: 0.6706 - val_acc: 0.6704\n",
      "Epoch 265/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6845 - acc: 0.5393 - val_loss: 0.6705 - val_acc: 0.6704\n",
      "Epoch 266/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6898 - acc: 0.5154 - val_loss: 0.6705 - val_acc: 0.6704\n",
      "Epoch 267/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6899 - acc: 0.5323 - val_loss: 0.6705 - val_acc: 0.6704\n",
      "Epoch 268/1000\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.6868 - acc: 0.5407 - val_loss: 0.6705 - val_acc: 0.6704\n",
      "Epoch 269/1000\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.6911 - acc: 0.5197 - val_loss: 0.6705 - val_acc: 0.6704\n",
      "Epoch 270/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6960 - acc: 0.4986 - val_loss: 0.6705 - val_acc: 0.6704\n",
      "Epoch 271/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6875 - acc: 0.5379 - val_loss: 0.6704 - val_acc: 0.6704\n",
      "Epoch 272/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6906 - acc: 0.5253 - val_loss: 0.6704 - val_acc: 0.6704\n",
      "Epoch 273/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6819 - acc: 0.5730 - val_loss: 0.6704 - val_acc: 0.6704\n",
      "Epoch 274/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6916 - acc: 0.5323 - val_loss: 0.6704 - val_acc: 0.6704\n",
      "Epoch 275/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6843 - acc: 0.5520 - val_loss: 0.6704 - val_acc: 0.6704\n",
      "Epoch 276/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6878 - acc: 0.5365 - val_loss: 0.6704 - val_acc: 0.6704\n",
      "Epoch 277/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6904 - acc: 0.5253 - val_loss: 0.6703 - val_acc: 0.6704\n",
      "Epoch 278/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6937 - acc: 0.5169 - val_loss: 0.6703 - val_acc: 0.6704\n",
      "Epoch 279/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6812 - acc: 0.5843 - val_loss: 0.6703 - val_acc: 0.6704\n",
      "Epoch 280/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6955 - acc: 0.5239 - val_loss: 0.6703 - val_acc: 0.6704\n",
      "Epoch 281/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6906 - acc: 0.5154 - val_loss: 0.6703 - val_acc: 0.6704\n",
      "Epoch 282/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6821 - acc: 0.5590 - val_loss: 0.6703 - val_acc: 0.6704\n",
      "Epoch 283/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6879 - acc: 0.5323 - val_loss: 0.6702 - val_acc: 0.6704\n",
      "Epoch 284/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6943 - acc: 0.5281 - val_loss: 0.6702 - val_acc: 0.6704\n",
      "Epoch 285/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6836 - acc: 0.5534 - val_loss: 0.6702 - val_acc: 0.6704\n",
      "Epoch 286/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6862 - acc: 0.5660 - val_loss: 0.6702 - val_acc: 0.6704\n",
      "Epoch 287/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6856 - acc: 0.5379 - val_loss: 0.6702 - val_acc: 0.6704\n",
      "Epoch 288/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6863 - acc: 0.5576 - val_loss: 0.6702 - val_acc: 0.6704\n",
      "Epoch 289/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6879 - acc: 0.5393 - val_loss: 0.6701 - val_acc: 0.6704\n",
      "Epoch 290/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6869 - acc: 0.5674 - val_loss: 0.6701 - val_acc: 0.6704\n",
      "Epoch 291/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6997 - acc: 0.4944 - val_loss: 0.6701 - val_acc: 0.6704\n",
      "Epoch 292/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6906 - acc: 0.5197 - val_loss: 0.6701 - val_acc: 0.6704\n",
      "Epoch 293/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6851 - acc: 0.5393 - val_loss: 0.6701 - val_acc: 0.6704\n",
      "Epoch 294/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6835 - acc: 0.5449 - val_loss: 0.6700 - val_acc: 0.6704\n",
      "Epoch 295/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6865 - acc: 0.5478 - val_loss: 0.6700 - val_acc: 0.6704\n",
      "Epoch 296/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6831 - acc: 0.5379 - val_loss: 0.6700 - val_acc: 0.6704\n",
      "Epoch 297/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6913 - acc: 0.5140 - val_loss: 0.6700 - val_acc: 0.6704\n",
      "Epoch 298/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6839 - acc: 0.5772 - val_loss: 0.6700 - val_acc: 0.6704\n",
      "Epoch 299/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6818 - acc: 0.5590 - val_loss: 0.6700 - val_acc: 0.6704\n",
      "Epoch 300/1000\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.6878 - acc: 0.5295 - val_loss: 0.6699 - val_acc: 0.6704\n",
      "Epoch 301/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6926 - acc: 0.5140 - val_loss: 0.6699 - val_acc: 0.6704\n",
      "Epoch 302/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6891 - acc: 0.5183 - val_loss: 0.6699 - val_acc: 0.6704\n",
      "Epoch 303/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6868 - acc: 0.5351 - val_loss: 0.6699 - val_acc: 0.6704\n",
      "Epoch 304/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6887 - acc: 0.5323 - val_loss: 0.6699 - val_acc: 0.6704\n",
      "Epoch 305/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6894 - acc: 0.5197 - val_loss: 0.6699 - val_acc: 0.6704\n",
      "Epoch 306/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6929 - acc: 0.5154 - val_loss: 0.6698 - val_acc: 0.6704\n",
      "Epoch 307/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6879 - acc: 0.5478 - val_loss: 0.6698 - val_acc: 0.6704\n",
      "Epoch 308/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6948 - acc: 0.5028 - val_loss: 0.6698 - val_acc: 0.6704\n",
      "Epoch 309/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6936 - acc: 0.5225 - val_loss: 0.6698 - val_acc: 0.6704\n",
      "Epoch 310/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6872 - acc: 0.5478 - val_loss: 0.6698 - val_acc: 0.6704\n",
      "Epoch 311/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6879 - acc: 0.5183 - val_loss: 0.6698 - val_acc: 0.6704\n",
      "Epoch 312/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6909 - acc: 0.5197 - val_loss: 0.6697 - val_acc: 0.6704\n",
      "Epoch 313/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6822 - acc: 0.5716 - val_loss: 0.6697 - val_acc: 0.6704\n",
      "Epoch 314/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6881 - acc: 0.5435 - val_loss: 0.6697 - val_acc: 0.6704\n",
      "Epoch 315/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6890 - acc: 0.5281 - val_loss: 0.6697 - val_acc: 0.6704\n",
      "Epoch 316/1000\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.6919 - acc: 0.5309 - val_loss: 0.6697 - val_acc: 0.6704\n",
      "Epoch 317/1000\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.6833 - acc: 0.5590 - val_loss: 0.6697 - val_acc: 0.6704\n",
      "Epoch 318/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6925 - acc: 0.5337 - val_loss: 0.6696 - val_acc: 0.6704\n",
      "Epoch 319/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6783 - acc: 0.5604 - val_loss: 0.6696 - val_acc: 0.6704\n",
      "Epoch 320/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6758 - acc: 0.6025 - val_loss: 0.6696 - val_acc: 0.6704\n",
      "Epoch 321/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6925 - acc: 0.5379 - val_loss: 0.6696 - val_acc: 0.6704\n",
      "Epoch 322/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6956 - acc: 0.5112 - val_loss: 0.6696 - val_acc: 0.6704\n",
      "Epoch 323/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.7000 - acc: 0.5070 - val_loss: 0.6696 - val_acc: 0.6704\n",
      "Epoch 324/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6747 - acc: 0.5969 - val_loss: 0.6695 - val_acc: 0.6704\n",
      "Epoch 325/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6890 - acc: 0.5351 - val_loss: 0.6695 - val_acc: 0.6704\n",
      "Epoch 326/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6957 - acc: 0.5281 - val_loss: 0.6695 - val_acc: 0.6704\n",
      "Epoch 327/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6854 - acc: 0.5463 - val_loss: 0.6695 - val_acc: 0.6704\n",
      "Epoch 328/1000\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6936 - acc: 0.5098 - val_loss: 0.6695 - val_acc: 0.6704\n",
      "Epoch 329/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6904 - acc: 0.5281 - val_loss: 0.6695 - val_acc: 0.6704\n",
      "Epoch 330/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6906 - acc: 0.5309 - val_loss: 0.6694 - val_acc: 0.6704\n",
      "Epoch 331/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6886 - acc: 0.5183 - val_loss: 0.6694 - val_acc: 0.6704\n",
      "Epoch 332/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6893 - acc: 0.5281 - val_loss: 0.6694 - val_acc: 0.6704\n",
      "Epoch 333/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6868 - acc: 0.5506 - val_loss: 0.6694 - val_acc: 0.6704\n",
      "Epoch 334/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6812 - acc: 0.5702 - val_loss: 0.6694 - val_acc: 0.6704\n",
      "Epoch 335/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6867 - acc: 0.5520 - val_loss: 0.6694 - val_acc: 0.6704\n",
      "Epoch 336/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6872 - acc: 0.5463 - val_loss: 0.6693 - val_acc: 0.6704\n",
      "Epoch 337/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6930 - acc: 0.5239 - val_loss: 0.6693 - val_acc: 0.6704\n",
      "Epoch 338/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6832 - acc: 0.5632 - val_loss: 0.6693 - val_acc: 0.6704\n",
      "Epoch 339/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6850 - acc: 0.5449 - val_loss: 0.6693 - val_acc: 0.6704\n",
      "Epoch 340/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6897 - acc: 0.5323 - val_loss: 0.6693 - val_acc: 0.6704\n",
      "Epoch 341/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6882 - acc: 0.5449 - val_loss: 0.6693 - val_acc: 0.6704\n",
      "Epoch 342/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6891 - acc: 0.5337 - val_loss: 0.6692 - val_acc: 0.6704\n",
      "Epoch 343/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6860 - acc: 0.5267 - val_loss: 0.6692 - val_acc: 0.6704\n",
      "Epoch 344/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6870 - acc: 0.5449 - val_loss: 0.6692 - val_acc: 0.6704\n",
      "Epoch 345/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6910 - acc: 0.5295 - val_loss: 0.6692 - val_acc: 0.6704\n",
      "Epoch 346/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6947 - acc: 0.5309 - val_loss: 0.6692 - val_acc: 0.6704\n",
      "Epoch 347/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6770 - acc: 0.5857 - val_loss: 0.6692 - val_acc: 0.6704\n",
      "Epoch 348/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6854 - acc: 0.5590 - val_loss: 0.6691 - val_acc: 0.6704\n",
      "Epoch 349/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6887 - acc: 0.5183 - val_loss: 0.6691 - val_acc: 0.6704\n",
      "Epoch 350/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6874 - acc: 0.5126 - val_loss: 0.6691 - val_acc: 0.6704\n",
      "Epoch 351/1000\n",
      "712/712 [==============================] - 0s 94us/step - loss: 0.6790 - acc: 0.5885 - val_loss: 0.6691 - val_acc: 0.6704\n",
      "Epoch 352/1000\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.6816 - acc: 0.5758 - val_loss: 0.6691 - val_acc: 0.6704\n",
      "Epoch 353/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.6896 - acc: 0.5351 - val_loss: 0.6691 - val_acc: 0.6704\n",
      "Epoch 354/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.6800 - acc: 0.5562 - val_loss: 0.6690 - val_acc: 0.6704\n",
      "Epoch 355/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.6837 - acc: 0.5281 - val_loss: 0.6690 - val_acc: 0.6704\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 109us/step - loss: 0.6889 - acc: 0.5478 - val_loss: 0.6690 - val_acc: 0.6704\n",
      "Epoch 357/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6941 - acc: 0.5112 - val_loss: 0.6690 - val_acc: 0.6704\n",
      "Epoch 358/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6838 - acc: 0.5646 - val_loss: 0.6690 - val_acc: 0.6704\n",
      "Epoch 359/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6912 - acc: 0.5112 - val_loss: 0.6690 - val_acc: 0.6704\n",
      "Epoch 360/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6926 - acc: 0.5351 - val_loss: 0.6689 - val_acc: 0.6704\n",
      "Epoch 361/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6870 - acc: 0.5463 - val_loss: 0.6689 - val_acc: 0.6704\n",
      "Epoch 362/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6884 - acc: 0.5295 - val_loss: 0.6689 - val_acc: 0.6704\n",
      "Epoch 363/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6920 - acc: 0.5140 - val_loss: 0.6689 - val_acc: 0.6704\n",
      "Epoch 364/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.6872 - acc: 0.5407 - val_loss: 0.6689 - val_acc: 0.6704\n",
      "Epoch 365/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.6856 - acc: 0.5520 - val_loss: 0.6688 - val_acc: 0.6704\n",
      "Epoch 366/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6881 - acc: 0.5239 - val_loss: 0.6688 - val_acc: 0.6704\n",
      "Epoch 367/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6895 - acc: 0.5393 - val_loss: 0.6688 - val_acc: 0.6704\n",
      "Epoch 368/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6813 - acc: 0.5604 - val_loss: 0.6688 - val_acc: 0.6704\n",
      "Epoch 369/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6897 - acc: 0.5225 - val_loss: 0.6688 - val_acc: 0.6704\n",
      "Epoch 370/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6838 - acc: 0.5688 - val_loss: 0.6688 - val_acc: 0.6704\n",
      "Epoch 371/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6918 - acc: 0.5421 - val_loss: 0.6688 - val_acc: 0.6704\n",
      "Epoch 372/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6878 - acc: 0.5365 - val_loss: 0.6687 - val_acc: 0.6704\n",
      "Epoch 373/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6896 - acc: 0.5295 - val_loss: 0.6687 - val_acc: 0.6704\n",
      "Epoch 374/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6872 - acc: 0.5267 - val_loss: 0.6687 - val_acc: 0.6704\n",
      "Epoch 375/1000\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.6905 - acc: 0.5225 - val_loss: 0.6687 - val_acc: 0.6704\n",
      "Epoch 376/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6903 - acc: 0.5351 - val_loss: 0.6687 - val_acc: 0.6592\n",
      "Epoch 377/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6876 - acc: 0.5281 - val_loss: 0.6687 - val_acc: 0.6592\n",
      "Epoch 378/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6866 - acc: 0.5379 - val_loss: 0.6686 - val_acc: 0.6592\n",
      "Epoch 379/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6832 - acc: 0.5407 - val_loss: 0.6686 - val_acc: 0.6592\n",
      "Epoch 380/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.6886 - acc: 0.5478 - val_loss: 0.6686 - val_acc: 0.6592\n",
      "Epoch 381/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6864 - acc: 0.5365 - val_loss: 0.6686 - val_acc: 0.6592\n",
      "Epoch 382/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.6797 - acc: 0.5492 - val_loss: 0.6686 - val_acc: 0.6592\n",
      "Epoch 383/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.6902 - acc: 0.5309 - val_loss: 0.6686 - val_acc: 0.6592\n",
      "Epoch 384/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6860 - acc: 0.5506 - val_loss: 0.6685 - val_acc: 0.6592\n",
      "Epoch 385/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.6900 - acc: 0.5351 - val_loss: 0.6685 - val_acc: 0.6592\n",
      "Epoch 386/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6879 - acc: 0.5351 - val_loss: 0.6685 - val_acc: 0.6592\n",
      "Epoch 387/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6854 - acc: 0.5744 - val_loss: 0.6685 - val_acc: 0.6592\n",
      "Epoch 388/1000\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.6848 - acc: 0.5674 - val_loss: 0.6685 - val_acc: 0.6592\n",
      "Epoch 389/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6878 - acc: 0.5506 - val_loss: 0.6685 - val_acc: 0.6592\n",
      "Epoch 390/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6850 - acc: 0.5435 - val_loss: 0.6684 - val_acc: 0.6592\n",
      "Epoch 391/1000\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.6793 - acc: 0.5899 - val_loss: 0.6684 - val_acc: 0.6592\n",
      "Epoch 392/1000\n",
      "712/712 [==============================] - 0s 163us/step - loss: 0.6870 - acc: 0.5309 - val_loss: 0.6684 - val_acc: 0.6592\n",
      "Epoch 393/1000\n",
      "712/712 [==============================] - 0s 171us/step - loss: 0.6882 - acc: 0.5337 - val_loss: 0.6684 - val_acc: 0.6592\n",
      "Epoch 394/1000\n",
      "712/712 [==============================] - 0s 169us/step - loss: 0.6784 - acc: 0.5857 - val_loss: 0.6684 - val_acc: 0.6592\n",
      "Epoch 395/1000\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.6825 - acc: 0.5688 - val_loss: 0.6684 - val_acc: 0.6592\n",
      "Epoch 396/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6868 - acc: 0.5323 - val_loss: 0.6683 - val_acc: 0.6592\n",
      "Epoch 397/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6909 - acc: 0.5534 - val_loss: 0.6683 - val_acc: 0.6592\n",
      "Epoch 398/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6944 - acc: 0.5211 - val_loss: 0.6683 - val_acc: 0.6592\n",
      "Epoch 399/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6864 - acc: 0.5492 - val_loss: 0.6683 - val_acc: 0.6592\n",
      "Epoch 400/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6909 - acc: 0.5225 - val_loss: 0.6683 - val_acc: 0.6592\n",
      "Epoch 401/1000\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6903 - acc: 0.5126 - val_loss: 0.6683 - val_acc: 0.6592\n",
      "Epoch 402/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6873 - acc: 0.5351 - val_loss: 0.6682 - val_acc: 0.6592\n",
      "Epoch 403/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6849 - acc: 0.5435 - val_loss: 0.6682 - val_acc: 0.6592\n",
      "Epoch 404/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6829 - acc: 0.5562 - val_loss: 0.6682 - val_acc: 0.6592\n",
      "Epoch 405/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.6858 - acc: 0.5323 - val_loss: 0.6682 - val_acc: 0.6592\n",
      "Epoch 406/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6839 - acc: 0.5365 - val_loss: 0.6682 - val_acc: 0.6592\n",
      "Epoch 407/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6916 - acc: 0.5323 - val_loss: 0.6682 - val_acc: 0.6592\n",
      "Epoch 408/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6886 - acc: 0.5295 - val_loss: 0.6681 - val_acc: 0.6592\n",
      "Epoch 409/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6934 - acc: 0.5140 - val_loss: 0.6681 - val_acc: 0.6592\n",
      "Epoch 410/1000\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.6865 - acc: 0.5435 - val_loss: 0.6681 - val_acc: 0.6592\n",
      "Epoch 411/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6830 - acc: 0.5758 - val_loss: 0.6681 - val_acc: 0.6592\n",
      "Epoch 412/1000\n",
      "712/712 [==============================] - 0s 176us/step - loss: 0.6882 - acc: 0.5506 - val_loss: 0.6681 - val_acc: 0.6592\n",
      "Epoch 413/1000\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6810 - acc: 0.5618 - val_loss: 0.6681 - val_acc: 0.6592\n",
      "Epoch 414/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6860 - acc: 0.5548 - val_loss: 0.6680 - val_acc: 0.6592\n",
      "Epoch 415/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6856 - acc: 0.5604 - val_loss: 0.6680 - val_acc: 0.6592\n",
      "Epoch 416/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6810 - acc: 0.5576 - val_loss: 0.6680 - val_acc: 0.6592\n",
      "Epoch 417/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6900 - acc: 0.5463 - val_loss: 0.6680 - val_acc: 0.6592\n",
      "Epoch 418/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.6885 - acc: 0.5267 - val_loss: 0.6680 - val_acc: 0.6592\n",
      "Epoch 419/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6847 - acc: 0.5744 - val_loss: 0.6680 - val_acc: 0.6592\n",
      "Epoch 420/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6876 - acc: 0.5562 - val_loss: 0.6679 - val_acc: 0.6592\n",
      "Epoch 421/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6821 - acc: 0.5660 - val_loss: 0.6679 - val_acc: 0.6592\n",
      "Epoch 422/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6890 - acc: 0.5183 - val_loss: 0.6679 - val_acc: 0.6592\n",
      "Epoch 423/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6856 - acc: 0.5548 - val_loss: 0.6679 - val_acc: 0.6592\n",
      "Epoch 424/1000\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.6934 - acc: 0.5211 - val_loss: 0.6679 - val_acc: 0.6592\n",
      "Epoch 425/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6841 - acc: 0.5604 - val_loss: 0.6679 - val_acc: 0.6592\n",
      "Epoch 426/1000\n",
      "712/712 [==============================] - ETA: 0s - loss: 0.6996 - acc: 0.502 - 0s 135us/step - loss: 0.6954 - acc: 0.5239 - val_loss: 0.6678 - val_acc: 0.6592\n",
      "Epoch 427/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.6847 - acc: 0.5337 - val_loss: 0.6678 - val_acc: 0.6592\n",
      "Epoch 428/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.6895 - acc: 0.5520 - val_loss: 0.6678 - val_acc: 0.6592\n",
      "Epoch 429/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.6920 - acc: 0.5478 - val_loss: 0.6678 - val_acc: 0.6592\n",
      "Epoch 430/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6807 - acc: 0.5520 - val_loss: 0.6678 - val_acc: 0.6592\n",
      "Epoch 431/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6900 - acc: 0.5239 - val_loss: 0.6678 - val_acc: 0.6592\n",
      "Epoch 432/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6883 - acc: 0.5309 - val_loss: 0.6677 - val_acc: 0.6592\n",
      "Epoch 433/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6857 - acc: 0.5506 - val_loss: 0.6677 - val_acc: 0.6592\n",
      "Epoch 434/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6930 - acc: 0.5098 - val_loss: 0.6677 - val_acc: 0.6592\n",
      "Epoch 435/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6870 - acc: 0.5351 - val_loss: 0.6677 - val_acc: 0.6592\n",
      "Epoch 436/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6833 - acc: 0.5688 - val_loss: 0.6677 - val_acc: 0.6592\n",
      "Epoch 437/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6932 - acc: 0.5225 - val_loss: 0.6677 - val_acc: 0.6592\n",
      "Epoch 438/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.6891 - acc: 0.5365 - val_loss: 0.6676 - val_acc: 0.6592\n",
      "Epoch 439/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6864 - acc: 0.5351 - val_loss: 0.6676 - val_acc: 0.6592\n",
      "Epoch 440/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6890 - acc: 0.5140 - val_loss: 0.6676 - val_acc: 0.6592\n",
      "Epoch 441/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6868 - acc: 0.5393 - val_loss: 0.6676 - val_acc: 0.6592\n",
      "Epoch 442/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.6820 - acc: 0.5520 - val_loss: 0.6676 - val_acc: 0.6592\n",
      "Epoch 443/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.6810 - acc: 0.5590 - val_loss: 0.6676 - val_acc: 0.6592\n",
      "Epoch 444/1000\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.6856 - acc: 0.5393 - val_loss: 0.6675 - val_acc: 0.6592\n",
      "Epoch 445/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6837 - acc: 0.5618 - val_loss: 0.6675 - val_acc: 0.6592\n",
      "Epoch 446/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.6901 - acc: 0.5449 - val_loss: 0.6675 - val_acc: 0.6592\n",
      "Epoch 447/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.6927 - acc: 0.5211 - val_loss: 0.6675 - val_acc: 0.6592\n",
      "Epoch 448/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.6824 - acc: 0.5435 - val_loss: 0.6675 - val_acc: 0.6592\n",
      "Epoch 449/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6750 - acc: 0.5829 - val_loss: 0.6675 - val_acc: 0.6592\n",
      "Epoch 450/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6865 - acc: 0.5534 - val_loss: 0.6675 - val_acc: 0.6592\n",
      "Epoch 451/1000\n",
      "712/712 [==============================] - 0s 158us/step - loss: 0.6866 - acc: 0.5421 - val_loss: 0.6674 - val_acc: 0.6592\n",
      "Epoch 452/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6794 - acc: 0.5815 - val_loss: 0.6674 - val_acc: 0.6592\n",
      "Epoch 453/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6832 - acc: 0.5463 - val_loss: 0.6674 - val_acc: 0.6592\n",
      "Epoch 454/1000\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.6781 - acc: 0.5787 - val_loss: 0.6674 - val_acc: 0.6592\n",
      "Epoch 455/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6806 - acc: 0.5365 - val_loss: 0.6674 - val_acc: 0.6592\n",
      "Epoch 456/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6813 - acc: 0.5801 - val_loss: 0.6674 - val_acc: 0.6592\n",
      "Epoch 457/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6766 - acc: 0.5801 - val_loss: 0.6673 - val_acc: 0.6592\n",
      "Epoch 458/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6839 - acc: 0.5646 - val_loss: 0.6673 - val_acc: 0.6592\n",
      "Epoch 459/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6890 - acc: 0.5323 - val_loss: 0.6673 - val_acc: 0.6592\n",
      "Epoch 460/1000\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6910 - acc: 0.5169 - val_loss: 0.6673 - val_acc: 0.6592\n",
      "Epoch 461/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6906 - acc: 0.5323 - val_loss: 0.6673 - val_acc: 0.6592\n",
      "Epoch 462/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6862 - acc: 0.5492 - val_loss: 0.6673 - val_acc: 0.6592\n",
      "Epoch 463/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6825 - acc: 0.5548 - val_loss: 0.6672 - val_acc: 0.6592\n",
      "Epoch 464/1000\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.6908 - acc: 0.5449 - val_loss: 0.6672 - val_acc: 0.6592\n",
      "Epoch 465/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6910 - acc: 0.5295 - val_loss: 0.6672 - val_acc: 0.6592\n",
      "Epoch 466/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6915 - acc: 0.5239 - val_loss: 0.6672 - val_acc: 0.6592\n",
      "Epoch 467/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6808 - acc: 0.5548 - val_loss: 0.6672 - val_acc: 0.6592\n",
      "Epoch 468/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6871 - acc: 0.5492 - val_loss: 0.6672 - val_acc: 0.6592\n",
      "Epoch 469/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6828 - acc: 0.5576 - val_loss: 0.6671 - val_acc: 0.6592\n",
      "Epoch 470/1000\n",
      "712/712 [==============================] - 0s 164us/step - loss: 0.6817 - acc: 0.5393 - val_loss: 0.6671 - val_acc: 0.6592\n",
      "Epoch 471/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6845 - acc: 0.5646 - val_loss: 0.6671 - val_acc: 0.6592\n",
      "Epoch 472/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6827 - acc: 0.5829 - val_loss: 0.6671 - val_acc: 0.6592\n",
      "Epoch 473/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6809 - acc: 0.5492 - val_loss: 0.6671 - val_acc: 0.6592\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 128us/step - loss: 0.6874 - acc: 0.5463 - val_loss: 0.6671 - val_acc: 0.6592\n",
      "Epoch 475/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6838 - acc: 0.5534 - val_loss: 0.6670 - val_acc: 0.6592\n",
      "Epoch 476/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6828 - acc: 0.5478 - val_loss: 0.6670 - val_acc: 0.6592\n",
      "Epoch 477/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6805 - acc: 0.5646 - val_loss: 0.6670 - val_acc: 0.6592\n",
      "Epoch 478/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6914 - acc: 0.5225 - val_loss: 0.6670 - val_acc: 0.6592\n",
      "Epoch 479/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6775 - acc: 0.5955 - val_loss: 0.6670 - val_acc: 0.6592\n",
      "Epoch 480/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6898 - acc: 0.5435 - val_loss: 0.6670 - val_acc: 0.6592\n",
      "Epoch 481/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6866 - acc: 0.5506 - val_loss: 0.6670 - val_acc: 0.6592\n",
      "Epoch 482/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6807 - acc: 0.5604 - val_loss: 0.6669 - val_acc: 0.6592\n",
      "Epoch 483/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6815 - acc: 0.5590 - val_loss: 0.6669 - val_acc: 0.6592\n",
      "Epoch 484/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6869 - acc: 0.5351 - val_loss: 0.6669 - val_acc: 0.6592\n",
      "Epoch 485/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6842 - acc: 0.5674 - val_loss: 0.6669 - val_acc: 0.6592\n",
      "Epoch 486/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6799 - acc: 0.5632 - val_loss: 0.6669 - val_acc: 0.6592\n",
      "Epoch 487/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6809 - acc: 0.5435 - val_loss: 0.6669 - val_acc: 0.6592\n",
      "Epoch 488/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6923 - acc: 0.5337 - val_loss: 0.6668 - val_acc: 0.6592\n",
      "Epoch 489/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6888 - acc: 0.5337 - val_loss: 0.6668 - val_acc: 0.6592\n",
      "Epoch 490/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6810 - acc: 0.5688 - val_loss: 0.6668 - val_acc: 0.6592\n",
      "Epoch 491/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6785 - acc: 0.5815 - val_loss: 0.6668 - val_acc: 0.6592\n",
      "Epoch 492/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6879 - acc: 0.5351 - val_loss: 0.6668 - val_acc: 0.6592\n",
      "Epoch 493/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6817 - acc: 0.5660 - val_loss: 0.6668 - val_acc: 0.6592\n",
      "Epoch 494/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6828 - acc: 0.5449 - val_loss: 0.6667 - val_acc: 0.6592\n",
      "Epoch 495/1000\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.6853 - acc: 0.5646 - val_loss: 0.6667 - val_acc: 0.6592\n",
      "Epoch 496/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6837 - acc: 0.5562 - val_loss: 0.6667 - val_acc: 0.6592\n",
      "Epoch 497/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6871 - acc: 0.5323 - val_loss: 0.6667 - val_acc: 0.6592\n",
      "Epoch 498/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6821 - acc: 0.5787 - val_loss: 0.6667 - val_acc: 0.6592\n",
      "Epoch 499/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6910 - acc: 0.4944 - val_loss: 0.6667 - val_acc: 0.6592\n",
      "Epoch 500/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6920 - acc: 0.5140 - val_loss: 0.6666 - val_acc: 0.6592\n",
      "Epoch 501/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6879 - acc: 0.5407 - val_loss: 0.6666 - val_acc: 0.6592\n",
      "Epoch 502/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6890 - acc: 0.5253 - val_loss: 0.6666 - val_acc: 0.6592\n",
      "Epoch 503/1000\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6860 - acc: 0.5506 - val_loss: 0.6666 - val_acc: 0.6592\n",
      "Epoch 504/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6808 - acc: 0.5365 - val_loss: 0.6666 - val_acc: 0.6592\n",
      "Epoch 505/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6865 - acc: 0.5463 - val_loss: 0.6666 - val_acc: 0.6592\n",
      "Epoch 506/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6882 - acc: 0.5478 - val_loss: 0.6666 - val_acc: 0.6592\n",
      "Epoch 507/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6871 - acc: 0.5351 - val_loss: 0.6665 - val_acc: 0.6592\n",
      "Epoch 508/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6863 - acc: 0.5548 - val_loss: 0.6665 - val_acc: 0.6592\n",
      "Epoch 509/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6823 - acc: 0.5927 - val_loss: 0.6665 - val_acc: 0.6592\n",
      "Epoch 510/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6781 - acc: 0.5772 - val_loss: 0.6665 - val_acc: 0.6592\n",
      "Epoch 511/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6806 - acc: 0.5618 - val_loss: 0.6665 - val_acc: 0.6592\n",
      "Epoch 512/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6876 - acc: 0.5197 - val_loss: 0.6665 - val_acc: 0.6592\n",
      "Epoch 513/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6915 - acc: 0.5112 - val_loss: 0.6664 - val_acc: 0.6592\n",
      "Epoch 514/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6884 - acc: 0.5169 - val_loss: 0.6664 - val_acc: 0.6592\n",
      "Epoch 515/1000\n",
      "712/712 [==============================] - 0s 163us/step - loss: 0.6869 - acc: 0.5281 - val_loss: 0.6664 - val_acc: 0.6592\n",
      "Epoch 516/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6863 - acc: 0.5534 - val_loss: 0.6664 - val_acc: 0.6592\n",
      "Epoch 517/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6815 - acc: 0.5787 - val_loss: 0.6664 - val_acc: 0.6592\n",
      "Epoch 518/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6854 - acc: 0.5463 - val_loss: 0.6664 - val_acc: 0.6592\n",
      "Epoch 519/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6845 - acc: 0.5632 - val_loss: 0.6663 - val_acc: 0.6592\n",
      "Epoch 520/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6874 - acc: 0.5393 - val_loss: 0.6663 - val_acc: 0.6592\n",
      "Epoch 521/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6850 - acc: 0.5744 - val_loss: 0.6663 - val_acc: 0.6592\n",
      "Epoch 522/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6863 - acc: 0.5463 - val_loss: 0.6663 - val_acc: 0.6592\n",
      "Epoch 523/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6872 - acc: 0.5534 - val_loss: 0.6663 - val_acc: 0.6592\n",
      "Epoch 524/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6790 - acc: 0.5660 - val_loss: 0.6663 - val_acc: 0.6592\n",
      "Epoch 525/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6847 - acc: 0.5365 - val_loss: 0.6662 - val_acc: 0.6592\n",
      "Epoch 526/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6826 - acc: 0.5449 - val_loss: 0.6662 - val_acc: 0.6592\n",
      "Epoch 527/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6861 - acc: 0.5506 - val_loss: 0.6662 - val_acc: 0.6592\n",
      "Epoch 528/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6933 - acc: 0.5520 - val_loss: 0.6662 - val_acc: 0.6592\n",
      "Epoch 529/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6877 - acc: 0.5351 - val_loss: 0.6662 - val_acc: 0.6592\n",
      "Epoch 530/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6845 - acc: 0.5562 - val_loss: 0.6662 - val_acc: 0.6592\n",
      "Epoch 531/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6867 - acc: 0.5337 - val_loss: 0.6661 - val_acc: 0.6592\n",
      "Epoch 532/1000\n",
      "712/712 [==============================] - 0s 157us/step - loss: 0.6923 - acc: 0.5239 - val_loss: 0.6661 - val_acc: 0.6592\n",
      "Epoch 533/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6846 - acc: 0.5548 - val_loss: 0.6661 - val_acc: 0.6592\n",
      "Epoch 534/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6839 - acc: 0.5506 - val_loss: 0.6661 - val_acc: 0.6592\n",
      "Epoch 535/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6906 - acc: 0.5042 - val_loss: 0.6661 - val_acc: 0.6592\n",
      "Epoch 536/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6940 - acc: 0.5154 - val_loss: 0.6661 - val_acc: 0.6592\n",
      "Epoch 537/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6807 - acc: 0.5871 - val_loss: 0.6661 - val_acc: 0.6592\n",
      "Epoch 538/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6838 - acc: 0.5492 - val_loss: 0.6660 - val_acc: 0.6592\n",
      "Epoch 539/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6815 - acc: 0.5618 - val_loss: 0.6660 - val_acc: 0.6592\n",
      "Epoch 540/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6784 - acc: 0.5646 - val_loss: 0.6660 - val_acc: 0.6592\n",
      "Epoch 541/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6915 - acc: 0.5421 - val_loss: 0.6660 - val_acc: 0.6592\n",
      "Epoch 542/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6863 - acc: 0.5478 - val_loss: 0.6660 - val_acc: 0.6592\n",
      "Epoch 543/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6878 - acc: 0.5267 - val_loss: 0.6660 - val_acc: 0.6592\n",
      "Epoch 544/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6772 - acc: 0.5772 - val_loss: 0.6659 - val_acc: 0.6592\n",
      "Epoch 545/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6848 - acc: 0.5548 - val_loss: 0.6659 - val_acc: 0.6592\n",
      "Epoch 546/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6857 - acc: 0.5435 - val_loss: 0.6659 - val_acc: 0.6592\n",
      "Epoch 547/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6851 - acc: 0.5435 - val_loss: 0.6659 - val_acc: 0.6592\n",
      "Epoch 548/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6835 - acc: 0.5478 - val_loss: 0.6659 - val_acc: 0.6592\n",
      "Epoch 549/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6816 - acc: 0.5604 - val_loss: 0.6659 - val_acc: 0.6592\n",
      "Epoch 550/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6832 - acc: 0.5815 - val_loss: 0.6658 - val_acc: 0.6592\n",
      "Epoch 551/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6875 - acc: 0.5463 - val_loss: 0.6658 - val_acc: 0.6592\n",
      "Epoch 552/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6783 - acc: 0.5660 - val_loss: 0.6658 - val_acc: 0.6592\n",
      "Epoch 553/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6928 - acc: 0.5211 - val_loss: 0.6658 - val_acc: 0.6592\n",
      "Epoch 554/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6879 - acc: 0.5393 - val_loss: 0.6658 - val_acc: 0.6592\n",
      "Epoch 555/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6845 - acc: 0.5590 - val_loss: 0.6658 - val_acc: 0.6592\n",
      "Epoch 556/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6820 - acc: 0.5365 - val_loss: 0.6657 - val_acc: 0.6592\n",
      "Epoch 557/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.6801 - acc: 0.5463 - val_loss: 0.6657 - val_acc: 0.6592\n",
      "Epoch 558/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6872 - acc: 0.5365 - val_loss: 0.6657 - val_acc: 0.6592\n",
      "Epoch 559/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.6831 - acc: 0.5590 - val_loss: 0.6657 - val_acc: 0.6592\n",
      "Epoch 560/1000\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.6852 - acc: 0.5393 - val_loss: 0.6657 - val_acc: 0.6592\n",
      "Epoch 561/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6844 - acc: 0.5365 - val_loss: 0.6657 - val_acc: 0.6592\n",
      "Epoch 562/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6861 - acc: 0.5632 - val_loss: 0.6657 - val_acc: 0.6592\n",
      "Epoch 563/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6772 - acc: 0.5955 - val_loss: 0.6656 - val_acc: 0.6592\n",
      "Epoch 564/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6843 - acc: 0.5590 - val_loss: 0.6656 - val_acc: 0.6592\n",
      "Epoch 565/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6825 - acc: 0.5534 - val_loss: 0.6656 - val_acc: 0.6592\n",
      "Epoch 566/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6789 - acc: 0.5632 - val_loss: 0.6656 - val_acc: 0.6592\n",
      "Epoch 567/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6870 - acc: 0.5534 - val_loss: 0.6656 - val_acc: 0.6592\n",
      "Epoch 568/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6901 - acc: 0.5548 - val_loss: 0.6656 - val_acc: 0.6592\n",
      "Epoch 569/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6837 - acc: 0.5660 - val_loss: 0.6655 - val_acc: 0.6592\n",
      "Epoch 570/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6840 - acc: 0.5548 - val_loss: 0.6655 - val_acc: 0.6592\n",
      "Epoch 571/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6777 - acc: 0.5801 - val_loss: 0.6655 - val_acc: 0.6592\n",
      "Epoch 572/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6959 - acc: 0.5042 - val_loss: 0.6655 - val_acc: 0.6592\n",
      "Epoch 573/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6791 - acc: 0.5618 - val_loss: 0.6655 - val_acc: 0.6592\n",
      "Epoch 574/1000\n",
      "712/712 [==============================] - 0s 161us/step - loss: 0.6830 - acc: 0.5492 - val_loss: 0.6655 - val_acc: 0.6592\n",
      "Epoch 575/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6867 - acc: 0.5309 - val_loss: 0.6654 - val_acc: 0.6592\n",
      "Epoch 576/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6836 - acc: 0.5548 - val_loss: 0.6654 - val_acc: 0.6592\n",
      "Epoch 577/1000\n",
      "712/712 [==============================] - 0s 166us/step - loss: 0.6899 - acc: 0.5365 - val_loss: 0.6654 - val_acc: 0.6592\n",
      "Epoch 578/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6840 - acc: 0.5604 - val_loss: 0.6654 - val_acc: 0.6592\n",
      "Epoch 579/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6859 - acc: 0.5365 - val_loss: 0.6654 - val_acc: 0.6592\n",
      "Epoch 580/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6847 - acc: 0.5548 - val_loss: 0.6654 - val_acc: 0.6592\n",
      "Epoch 581/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6922 - acc: 0.5169 - val_loss: 0.6654 - val_acc: 0.6592\n",
      "Epoch 582/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6868 - acc: 0.5393 - val_loss: 0.6653 - val_acc: 0.6592\n",
      "Epoch 583/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6873 - acc: 0.5253 - val_loss: 0.6653 - val_acc: 0.6592\n",
      "Epoch 584/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6904 - acc: 0.5323 - val_loss: 0.6653 - val_acc: 0.6592\n",
      "Epoch 585/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6893 - acc: 0.5604 - val_loss: 0.6653 - val_acc: 0.6592\n",
      "Epoch 586/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6817 - acc: 0.5843 - val_loss: 0.6653 - val_acc: 0.6592\n",
      "Epoch 587/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6809 - acc: 0.5674 - val_loss: 0.6653 - val_acc: 0.6592\n",
      "Epoch 588/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6784 - acc: 0.5632 - val_loss: 0.6652 - val_acc: 0.6592\n",
      "Epoch 589/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6868 - acc: 0.5126 - val_loss: 0.6652 - val_acc: 0.6592\n",
      "Epoch 590/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6823 - acc: 0.5576 - val_loss: 0.6652 - val_acc: 0.6592\n",
      "Epoch 591/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6830 - acc: 0.5548 - val_loss: 0.6652 - val_acc: 0.6592\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 146us/step - loss: 0.6797 - acc: 0.5758 - val_loss: 0.6652 - val_acc: 0.6592\n",
      "Epoch 593/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6801 - acc: 0.5618 - val_loss: 0.6652 - val_acc: 0.6592\n",
      "Epoch 594/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6843 - acc: 0.5562 - val_loss: 0.6651 - val_acc: 0.6592\n",
      "Epoch 595/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6913 - acc: 0.5253 - val_loss: 0.6651 - val_acc: 0.6592\n",
      "Epoch 596/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6854 - acc: 0.5407 - val_loss: 0.6651 - val_acc: 0.6592\n",
      "Epoch 597/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6757 - acc: 0.5548 - val_loss: 0.6651 - val_acc: 0.6592\n",
      "Epoch 598/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6788 - acc: 0.5520 - val_loss: 0.6651 - val_acc: 0.6592\n",
      "Epoch 599/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6858 - acc: 0.5449 - val_loss: 0.6651 - val_acc: 0.6592\n",
      "Epoch 600/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6813 - acc: 0.5520 - val_loss: 0.6651 - val_acc: 0.6592\n",
      "Epoch 601/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6809 - acc: 0.5576 - val_loss: 0.6650 - val_acc: 0.6592\n",
      "Epoch 602/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6903 - acc: 0.5351 - val_loss: 0.6650 - val_acc: 0.6592\n",
      "Epoch 603/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6841 - acc: 0.5688 - val_loss: 0.6650 - val_acc: 0.6592\n",
      "Epoch 604/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6801 - acc: 0.5379 - val_loss: 0.6650 - val_acc: 0.6592\n",
      "Epoch 605/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6882 - acc: 0.5407 - val_loss: 0.6650 - val_acc: 0.6592\n",
      "Epoch 606/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6868 - acc: 0.5281 - val_loss: 0.6650 - val_acc: 0.6592\n",
      "Epoch 607/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6827 - acc: 0.5435 - val_loss: 0.6650 - val_acc: 0.6592\n",
      "Epoch 608/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6853 - acc: 0.5463 - val_loss: 0.6649 - val_acc: 0.6592\n",
      "Epoch 609/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6796 - acc: 0.5815 - val_loss: 0.6649 - val_acc: 0.6592\n",
      "Epoch 610/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6876 - acc: 0.5421 - val_loss: 0.6649 - val_acc: 0.6592\n",
      "Epoch 611/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6832 - acc: 0.5337 - val_loss: 0.6649 - val_acc: 0.6592\n",
      "Epoch 612/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6871 - acc: 0.5632 - val_loss: 0.6649 - val_acc: 0.6592\n",
      "Epoch 613/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6846 - acc: 0.5646 - val_loss: 0.6649 - val_acc: 0.6592\n",
      "Epoch 614/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6867 - acc: 0.5421 - val_loss: 0.6648 - val_acc: 0.6592\n",
      "Epoch 615/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6889 - acc: 0.5618 - val_loss: 0.6648 - val_acc: 0.6592\n",
      "Epoch 616/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6849 - acc: 0.5534 - val_loss: 0.6648 - val_acc: 0.6592\n",
      "Epoch 617/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6906 - acc: 0.5365 - val_loss: 0.6648 - val_acc: 0.6592\n",
      "Epoch 618/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6864 - acc: 0.5365 - val_loss: 0.6648 - val_acc: 0.6592\n",
      "Epoch 619/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6772 - acc: 0.5730 - val_loss: 0.6648 - val_acc: 0.6592\n",
      "Epoch 620/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6813 - acc: 0.5590 - val_loss: 0.6648 - val_acc: 0.6592\n",
      "Epoch 621/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6840 - acc: 0.5660 - val_loss: 0.6647 - val_acc: 0.6536\n",
      "Epoch 622/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6908 - acc: 0.5478 - val_loss: 0.6647 - val_acc: 0.6536\n",
      "Epoch 623/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6819 - acc: 0.5688 - val_loss: 0.6647 - val_acc: 0.6536\n",
      "Epoch 624/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6813 - acc: 0.5618 - val_loss: 0.6647 - val_acc: 0.6536\n",
      "Epoch 625/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6903 - acc: 0.5211 - val_loss: 0.6647 - val_acc: 0.6536\n",
      "Epoch 626/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6855 - acc: 0.5393 - val_loss: 0.6647 - val_acc: 0.6536\n",
      "Epoch 627/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6804 - acc: 0.5590 - val_loss: 0.6646 - val_acc: 0.6536\n",
      "Epoch 628/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6890 - acc: 0.5323 - val_loss: 0.6646 - val_acc: 0.6536\n",
      "Epoch 629/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6818 - acc: 0.5674 - val_loss: 0.6646 - val_acc: 0.6536\n",
      "Epoch 630/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6815 - acc: 0.5646 - val_loss: 0.6646 - val_acc: 0.6536\n",
      "Epoch 631/1000\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.6773 - acc: 0.5688 - val_loss: 0.6646 - val_acc: 0.6536\n",
      "Epoch 632/1000\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.6771 - acc: 0.5787 - val_loss: 0.6646 - val_acc: 0.6536\n",
      "Epoch 633/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6839 - acc: 0.5309 - val_loss: 0.6645 - val_acc: 0.6536\n",
      "Epoch 634/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6898 - acc: 0.5534 - val_loss: 0.6645 - val_acc: 0.6536\n",
      "Epoch 635/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6937 - acc: 0.5351 - val_loss: 0.6645 - val_acc: 0.6536\n",
      "Epoch 636/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6815 - acc: 0.5576 - val_loss: 0.6645 - val_acc: 0.6536\n",
      "Epoch 637/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6854 - acc: 0.5520 - val_loss: 0.6645 - val_acc: 0.6536\n",
      "Epoch 638/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6853 - acc: 0.5421 - val_loss: 0.6645 - val_acc: 0.6536\n",
      "Epoch 639/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6806 - acc: 0.5632 - val_loss: 0.6645 - val_acc: 0.6536\n",
      "Epoch 640/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6864 - acc: 0.5492 - val_loss: 0.6644 - val_acc: 0.6536\n",
      "Epoch 641/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6924 - acc: 0.5154 - val_loss: 0.6644 - val_acc: 0.6536\n",
      "Epoch 642/1000\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.6887 - acc: 0.5506 - val_loss: 0.6644 - val_acc: 0.6536\n",
      "Epoch 643/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6917 - acc: 0.5421 - val_loss: 0.6644 - val_acc: 0.6536\n",
      "Epoch 644/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6817 - acc: 0.5632 - val_loss: 0.6644 - val_acc: 0.6536\n",
      "Epoch 645/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6790 - acc: 0.5899 - val_loss: 0.6644 - val_acc: 0.6536\n",
      "Epoch 646/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6845 - acc: 0.5449 - val_loss: 0.6643 - val_acc: 0.6536\n",
      "Epoch 647/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6868 - acc: 0.5646 - val_loss: 0.6643 - val_acc: 0.6536\n",
      "Epoch 648/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6961 - acc: 0.5126 - val_loss: 0.6643 - val_acc: 0.6536\n",
      "Epoch 649/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6825 - acc: 0.5548 - val_loss: 0.6643 - val_acc: 0.6536\n",
      "Epoch 650/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6871 - acc: 0.5478 - val_loss: 0.6643 - val_acc: 0.6536\n",
      "Epoch 651/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6824 - acc: 0.5506 - val_loss: 0.6643 - val_acc: 0.6536\n",
      "Epoch 652/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6941 - acc: 0.5351 - val_loss: 0.6642 - val_acc: 0.6536\n",
      "Epoch 653/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6835 - acc: 0.5744 - val_loss: 0.6642 - val_acc: 0.6536\n",
      "Epoch 654/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6875 - acc: 0.5253 - val_loss: 0.6642 - val_acc: 0.6536\n",
      "Epoch 655/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6752 - acc: 0.5969 - val_loss: 0.6642 - val_acc: 0.6536\n",
      "Epoch 656/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6898 - acc: 0.5520 - val_loss: 0.6642 - val_acc: 0.6536\n",
      "Epoch 657/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6904 - acc: 0.5337 - val_loss: 0.6642 - val_acc: 0.6536\n",
      "Epoch 658/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6794 - acc: 0.5520 - val_loss: 0.6642 - val_acc: 0.6536\n",
      "Epoch 659/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6839 - acc: 0.5534 - val_loss: 0.6641 - val_acc: 0.6536\n",
      "Epoch 660/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6823 - acc: 0.5548 - val_loss: 0.6641 - val_acc: 0.6536\n",
      "Epoch 661/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6786 - acc: 0.5688 - val_loss: 0.6641 - val_acc: 0.6536\n",
      "Epoch 662/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6889 - acc: 0.5309 - val_loss: 0.6641 - val_acc: 0.6536\n",
      "Epoch 663/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6817 - acc: 0.5618 - val_loss: 0.6641 - val_acc: 0.6536\n",
      "Epoch 664/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6942 - acc: 0.5225 - val_loss: 0.6641 - val_acc: 0.6536\n",
      "Epoch 665/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6871 - acc: 0.5815 - val_loss: 0.6640 - val_acc: 0.6536\n",
      "Epoch 666/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6782 - acc: 0.5927 - val_loss: 0.6640 - val_acc: 0.6536\n",
      "Epoch 667/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6871 - acc: 0.5520 - val_loss: 0.6640 - val_acc: 0.6536\n",
      "Epoch 668/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6835 - acc: 0.5576 - val_loss: 0.6640 - val_acc: 0.6536\n",
      "Epoch 669/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6827 - acc: 0.5435 - val_loss: 0.6640 - val_acc: 0.6536\n",
      "Epoch 670/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6906 - acc: 0.5267 - val_loss: 0.6640 - val_acc: 0.6536\n",
      "Epoch 671/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6834 - acc: 0.5506 - val_loss: 0.6640 - val_acc: 0.6536\n",
      "Epoch 672/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6870 - acc: 0.5393 - val_loss: 0.6639 - val_acc: 0.6536\n",
      "Epoch 673/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6840 - acc: 0.5506 - val_loss: 0.6639 - val_acc: 0.6536\n",
      "Epoch 674/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.6805 - acc: 0.5716 - val_loss: 0.6639 - val_acc: 0.6536\n",
      "Epoch 675/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.6909 - acc: 0.5211 - val_loss: 0.6639 - val_acc: 0.6536\n",
      "Epoch 676/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6830 - acc: 0.5646 - val_loss: 0.6639 - val_acc: 0.6536\n",
      "Epoch 677/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6853 - acc: 0.5548 - val_loss: 0.6639 - val_acc: 0.6536\n",
      "Epoch 678/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6799 - acc: 0.5744 - val_loss: 0.6639 - val_acc: 0.6536\n",
      "Epoch 679/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6808 - acc: 0.5632 - val_loss: 0.6638 - val_acc: 0.6536\n",
      "Epoch 680/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6796 - acc: 0.5506 - val_loss: 0.6638 - val_acc: 0.6536\n",
      "Epoch 681/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6792 - acc: 0.5857 - val_loss: 0.6638 - val_acc: 0.6536\n",
      "Epoch 682/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6809 - acc: 0.5520 - val_loss: 0.6638 - val_acc: 0.6536\n",
      "Epoch 683/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6896 - acc: 0.5309 - val_loss: 0.6638 - val_acc: 0.6536\n",
      "Epoch 684/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6775 - acc: 0.5646 - val_loss: 0.6638 - val_acc: 0.6536\n",
      "Epoch 685/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6772 - acc: 0.5815 - val_loss: 0.6637 - val_acc: 0.6536\n",
      "Epoch 686/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6824 - acc: 0.5548 - val_loss: 0.6637 - val_acc: 0.6536\n",
      "Epoch 687/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6846 - acc: 0.5576 - val_loss: 0.6637 - val_acc: 0.6536\n",
      "Epoch 688/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6778 - acc: 0.5787 - val_loss: 0.6637 - val_acc: 0.6536\n",
      "Epoch 689/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6762 - acc: 0.5688 - val_loss: 0.6637 - val_acc: 0.6536\n",
      "Epoch 690/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6799 - acc: 0.5744 - val_loss: 0.6637 - val_acc: 0.6536\n",
      "Epoch 691/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6885 - acc: 0.5632 - val_loss: 0.6637 - val_acc: 0.6536\n",
      "Epoch 692/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6863 - acc: 0.5365 - val_loss: 0.6636 - val_acc: 0.6536\n",
      "Epoch 693/1000\n",
      "712/712 [==============================] - 0s 146us/step - loss: 0.6804 - acc: 0.5632 - val_loss: 0.6636 - val_acc: 0.6536\n",
      "Epoch 694/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6864 - acc: 0.5520 - val_loss: 0.6636 - val_acc: 0.6536\n",
      "Epoch 695/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6844 - acc: 0.5660 - val_loss: 0.6636 - val_acc: 0.6536\n",
      "Epoch 696/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6790 - acc: 0.5829 - val_loss: 0.6636 - val_acc: 0.6536\n",
      "Epoch 697/1000\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.6874 - acc: 0.5576 - val_loss: 0.6636 - val_acc: 0.6536\n",
      "Epoch 698/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6809 - acc: 0.5660 - val_loss: 0.6635 - val_acc: 0.6536\n",
      "Epoch 699/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6728 - acc: 0.5955 - val_loss: 0.6635 - val_acc: 0.6536\n",
      "Epoch 700/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6870 - acc: 0.5702 - val_loss: 0.6635 - val_acc: 0.6536\n",
      "Epoch 701/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6831 - acc: 0.5492 - val_loss: 0.6635 - val_acc: 0.6536\n",
      "Epoch 702/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6863 - acc: 0.5618 - val_loss: 0.6635 - val_acc: 0.6536\n",
      "Epoch 703/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6784 - acc: 0.5646 - val_loss: 0.6635 - val_acc: 0.6536\n",
      "Epoch 704/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6824 - acc: 0.5534 - val_loss: 0.6635 - val_acc: 0.6536\n",
      "Epoch 705/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6820 - acc: 0.5562 - val_loss: 0.6634 - val_acc: 0.6536\n",
      "Epoch 706/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6878 - acc: 0.5492 - val_loss: 0.6634 - val_acc: 0.6536\n",
      "Epoch 707/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.6732 - acc: 0.5955 - val_loss: 0.6634 - val_acc: 0.6536\n",
      "Epoch 708/1000\n",
      "712/712 [==============================] - 0s 118us/step - loss: 0.6847 - acc: 0.5772 - val_loss: 0.6634 - val_acc: 0.6536\n",
      "Epoch 709/1000\n",
      "712/712 [==============================] - 0s 124us/step - loss: 0.6880 - acc: 0.5323 - val_loss: 0.6634 - val_acc: 0.6536\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 109us/step - loss: 0.6789 - acc: 0.5618 - val_loss: 0.6634 - val_acc: 0.6536\n",
      "Epoch 711/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6825 - acc: 0.5295 - val_loss: 0.6634 - val_acc: 0.6536\n",
      "Epoch 712/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6792 - acc: 0.5520 - val_loss: 0.6633 - val_acc: 0.6536\n",
      "Epoch 713/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6854 - acc: 0.5744 - val_loss: 0.6633 - val_acc: 0.6536\n",
      "Epoch 714/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.6877 - acc: 0.5562 - val_loss: 0.6633 - val_acc: 0.6536\n",
      "Epoch 715/1000\n",
      "712/712 [==============================] - 0s 100us/step - loss: 0.6827 - acc: 0.5534 - val_loss: 0.6633 - val_acc: 0.6536\n",
      "Epoch 716/1000\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.6863 - acc: 0.5323 - val_loss: 0.6633 - val_acc: 0.6536\n",
      "Epoch 717/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.6850 - acc: 0.5562 - val_loss: 0.6633 - val_acc: 0.6536\n",
      "Epoch 718/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.6827 - acc: 0.5632 - val_loss: 0.6632 - val_acc: 0.6536\n",
      "Epoch 719/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.6815 - acc: 0.5618 - val_loss: 0.6632 - val_acc: 0.6536\n",
      "Epoch 720/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.6846 - acc: 0.5520 - val_loss: 0.6632 - val_acc: 0.6536\n",
      "Epoch 721/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6803 - acc: 0.5646 - val_loss: 0.6632 - val_acc: 0.6536\n",
      "Epoch 722/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6843 - acc: 0.5604 - val_loss: 0.6632 - val_acc: 0.6536\n",
      "Epoch 723/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6853 - acc: 0.5534 - val_loss: 0.6632 - val_acc: 0.6536\n",
      "Epoch 724/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6875 - acc: 0.5323 - val_loss: 0.6632 - val_acc: 0.6536\n",
      "Epoch 725/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6764 - acc: 0.5716 - val_loss: 0.6631 - val_acc: 0.6536\n",
      "Epoch 726/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6831 - acc: 0.5506 - val_loss: 0.6631 - val_acc: 0.6536\n",
      "Epoch 727/1000\n",
      "712/712 [==============================] - 0s 159us/step - loss: 0.6915 - acc: 0.5225 - val_loss: 0.6631 - val_acc: 0.6536\n",
      "Epoch 728/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6773 - acc: 0.5772 - val_loss: 0.6631 - val_acc: 0.6536\n",
      "Epoch 729/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6795 - acc: 0.5520 - val_loss: 0.6631 - val_acc: 0.6536\n",
      "Epoch 730/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.6796 - acc: 0.5590 - val_loss: 0.6631 - val_acc: 0.6536\n",
      "Epoch 731/1000\n",
      "712/712 [==============================] - 0s 122us/step - loss: 0.6873 - acc: 0.5379 - val_loss: 0.6631 - val_acc: 0.6536\n",
      "Epoch 732/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6817 - acc: 0.5520 - val_loss: 0.6630 - val_acc: 0.6536\n",
      "Epoch 733/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6822 - acc: 0.5463 - val_loss: 0.6630 - val_acc: 0.6536\n",
      "Epoch 734/1000\n",
      "712/712 [==============================] - 0s 168us/step - loss: 0.6776 - acc: 0.5815 - val_loss: 0.6630 - val_acc: 0.6536\n",
      "Epoch 735/1000\n",
      "712/712 [==============================] - 0s 174us/step - loss: 0.6765 - acc: 0.5857 - val_loss: 0.6630 - val_acc: 0.6536\n",
      "Epoch 736/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6799 - acc: 0.5632 - val_loss: 0.6630 - val_acc: 0.6536\n",
      "Epoch 737/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6761 - acc: 0.5857 - val_loss: 0.6630 - val_acc: 0.6536\n",
      "Epoch 738/1000\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.6762 - acc: 0.5660 - val_loss: 0.6629 - val_acc: 0.6536\n",
      "Epoch 739/1000\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.6770 - acc: 0.5492 - val_loss: 0.6629 - val_acc: 0.6536\n",
      "Epoch 740/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6824 - acc: 0.5463 - val_loss: 0.6629 - val_acc: 0.6536\n",
      "Epoch 741/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6779 - acc: 0.5801 - val_loss: 0.6629 - val_acc: 0.6536\n",
      "Epoch 742/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6878 - acc: 0.5520 - val_loss: 0.6629 - val_acc: 0.6536\n",
      "Epoch 743/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6836 - acc: 0.5520 - val_loss: 0.6629 - val_acc: 0.6536\n",
      "Epoch 744/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6879 - acc: 0.5534 - val_loss: 0.6629 - val_acc: 0.6536\n",
      "Epoch 745/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6823 - acc: 0.5590 - val_loss: 0.6628 - val_acc: 0.6536\n",
      "Epoch 746/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6780 - acc: 0.5913 - val_loss: 0.6628 - val_acc: 0.6536\n",
      "Epoch 747/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6774 - acc: 0.5787 - val_loss: 0.6628 - val_acc: 0.6536\n",
      "Epoch 748/1000\n",
      "712/712 [==============================] - 0s 148us/step - loss: 0.6924 - acc: 0.5253 - val_loss: 0.6628 - val_acc: 0.6536\n",
      "Epoch 749/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6782 - acc: 0.5801 - val_loss: 0.6628 - val_acc: 0.6536\n",
      "Epoch 750/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6860 - acc: 0.5421 - val_loss: 0.6628 - val_acc: 0.6536\n",
      "Epoch 751/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6818 - acc: 0.5393 - val_loss: 0.6627 - val_acc: 0.6536\n",
      "Epoch 752/1000\n",
      "712/712 [==============================] - 0s 140us/step - loss: 0.6816 - acc: 0.5492 - val_loss: 0.6627 - val_acc: 0.6536\n",
      "Epoch 753/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6822 - acc: 0.5857 - val_loss: 0.6627 - val_acc: 0.6536\n",
      "Epoch 754/1000\n",
      "712/712 [==============================] - 0s 153us/step - loss: 0.6825 - acc: 0.5590 - val_loss: 0.6627 - val_acc: 0.6536\n",
      "Epoch 755/1000\n",
      "712/712 [==============================] - 0s 162us/step - loss: 0.6801 - acc: 0.5646 - val_loss: 0.6627 - val_acc: 0.6536\n",
      "Epoch 756/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6806 - acc: 0.5660 - val_loss: 0.6627 - val_acc: 0.6536\n",
      "Epoch 757/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6820 - acc: 0.5688 - val_loss: 0.6627 - val_acc: 0.6536\n",
      "Epoch 758/1000\n",
      "712/712 [==============================] - 0s 91us/step - loss: 0.6844 - acc: 0.5449 - val_loss: 0.6626 - val_acc: 0.6536\n",
      "Epoch 759/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6905 - acc: 0.5225 - val_loss: 0.6626 - val_acc: 0.6536\n",
      "Epoch 760/1000\n",
      "712/712 [==============================] - 0s 92us/step - loss: 0.6903 - acc: 0.5379 - val_loss: 0.6626 - val_acc: 0.6536\n",
      "Epoch 761/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6907 - acc: 0.5309 - val_loss: 0.6626 - val_acc: 0.6536\n",
      "Epoch 762/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6831 - acc: 0.5702 - val_loss: 0.6626 - val_acc: 0.6536\n",
      "Epoch 763/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6733 - acc: 0.5871 - val_loss: 0.6626 - val_acc: 0.6536\n",
      "Epoch 764/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6862 - acc: 0.5646 - val_loss: 0.6625 - val_acc: 0.6536\n",
      "Epoch 765/1000\n",
      "712/712 [==============================] - 0s 77us/step - loss: 0.6776 - acc: 0.5674 - val_loss: 0.6625 - val_acc: 0.6536\n",
      "Epoch 766/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6900 - acc: 0.5534 - val_loss: 0.6625 - val_acc: 0.6536\n",
      "Epoch 767/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6846 - acc: 0.5435 - val_loss: 0.6625 - val_acc: 0.6536\n",
      "Epoch 768/1000\n",
      "712/712 [==============================] - 0s 96us/step - loss: 0.6811 - acc: 0.5674 - val_loss: 0.6625 - val_acc: 0.6536\n",
      "Epoch 769/1000\n",
      "712/712 [==============================] - 0s 78us/step - loss: 0.6788 - acc: 0.5674 - val_loss: 0.6625 - val_acc: 0.6536\n",
      "Epoch 770/1000\n",
      "712/712 [==============================] - 0s 76us/step - loss: 0.6841 - acc: 0.5534 - val_loss: 0.6625 - val_acc: 0.6536\n",
      "Epoch 771/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6767 - acc: 0.5758 - val_loss: 0.6624 - val_acc: 0.6536\n",
      "Epoch 772/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6794 - acc: 0.5646 - val_loss: 0.6624 - val_acc: 0.6536\n",
      "Epoch 773/1000\n",
      "712/712 [==============================] - 0s 75us/step - loss: 0.6800 - acc: 0.5829 - val_loss: 0.6624 - val_acc: 0.6536\n",
      "Epoch 774/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6736 - acc: 0.5829 - val_loss: 0.6624 - val_acc: 0.6536\n",
      "Epoch 775/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6820 - acc: 0.5688 - val_loss: 0.6624 - val_acc: 0.6536\n",
      "Epoch 776/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.6728 - acc: 0.6039 - val_loss: 0.6624 - val_acc: 0.6536\n",
      "Epoch 777/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.6858 - acc: 0.5407 - val_loss: 0.6623 - val_acc: 0.6536\n",
      "Epoch 778/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6809 - acc: 0.5337 - val_loss: 0.6623 - val_acc: 0.6536\n",
      "Epoch 779/1000\n",
      "712/712 [==============================] - 0s 97us/step - loss: 0.6868 - acc: 0.5478 - val_loss: 0.6623 - val_acc: 0.6536\n",
      "Epoch 780/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.6904 - acc: 0.5211 - val_loss: 0.6623 - val_acc: 0.6536\n",
      "Epoch 781/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6908 - acc: 0.5435 - val_loss: 0.6623 - val_acc: 0.6536\n",
      "Epoch 782/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6821 - acc: 0.5590 - val_loss: 0.6623 - val_acc: 0.6536\n",
      "Epoch 783/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6810 - acc: 0.5548 - val_loss: 0.6623 - val_acc: 0.6536\n",
      "Epoch 784/1000\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.6803 - acc: 0.5702 - val_loss: 0.6622 - val_acc: 0.6536\n",
      "Epoch 785/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.6877 - acc: 0.5506 - val_loss: 0.6622 - val_acc: 0.6536\n",
      "Epoch 786/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.6777 - acc: 0.5857 - val_loss: 0.6622 - val_acc: 0.6536\n",
      "Epoch 787/1000\n",
      "712/712 [==============================] - 0s 106us/step - loss: 0.6851 - acc: 0.5393 - val_loss: 0.6622 - val_acc: 0.6536\n",
      "Epoch 788/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6815 - acc: 0.5716 - val_loss: 0.6622 - val_acc: 0.6536\n",
      "Epoch 789/1000\n",
      "712/712 [==============================] - 0s 109us/step - loss: 0.6895 - acc: 0.5295 - val_loss: 0.6622 - val_acc: 0.6536\n",
      "Epoch 790/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6840 - acc: 0.5730 - val_loss: 0.6622 - val_acc: 0.6536\n",
      "Epoch 791/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6862 - acc: 0.5295 - val_loss: 0.6621 - val_acc: 0.6536\n",
      "Epoch 792/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6817 - acc: 0.5674 - val_loss: 0.6621 - val_acc: 0.6536\n",
      "Epoch 793/1000\n",
      "712/712 [==============================] - 0s 112us/step - loss: 0.6765 - acc: 0.5787 - val_loss: 0.6621 - val_acc: 0.6536\n",
      "Epoch 794/1000\n",
      "712/712 [==============================] - 0s 114us/step - loss: 0.6828 - acc: 0.5351 - val_loss: 0.6621 - val_acc: 0.6536\n",
      "Epoch 795/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6840 - acc: 0.5506 - val_loss: 0.6621 - val_acc: 0.6536\n",
      "Epoch 796/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6741 - acc: 0.5829 - val_loss: 0.6621 - val_acc: 0.6536\n",
      "Epoch 797/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6728 - acc: 0.5758 - val_loss: 0.6620 - val_acc: 0.6536\n",
      "Epoch 798/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6815 - acc: 0.5772 - val_loss: 0.6620 - val_acc: 0.6536\n",
      "Epoch 799/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6828 - acc: 0.5674 - val_loss: 0.6620 - val_acc: 0.6536\n",
      "Epoch 800/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6771 - acc: 0.5730 - val_loss: 0.6620 - val_acc: 0.6536\n",
      "Epoch 801/1000\n",
      "712/712 [==============================] - 0s 121us/step - loss: 0.6855 - acc: 0.5576 - val_loss: 0.6620 - val_acc: 0.6536\n",
      "Epoch 802/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6894 - acc: 0.5211 - val_loss: 0.6620 - val_acc: 0.6536\n",
      "Epoch 803/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6853 - acc: 0.5646 - val_loss: 0.6620 - val_acc: 0.6536\n",
      "Epoch 804/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6856 - acc: 0.5478 - val_loss: 0.6619 - val_acc: 0.6536\n",
      "Epoch 805/1000\n",
      "712/712 [==============================] - 0s 136us/step - loss: 0.6751 - acc: 0.5871 - val_loss: 0.6619 - val_acc: 0.6536\n",
      "Epoch 806/1000\n",
      "712/712 [==============================] - 0s 138us/step - loss: 0.6814 - acc: 0.5730 - val_loss: 0.6619 - val_acc: 0.6536\n",
      "Epoch 807/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6784 - acc: 0.5548 - val_loss: 0.6619 - val_acc: 0.6536\n",
      "Epoch 808/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6789 - acc: 0.5913 - val_loss: 0.6619 - val_acc: 0.6536\n",
      "Epoch 809/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6805 - acc: 0.5421 - val_loss: 0.6619 - val_acc: 0.6536\n",
      "Epoch 810/1000\n",
      "712/712 [==============================] - 0s 149us/step - loss: 0.6828 - acc: 0.5618 - val_loss: 0.6619 - val_acc: 0.6536\n",
      "Epoch 811/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6858 - acc: 0.5449 - val_loss: 0.6618 - val_acc: 0.6536\n",
      "Epoch 812/1000\n",
      "712/712 [==============================] - 0s 160us/step - loss: 0.6819 - acc: 0.5646 - val_loss: 0.6618 - val_acc: 0.6536\n",
      "Epoch 813/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6821 - acc: 0.5337 - val_loss: 0.6618 - val_acc: 0.6536\n",
      "Epoch 814/1000\n",
      "712/712 [==============================] - 0s 156us/step - loss: 0.6764 - acc: 0.5829 - val_loss: 0.6618 - val_acc: 0.6536\n",
      "Epoch 815/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6835 - acc: 0.5801 - val_loss: 0.6618 - val_acc: 0.6536\n",
      "Epoch 816/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6795 - acc: 0.5632 - val_loss: 0.6618 - val_acc: 0.6536\n",
      "Epoch 817/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6896 - acc: 0.5154 - val_loss: 0.6617 - val_acc: 0.6536\n",
      "Epoch 818/1000\n",
      "712/712 [==============================] - 0s 147us/step - loss: 0.6833 - acc: 0.5379 - val_loss: 0.6617 - val_acc: 0.6536\n",
      "Epoch 819/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6830 - acc: 0.5253 - val_loss: 0.6617 - val_acc: 0.6536\n",
      "Epoch 820/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6827 - acc: 0.5478 - val_loss: 0.6617 - val_acc: 0.6536\n",
      "Epoch 821/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6803 - acc: 0.5730 - val_loss: 0.6617 - val_acc: 0.6536\n",
      "Epoch 822/1000\n",
      "712/712 [==============================] - 0s 151us/step - loss: 0.6915 - acc: 0.5323 - val_loss: 0.6617 - val_acc: 0.6536\n",
      "Epoch 823/1000\n",
      "712/712 [==============================] - 0s 145us/step - loss: 0.6832 - acc: 0.5534 - val_loss: 0.6617 - val_acc: 0.6536\n",
      "Epoch 824/1000\n",
      "712/712 [==============================] - 0s 154us/step - loss: 0.6760 - acc: 0.5702 - val_loss: 0.6616 - val_acc: 0.6536\n",
      "Epoch 825/1000\n",
      "712/712 [==============================] - 0s 155us/step - loss: 0.6768 - acc: 0.5815 - val_loss: 0.6616 - val_acc: 0.6536\n",
      "Epoch 826/1000\n",
      "712/712 [==============================] - 0s 152us/step - loss: 0.6841 - acc: 0.5506 - val_loss: 0.6616 - val_acc: 0.6536\n",
      "Epoch 827/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6828 - acc: 0.5435 - val_loss: 0.6616 - val_acc: 0.6536\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 146us/step - loss: 0.6783 - acc: 0.5772 - val_loss: 0.6616 - val_acc: 0.6536\n",
      "Epoch 829/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6827 - acc: 0.5562 - val_loss: 0.6616 - val_acc: 0.6536\n",
      "Epoch 830/1000\n",
      "712/712 [==============================] - 0s 150us/step - loss: 0.6788 - acc: 0.5632 - val_loss: 0.6616 - val_acc: 0.6536\n",
      "Epoch 831/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6819 - acc: 0.5576 - val_loss: 0.6615 - val_acc: 0.6536\n",
      "Epoch 832/1000\n",
      "712/712 [==============================] - 0s 110us/step - loss: 0.6760 - acc: 0.5829 - val_loss: 0.6615 - val_acc: 0.6536\n",
      "Epoch 833/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6785 - acc: 0.5801 - val_loss: 0.6615 - val_acc: 0.6536\n",
      "Epoch 834/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6775 - acc: 0.5688 - val_loss: 0.6615 - val_acc: 0.6536\n",
      "Epoch 835/1000\n",
      "712/712 [==============================] - 0s 142us/step - loss: 0.6903 - acc: 0.5295 - val_loss: 0.6615 - val_acc: 0.6536\n",
      "Epoch 836/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6840 - acc: 0.5590 - val_loss: 0.6615 - val_acc: 0.6536\n",
      "Epoch 837/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6838 - acc: 0.5506 - val_loss: 0.6614 - val_acc: 0.6536\n",
      "Epoch 838/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6886 - acc: 0.5393 - val_loss: 0.6614 - val_acc: 0.6536\n",
      "Epoch 839/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6827 - acc: 0.5801 - val_loss: 0.6614 - val_acc: 0.6536\n",
      "Epoch 840/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6837 - acc: 0.5646 - val_loss: 0.6614 - val_acc: 0.6536\n",
      "Epoch 841/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6773 - acc: 0.5744 - val_loss: 0.6614 - val_acc: 0.6536\n",
      "Epoch 842/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6808 - acc: 0.5576 - val_loss: 0.6614 - val_acc: 0.6536\n",
      "Epoch 843/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6765 - acc: 0.5843 - val_loss: 0.6614 - val_acc: 0.6536\n",
      "Epoch 844/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6787 - acc: 0.5744 - val_loss: 0.6613 - val_acc: 0.6536\n",
      "Epoch 845/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6831 - acc: 0.5688 - val_loss: 0.6613 - val_acc: 0.6536\n",
      "Epoch 846/1000\n",
      "712/712 [==============================] - 0s 141us/step - loss: 0.6873 - acc: 0.5253 - val_loss: 0.6613 - val_acc: 0.6536\n",
      "Epoch 847/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6853 - acc: 0.5478 - val_loss: 0.6613 - val_acc: 0.6536\n",
      "Epoch 848/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6710 - acc: 0.6081 - val_loss: 0.6613 - val_acc: 0.6536\n",
      "Epoch 849/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6773 - acc: 0.5702 - val_loss: 0.6613 - val_acc: 0.6536\n",
      "Epoch 850/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6827 - acc: 0.5604 - val_loss: 0.6613 - val_acc: 0.6536\n",
      "Epoch 851/1000\n",
      "712/712 [==============================] - 0s 137us/step - loss: 0.6783 - acc: 0.5562 - val_loss: 0.6612 - val_acc: 0.6536\n",
      "Epoch 852/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6780 - acc: 0.5604 - val_loss: 0.6612 - val_acc: 0.6536\n",
      "Epoch 853/1000\n",
      "712/712 [==============================] - 0s 135us/step - loss: 0.6799 - acc: 0.5674 - val_loss: 0.6612 - val_acc: 0.6536\n",
      "Epoch 854/1000\n",
      "712/712 [==============================] - 0s 144us/step - loss: 0.6803 - acc: 0.5506 - val_loss: 0.6612 - val_acc: 0.6536\n",
      "Epoch 855/1000\n",
      "712/712 [==============================] - 0s 128us/step - loss: 0.6760 - acc: 0.5885 - val_loss: 0.6612 - val_acc: 0.6536\n",
      "Epoch 856/1000\n",
      "712/712 [==============================] - 0s 127us/step - loss: 0.6776 - acc: 0.5758 - val_loss: 0.6612 - val_acc: 0.6536\n",
      "Epoch 857/1000\n",
      "712/712 [==============================] - 0s 120us/step - loss: 0.6913 - acc: 0.5337 - val_loss: 0.6611 - val_acc: 0.6536\n",
      "Epoch 858/1000\n",
      "712/712 [==============================] - 0s 132us/step - loss: 0.6864 - acc: 0.5211 - val_loss: 0.6611 - val_acc: 0.6536\n",
      "Epoch 859/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6830 - acc: 0.5632 - val_loss: 0.6611 - val_acc: 0.6536\n",
      "Epoch 860/1000\n",
      "712/712 [==============================] - 0s 129us/step - loss: 0.6850 - acc: 0.5492 - val_loss: 0.6611 - val_acc: 0.6536\n",
      "Epoch 861/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6795 - acc: 0.5730 - val_loss: 0.6611 - val_acc: 0.6536\n",
      "Epoch 862/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6850 - acc: 0.5379 - val_loss: 0.6611 - val_acc: 0.6536\n",
      "Epoch 863/1000\n",
      "712/712 [==============================] - 0s 98us/step - loss: 0.6847 - acc: 0.5449 - val_loss: 0.6611 - val_acc: 0.6536\n",
      "Epoch 864/1000\n",
      "712/712 [==============================] - 0s 101us/step - loss: 0.6850 - acc: 0.5449 - val_loss: 0.6610 - val_acc: 0.6536\n",
      "Epoch 865/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.6771 - acc: 0.5927 - val_loss: 0.6610 - val_acc: 0.6536\n",
      "Epoch 866/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6828 - acc: 0.5660 - val_loss: 0.6610 - val_acc: 0.6536\n",
      "Epoch 867/1000\n",
      "712/712 [==============================] - 0s 133us/step - loss: 0.6841 - acc: 0.5618 - val_loss: 0.6610 - val_acc: 0.6536\n",
      "Epoch 868/1000\n",
      "712/712 [==============================] - 0s 134us/step - loss: 0.6758 - acc: 0.5787 - val_loss: 0.6610 - val_acc: 0.6536\n",
      "Epoch 869/1000\n",
      "712/712 [==============================] - 0s 99us/step - loss: 0.6734 - acc: 0.5857 - val_loss: 0.6610 - val_acc: 0.6536\n",
      "Epoch 870/1000\n",
      "712/712 [==============================] - 0s 107us/step - loss: 0.6849 - acc: 0.5463 - val_loss: 0.6609 - val_acc: 0.6536\n",
      "Epoch 871/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6835 - acc: 0.5548 - val_loss: 0.6609 - val_acc: 0.6536\n",
      "Epoch 872/1000\n",
      "712/712 [==============================] - 0s 115us/step - loss: 0.6831 - acc: 0.5337 - val_loss: 0.6609 - val_acc: 0.6536\n",
      "Epoch 873/1000\n",
      "712/712 [==============================] - 0s 104us/step - loss: 0.6769 - acc: 0.5843 - val_loss: 0.6609 - val_acc: 0.6536\n",
      "Epoch 874/1000\n",
      "712/712 [==============================] - 0s 102us/step - loss: 0.6794 - acc: 0.5660 - val_loss: 0.6609 - val_acc: 0.6536\n",
      "Epoch 875/1000\n",
      "712/712 [==============================] - 0s 111us/step - loss: 0.6758 - acc: 0.5618 - val_loss: 0.6609 - val_acc: 0.6536\n",
      "Epoch 876/1000\n",
      "712/712 [==============================] - 0s 103us/step - loss: 0.6862 - acc: 0.5534 - val_loss: 0.6609 - val_acc: 0.6536\n",
      "Epoch 877/1000\n",
      "712/712 [==============================] - 0s 117us/step - loss: 0.6801 - acc: 0.5590 - val_loss: 0.6608 - val_acc: 0.6536\n",
      "Epoch 878/1000\n",
      "712/712 [==============================] - 0s 108us/step - loss: 0.6774 - acc: 0.5562 - val_loss: 0.6608 - val_acc: 0.6536\n",
      "Epoch 879/1000\n",
      "712/712 [==============================] - 0s 105us/step - loss: 0.6752 - acc: 0.5871 - val_loss: 0.6608 - val_acc: 0.6536\n",
      "Epoch 880/1000\n",
      "712/712 [==============================] - 0s 113us/step - loss: 0.6848 - acc: 0.5379 - val_loss: 0.6608 - val_acc: 0.6536\n",
      "Epoch 881/1000\n",
      "712/712 [==============================] - 0s 116us/step - loss: 0.6844 - acc: 0.5492 - val_loss: 0.6608 - val_acc: 0.6536\n",
      "Epoch 882/1000\n",
      "712/712 [==============================] - 0s 119us/step - loss: 0.6752 - acc: 0.5744 - val_loss: 0.6608 - val_acc: 0.6536\n",
      "Epoch 883/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6866 - acc: 0.5506 - val_loss: 0.6607 - val_acc: 0.6536\n",
      "Epoch 884/1000\n",
      "712/712 [==============================] - 0s 123us/step - loss: 0.6806 - acc: 0.5520 - val_loss: 0.6607 - val_acc: 0.6536\n",
      "Epoch 885/1000\n",
      "712/712 [==============================] - 0s 131us/step - loss: 0.6870 - acc: 0.5435 - val_loss: 0.6607 - val_acc: 0.6536\n",
      "Epoch 886/1000\n",
      "712/712 [==============================] - 0s 139us/step - loss: 0.6783 - acc: 0.5646 - val_loss: 0.6607 - val_acc: 0.6536\n",
      "Epoch 887/1000\n",
      "712/712 [==============================] - 0s 126us/step - loss: 0.6792 - acc: 0.5534 - val_loss: 0.6607 - val_acc: 0.6536\n",
      "Epoch 888/1000\n",
      "712/712 [==============================] - 0s 143us/step - loss: 0.6783 - acc: 0.5604 - val_loss: 0.6607 - val_acc: 0.6536\n",
      "Epoch 889/1000\n",
      "712/712 [==============================] - 0s 125us/step - loss: 0.6812 - acc: 0.5562 - val_loss: 0.6607 - val_acc: 0.6536\n",
      "Epoch 890/1000\n",
      "712/712 [==============================] - 0s 130us/step - loss: 0.6823 - acc: 0.5463 - val_loss: 0.6606 - val_acc: 0.6536\n",
      "Epoch 891/1000\n",
      " 32/712 [>.............................] - ETA: 0s - loss: 0.7262 - acc: 0.3438"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-a6024ef984eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reduced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn = Sequential([\n",
    "    Dense(64, input_shape=(train_reduced.shape[1],), activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=10, verbose=1, mode='auto')\n",
    "callback_list = [earlystop]\n",
    "sgd = optimizers.SGD(lr=1e-6, decay=1e-8, momentum=0.9, nesterov=True)\n",
    "# For a binary classification problem\n",
    "nn.compile(optimizer=sgd,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "nn.fit(train_reduced, y, epochs=1000, batch_size=32, validation_split=0.2, shuffle=True, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
