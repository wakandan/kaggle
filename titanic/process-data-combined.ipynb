{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "----------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_df.info()\n",
    "print('-'*40)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akai/virtualenvs/tensor_flow/lib/python3.5/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15.0458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Fare\n",
       "0       1  60.0000\n",
       "1       2  15.0458\n",
       "2       3   8.0500"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[train_df.Fare.notnull()].groupby(['Pclass']).median().reset_index()[['Pclass', 'Fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akai/virtualenvs/tensor_flow/lib/python3.5/site-packages/ipykernel_launcher.py:16: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  app.launch_new_instance()\n",
      "/home/akai/virtualenvs/tensor_flow/lib/python3.5/site-packages/ipykernel_launcher.py:17: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Sex  Ticket  Cabin  Embarked  Title  IsAlone  AgeBand  FareBand\n",
      "0       3    1       1      8         2      2        0        1         0\n",
      "1       1    0      10      2         0      3        0        2         3\n",
      "2       3    0      26      8         2      1        1        1         0\n",
      "3       1    0      30      2         2      3        0        2         3\n",
      "4       3    1      30      8         2      2        1        2         1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.81005587, 0.79329609, 0.8258427 , 0.78089888, 0.84745763])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state = 42\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "combine = [train_df, test_df]\n",
    "target = train_df['Survived']\n",
    "test_ids = test_df['PassengerId']\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    dataset['Title'] = dataset['Title'].replace(['Jonkheer', 'Don', 'Sir', 'Countess', 'Lady', 'Dona'], 'Royalty')\n",
    "    dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer')\n",
    "    dataset['Title'] = dataset['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace(['Mme'], 'Mrs')\n",
    "    dataset['Title'] = dataset['Title'].astype('category')\n",
    "    dataset['Title'] = dataset['Title'].cat.codes\n",
    "\n",
    "combined = pd.concat([train_df, test_df])\n",
    "grouped_median_age = combined[train_df.Age.notnull()].groupby(['Sex', 'Pclass', 'Title']).median()\n",
    "grouped_median_age = grouped_median_age.reset_index()[['Sex', 'Pclass', 'Title', 'Age']]\n",
    "grouped_median_age\n",
    "\n",
    "def assign_age(row):\n",
    "    condition = (\n",
    "        (grouped_median_age['Sex'] == row['Sex']) & \n",
    "        (grouped_median_age['Title'] == row['Title']) & \n",
    "        (grouped_median_age['Pclass'] == row['Pclass'])\n",
    "    )\n",
    "    return grouped_median_age[condition]['Age'].values[0]\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Age'] = dataset.apply(lambda row: assign_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    dataset.loc[dataset.Embarked.isnull(), 'Embarked'] = 'S'\n",
    "    dataset.loc[dataset.Cabin.notnull(), 'Cabin'] = dataset.loc[dataset.Cabin.notnull(), 'Cabin'].map(lambda x: x[0])\n",
    "    dataset.loc[dataset.Cabin.isnull(), 'Cabin'] = 'U' #unknown\n",
    "    \n",
    "def cleanTicket(ticket):\n",
    "    ticket = ticket.replace('.', '')\n",
    "    ticket = ticket.replace('/', '')\n",
    "    ticket = ticket.split()\n",
    "    ticket = map(lambda t : t.strip(), ticket)\n",
    "    ticket = list(filter(lambda t : not t.isdigit(), ticket))\n",
    "    if len(ticket) > 0:\n",
    "        return ticket[0]\n",
    "    else: \n",
    "        return 'XXX'\n",
    "for dataset in combine:    \n",
    "    dataset.loc[ dataset['Age'] <= 16, 'AgeBand'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'AgeBand'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'AgeBand'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'AgeBand'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'AgeBand'] = 4\n",
    "    dataset['AgeBand'] = dataset['AgeBand'].astype(int)\n",
    "    dataset.loc[dataset['Fare'].isnull(), 'Fare'] = 8\n",
    "    dataset.loc[dataset['Fare'] <= 8, 'FareBand'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 8) & (dataset['Fare'] <= 14.454), 'FareBand'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'FareBand']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'FareBand'] = 3\n",
    "    dataset['FareBand'] = dataset['FareBand'].astype(int)\n",
    "    dataset['Ticket'] = dataset['Ticket'].map(cleanTicket)\n",
    "    for column in ['Sex', 'Cabin', 'Embarked', 'Ticket']:\n",
    "        dataset[column] = dataset[column].astype('category')\n",
    "        dataset[column] = dataset[column].cat.codes\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.drop(['PassengerId', 'Name', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize'], axis=1, inplace=True)\n",
    "y = train_df['Survived']\n",
    "train_df.drop(['Survived'], axis=1, inplace=True)\n",
    "print(train_df.head())\n",
    "## array([0.81564246, 0.80446927, 0.80898876, 0.79213483, 0.8079096 ])\n",
    "# clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, min_samples_leaf=100, max_depth=2, random_state=random_state)\n",
    "# array([0.79888268, 0.81564246, 0.81460674, 0.80337079, 0.85875706])\n",
    "clf = RandomForestClassifier(max_depth=4, max_features=3, n_estimators=400)\n",
    "# clf = VotingClassifier(\n",
    "#     estimators=[\n",
    "#         ('lr', LogisticRegression()),\n",
    "#         ('svc', SVC()),\n",
    "#         ('tree', DecisionTreeClassifier(max_depth=1)),\n",
    "#     ],\n",
    "#     voting='hard',\n",
    "# )\n",
    "# clf = AdaBoostClassifier(\n",
    "#     DecisionTreeClassifier(max_depth=1), n_estimators=500,\n",
    "#     algorithm='SAMME', learning_rate=0.5\n",
    "# )\n",
    "# clf = DecisionTreeClassifier()\n",
    "# cv = cross_val_score(clf, train_df, y, cv=5)\n",
    "# param_test = {'n_estimators': np.linspace(100,500,10, dtype=np.int),\n",
    "#              'max_depth': [1,2,3,4],\n",
    "#              'max_features': [2,3,4,5]}\n",
    "# gs = GridSearchCV(estimator=clf, param_grid=param_test, cv=5, n_jobs=5, verbose=1)\n",
    "# gs.fit(train_df, y)\n",
    "# gs.best_params_, gs.best_score_\n",
    "clf.fit(train_df, y)\n",
    "cv = cross_val_score(clf, train_df, y, cv=5)\n",
    "cv\n",
    "# features = pd.DataFrame()\n",
    "# features['feature'] = train_df.columns\n",
    "# features['importance'] = clf.feature_importances_\n",
    "# features.sort_values(by=['importance'], ascending=True, inplace=True)\n",
    "# features.set_index('feature', inplace=True)\n",
    "# features.plot(kind='barh', figsize=(25, 25))\n",
    "# model = SelectFromModel(clf, prefit=True)\n",
    "# train_reduced = model.transform(train_df)\n",
    "# print(train_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 4, 'max_features': 5, 'n_estimators': 277}, 0.8226711560044894)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1620 out of 1620 | elapsed:   60.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [50, 10], 'max_depth': [4, 6, 8], 'min_samples_leaf': [1, 3, 10], 'max_features': ['sqrt', 'auto', 'log2'], 'bootstrap': [True, False], 'min_samples_split': [2, 3, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier()\n",
    "parameter_grid = {\n",
    "    'max_depth' : [4, 6, 8],\n",
    "    'n_estimators': [50, 10],\n",
    "    'max_features': ['sqrt', 'auto', 'log2'],\n",
    "    'min_samples_split': [2, 3, 10],\n",
    "    'min_samples_leaf': [1, 3, 10],\n",
    "    'bootstrap': [True, False],\n",
    "}\n",
    "grid_search = GridSearchCV(forest,\n",
    "    scoring='accuracy',\n",
    "    param_grid=parameter_grid,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(train_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8260381593714927"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_df)\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_ids,\n",
    "    \"Survived\": y_pred\n",
    "})\n",
    "submission.to_csv('titanic_result_feature_engineer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle competitions submit titanic -f titanic_result_feature_engineer.csv -m \"some extensive feature engineer\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
